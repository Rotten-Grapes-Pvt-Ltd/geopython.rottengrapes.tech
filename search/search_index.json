{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Master GeoPython","text":"<p>This repository contains the course content for Master Geospatial Analysis using python, a comprehensive course designed to teach you the fundamentals and advanced concepts of geospatial programming using Python</p>"},{"location":"#course-overview","title":"Course Overview","text":"<p>This course is live on Udemy and covers a wide range of topics from installation and setup to advanced geospatial analysis techniques. The course is structured to provide a hands-on learning experience, with practical examples and real-world applications.</p>"},{"location":"advance-python/matplotlib/advanced_visualization/","title":"Chapter 5 \u2014 Advanced Visualizations and Techniques in Matplotlib","text":""},{"location":"advance-python/matplotlib/advanced_visualization/#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Learn advanced plotting methods for deeper insights.</li> <li>Work with histograms, scatter plots, and boxplots.</li> <li>Visualize 2D data using heatmaps and imshow.</li> <li>Create stacked and grouped bar plots.</li> <li>Handle time series data effectively.</li> <li>Integrate Matplotlib with Pandas.</li> <li>Apply colormaps, annotations, and advanced styling.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#histograms-understanding-distributions","title":"Histograms \u2014 Understanding Distributions","text":"<ul> <li>Use histograms to see how values are distributed across bins.</li> </ul> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.randn(1000)\n\nplt.hist(data, bins=30, color='skyblue', edgecolor='black')\nplt.title(\"Histogram of Random Data\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Frequency\")\nplt.show()\n</code></pre> <ul> <li>Adjust <code>bins</code> to control granularity.</li> <li>Use <code>density=True</code> for probability density.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#boxplots-detecting-outliers-and-spread","title":"Boxplots \u2014 Detecting Outliers and Spread","text":"<ul> <li>Boxplots show median, quartiles, and outliers.</li> </ul> <pre><code>np.random.seed(42)\ndata = [np.random.normal(0, std, 100) for std in range(1, 4)]\n\nplt.boxplot(data, vert=True, patch_artist=True)\nplt.title(\"Boxplot of Different Distributions\")\nplt.xticks([1,2,3], ['Std=1', 'Std=2', 'Std=3'])\nplt.show()\n</code></pre> <ul> <li>Useful for comparing multiple groups.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#scatter-plots-relationships-between-variables","title":"Scatter Plots \u2014 Relationships Between Variables","text":"<ul> <li>Scatter plots are great for correlation and clustering.</li> </ul> <pre><code>x = np.random.rand(100)\ny = x*2 + np.random.randn(100)*0.2\n\nplt.scatter(x, y, c='blue', alpha=0.6, edgecolor='black')\nplt.title(\"Scatter Plot Example\")\nplt.xlabel(\"X Values\")\nplt.ylabel(\"Y Values\")\nplt.show()\n</code></pre> <ul> <li>Use <code>c</code> and <code>s</code> parameters to control colors and marker sizes.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#heatmaps-and-imshow-visualizing-2d-data","title":"Heatmaps and Imshow \u2014 Visualizing 2D Data","text":"<ul> <li>Use <code>imshow</code> to plot matrices, images, or heatmaps.</li> </ul> <pre><code>matrix = np.random.rand(10,10)\n\nplt.imshow(matrix, cmap='viridis', interpolation='nearest')\nplt.colorbar(label=\"Intensity\")\nplt.title(\"Heatmap Example\")\nplt.show()\n</code></pre> <ul> <li>Common in correlation matrices and image data.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#stacked-and-grouped-bar-plots","title":"Stacked and Grouped Bar Plots","text":"<ul> <li>Stacked bars show parts of a whole.</li> </ul> <pre><code>labels = ['A','B','C','D']\nx = np.arange(len(labels))\n\nmen = [20, 34, 30, 35]\nwomen = [25, 32, 34, 20]\n\nplt.bar(x, men, label='Men')\nplt.bar(x, women, bottom=men, label='Women')\nplt.xticks(x, labels)\nplt.ylabel(\"Scores\")\nplt.title(\"Stacked Bar Plot\")\nplt.legend()\nplt.show()\n</code></pre> <ul> <li>Use side-by-side for comparisons:</li> </ul> <pre><code>width = 0.35\nplt.bar(x - width/2, men, width, label='Men')\nplt.bar(x + width/2, women, width, label='Women')\nplt.xticks(x, labels)\nplt.title(\"Grouped Bar Plot\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/advanced_visualization/#time-series-visualization","title":"Time Series Visualization","text":"<ul> <li>Matplotlib works well with datetime objects.</li> </ul> <pre><code>import pandas as pd\n\ndates = pd.date_range(start=\"2023-01-01\", periods=10)\nvalues = np.random.randint(10, 100, size=10)\n\nplt.plot(dates, values, marker='o')\nplt.title(\"Time Series Plot\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Value\")\nplt.xticks(rotation=45)\nplt.show()\n</code></pre> <ul> <li>Pandas integrates directly with plotting: <code>df['col'].plot()</code>.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#pandas-matplotlib-integration","title":"Pandas + Matplotlib Integration","text":"<ul> <li>Pandas has built-in Matplotlib support.</li> </ul> <pre><code>df = pd.DataFrame({\n    \"A\": np.random.randn(100).cumsum(),\n    \"B\": np.random.randn(100).cumsum()\n}, index=pd.date_range(\"2023-01-01\", periods=100))\n\ndf.plot(title=\"Cumulative Random Walks\", figsize=(8,4))\nplt.show()\n</code></pre> <ul> <li>Great for quick exploratory data analysis.</li> </ul>"},{"location":"advance-python/matplotlib/advanced_visualization/#colormaps-and-advanced-styling","title":"Colormaps and Advanced Styling","text":"<ul> <li>Use colormaps for better representation.</li> </ul> <pre><code>x = np.random.rand(100)\ny = np.random.rand(100)\ncolors = np.random.rand(100)\n\nplt.scatter(x, y, c=colors, cmap='plasma', s=80, alpha=0.7)\nplt.colorbar(label=\"Color Intensity\")\nplt.title(\"Scatter with Colormap\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/advanced_visualization/#annotations-for-clarity","title":"Annotations for Clarity","text":"<ul> <li>Add text, arrows, and highlights to make plots more informative.</li> </ul> <pre><code>x = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)\nplt.title(\"Annotated Sine Curve\")\nplt.xlabel(\"X\")\nplt.ylabel(\"sin(X)\")\n\n# annotate max\nmax_idx = np.argmax(y)\nplt.annotate(\"Max Point\",\n             xy=(x[max_idx], y[max_idx]),\n             xytext=(x[max_idx]+1, y[max_idx]),\n             arrowprops=dict(facecolor='red', shrink=0.05))\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/advanced_visualization/#exercises","title":"Exercises","text":"<ul> <li>Create a histogram with 50 bins and overlay a KDE (kernel density estimate).</li> <li>Plot a boxplot comparing test scores of 3 different subjects.</li> <li>Make a scatter plot where points are colored by a third variable.</li> <li>Create a heatmap of a correlation matrix for a random DataFrame.</li> <li>Plot stock price time series data with annotations for key events.</li> </ul>"},{"location":"advance-python/matplotlib/customize_plots/","title":"Chapter 3 \u2014 Customizing Plots in Matplotlib","text":"<p>Creating plots is only the first step. To make them clear, attractive, and meaningful, you need to customize them. Matplotlib offers a wide range of options to change how your plots look.</p>"},{"location":"advance-python/matplotlib/customize_plots/#changing-line-styles-and-colors","title":"Changing Line Styles and Colors","text":"<p>You can change the appearance of lines using color codes, line styles, and markers.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\n\nplt.plot(x, np.sin(x), color=\"blue\", linestyle=\"--\", linewidth=2, marker=\"o\", label=\"Sine\")\nplt.plot(x, np.cos(x), color=\"red\", linestyle=\"-.\", linewidth=2, marker=\"s\", label=\"Cosine\")\n\nplt.legend()\nplt.title(\"Custom Line Styles\")\nplt.show()\n</code></pre> <ul> <li>Colors: <code>\"red\"</code>, <code>\"blue\"</code>, <code>\"green\"</code>, or short codes like <code>\"r\"</code>, <code>\"b\"</code>, <code>\"g\"</code>.  </li> <li>Line styles: <code>\"-\"</code> (solid), <code>\"--\"</code> (dashed), <code>\"-.\"</code> (dash-dot), <code>\":\"</code> (dotted).  </li> <li>Markers: <code>\"o\"</code> (circle), <code>\"s\"</code> (square), <code>\"^\"</code> (triangle), <code>\"*\"</code>, etc.</li> </ul>"},{"location":"advance-python/matplotlib/customize_plots/#titles-labels-and-legends","title":"Titles, Labels, and Legends","text":"<p>Adding titles and labels makes plots understandable.</p> <pre><code>x = np.linspace(0, 5, 50)\ny = x ** 2\n\nplt.plot(x, y, label=\"y = x\u00b2\")\nplt.title(\"Quadratic Function\")\nplt.xlabel(\"X Axis\")\nplt.ylabel(\"Y Axis\")\nplt.legend(loc=\"upper left\")\nplt.show()\n</code></pre> <ul> <li><code>plt.title(\"...\")</code> adds a title.  </li> <li><code>plt.xlabel()</code> / <code>plt.ylabel()</code> add axis labels.  </li> <li><code>plt.legend()</code> shows labels defined in <code>label=</code>.  </li> <li>The <code>loc</code> parameter controls legend placement.</li> </ul>"},{"location":"advance-python/matplotlib/customize_plots/#adjusting-figure-size-and-resolution","title":"Adjusting Figure Size and Resolution","text":"<pre><code>x = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.figure(figsize=(8, 4), dpi=120)\nplt.plot(x, y)\nplt.title(\"Custom Figure Size &amp; Resolution\")\nplt.show()\n</code></pre> <ul> <li><code>figsize=(width, height)</code> is in inches.  </li> <li><code>dpi</code> controls resolution (dots per inch). Higher values = sharper plots.</li> </ul>"},{"location":"advance-python/matplotlib/customize_plots/#adding-gridlines","title":"Adding Gridlines","text":"<pre><code>x = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)\nplt.title(\"Grid Example\")\nplt.grid(True, linestyle=\"--\", color=\"gray\", alpha=0.7)\nplt.show()\n</code></pre> <p>Gridlines make plots easier to read, especially for precise values.</p>"},{"location":"advance-python/matplotlib/customize_plots/#fonts-and-text-customization","title":"Fonts and Text Customization","text":"<pre><code>plt.plot(x, y)\nplt.title(\"Custom Fonts\", fontsize=16, fontweight=\"bold\", color=\"darkblue\")\nplt.xlabel(\"Time\", fontsize=12, style=\"italic\")\nplt.ylabel(\"Amplitude\", fontsize=12)\nplt.show()\n</code></pre> <p>You can change font size, weight, style, and color for titles and labels.</p>"},{"location":"advance-python/matplotlib/customize_plots/#colormaps","title":"Colormaps","text":"<p>Colormaps (or \"cmap\") are used in heatmaps, scatter plots, and contour plots.</p> <pre><code>np.random.seed(0)\nx = np.random.rand(100)\ny = np.random.rand(100)\ncolors = np.random.rand(100)\n\nplt.scatter(x, y, c=colors, cmap=\"viridis\", s=80)\nplt.colorbar(label=\"Color Intensity\")\nplt.title(\"Scatter Plot with Colormap\")\nplt.show()\n</code></pre> <p>Popular colormaps: <code>\"viridis\"</code>, <code>\"plasma\"</code>, <code>\"inferno\"</code>, <code>\"coolwarm\"</code>, <code>\"cividis\"</code>.</p>"},{"location":"advance-python/matplotlib/customize_plots/#multiple-customizations-together","title":"Multiple Customizations Together","text":"<pre><code>t = np.linspace(0, 2*np.pi, 200)\ns = np.sin(t)\n\nplt.figure(figsize=(8, 5), dpi=100)\nplt.plot(t, s, color=\"purple\", linestyle=\"--\", linewidth=2, marker=\"o\", label=\"sin(t)\")\n\nplt.title(\"Beautifully Customized Plot\", fontsize=14, fontweight=\"bold\")\nplt.xlabel(\"Angle (radians)\")\nplt.ylabel(\"Value\")\nplt.legend()\nplt.grid(True, linestyle=\":\", color=\"gray\", alpha=0.6)\n\nplt.show()\n</code></pre> <p>This combines line style, markers, title, labels, legend, and grid.</p>"},{"location":"advance-python/matplotlib/customize_plots/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Use colors, line styles, and markers for clarity.  </li> <li>Always label axes and add legends where needed.  </li> <li>Adjust figure size and DPI for reports and presentations.  </li> <li>Gridlines and fonts make your plots more readable.  </li> <li>Use colormaps to represent additional data dimensions.  </li> </ul>"},{"location":"advance-python/matplotlib/introduction/","title":"Introduction to Matplotlib","text":"<p>Matplotlib is the most widely used data visualization library in Python. It provides the foundation for many other plotting libraries such as Seaborn and Pandas\u2019 built-in plotting functions. With Matplotlib, you can create everything from simple line charts to complex scientific visualizations.</p>"},{"location":"advance-python/matplotlib/introduction/#why-learn-matplotlib","title":"Why Learn Matplotlib?","text":"<ul> <li>Universal foundation: Most other Python visualization tools (Seaborn, Plotly, Pandas plots) are built on top of Matplotlib.  </li> <li>Customizable: Almost every element of a plot can be changed \u2014 colors, line styles, fonts, legends, axes.  </li> <li>Flexible: Works with NumPy arrays, Pandas DataFrames, and even raw Python lists.  </li> <li>Publication quality: Used in academic papers, research, and professional reports.</li> </ul>"},{"location":"advance-python/matplotlib/introduction/#installing-matplotlib","title":"Installing Matplotlib","text":"<p>If you don\u2019t have it installed:</p> <pre><code>pip install matplotlib\n</code></pre> <p>Importing conventionally:</p> <pre><code>import matplotlib.pyplot as plt\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#how-matplotlib-fits-with-numpy-pandas","title":"How Matplotlib Fits With NumPy &amp; Pandas","text":"<ul> <li>NumPy: Provides arrays of numbers that Matplotlib can visualize.  </li> <li>Pandas: Provides tabular data (rows and columns) that can be plotted directly with Matplotlib.  </li> <li>Matplotlib: Turns that numerical/tabular data into visualizations.</li> </ul> <p>Example:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = np.random.randn(100).cumsum()\ndf = pd.DataFrame(data, columns=[\"values\"])\n\nplt.plot(df[\"values\"])\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#anatomy-of-a-matplotlib-figure","title":"Anatomy of a Matplotlib Figure","text":"<p>Every Matplotlib visualization has a structure:</p> <ul> <li>Figure: The whole window or page where plots are drawn.  </li> <li>Axes: The area where the actual plot is drawn (can be multiple in one figure).  </li> <li>Axis: The x and y coordinate system of the plot.  </li> <li>Artist: Everything you see in the figure (titles, lines, text, legends).</li> </ul> <p>Example:</p> <pre><code>fig, ax = plt.subplots()\nax.plot([1, 2, 3], [2, 4, 6])\nax.set_title(\"My First Plot\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#interfaces-pyplot-vs-object-oriented-oo","title":"Interfaces: Pyplot vs Object-Oriented (OO)","text":"<ul> <li>Pyplot style (quick &amp; easy): Works like MATLAB, good for small scripts.</li> </ul> <pre><code>plt.plot([1, 2, 3], [2, 4, 6])\nplt.title(\"Quick Plot\")\nplt.show()\n</code></pre> <ul> <li>Object-Oriented style (recommended): Gives more control and scales better.</li> </ul> <pre><code>fig, ax = plt.subplots()\nax.plot([1, 2, 3], [2, 4, 6])\nax.set_title(\"Better Plot\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#first-plot-step-by-step","title":"First Plot: Step by Step","text":"<pre><code>x = [1, 2, 3, 4, 5]\ny = [2, 4, 6, 8, 10]\n\nplt.figure(figsize=(6,4))        # Set figure size\nplt.plot(x, y, color=\"blue\", marker=\"o\", linestyle=\"--\")\nplt.title(\"Simple Line Chart\")\nplt.xlabel(\"X-axis Label\")\nplt.ylabel(\"Y-axis Label\")\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#adding-labels-legends-and-colors","title":"Adding Labels, Legends, and Colors","text":"<pre><code>x = [1, 2, 3, 4, 5]\ny1 = [1, 4, 9, 16, 25]\ny2 = [2, 4, 6, 8, 10]\n\nplt.plot(x, y1, label=\"Squares\", color=\"red\")\nplt.plot(x, y2, label=\"Doubles\", color=\"green\")\nplt.xlabel(\"X values\")\nplt.ylabel(\"Y values\")\nplt.title(\"Multiple Lines with Legend\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#saving-plots","title":"Saving Plots","text":"<pre><code>plt.plot([1, 2, 3], [2, 4, 6])\nplt.savefig(\"my_plot.png\")   # Save as PNG\nplt.savefig(\"my_plot.pdf\")   # Save as PDF\n</code></pre>"},{"location":"advance-python/matplotlib/introduction/#best-practices-tips","title":"Best Practices &amp; Tips","text":"<ul> <li>Prefer object-oriented interface for bigger projects.  </li> <li>Use labels and legends to make plots understandable.  </li> <li>Always set titles and axis labels.  </li> <li>Choose colors and markers that improve readability.  </li> <li>Use <code>plt.savefig()</code> to preserve results for reports.  </li> </ul>"},{"location":"advance-python/matplotlib/make_plots/","title":"Basic Plots in Matplotlib","text":"<p>In this chapter, we will explore the most commonly used plots in Matplotlib. These basic plots form the foundation of data visualization in Python and will help you represent your data in multiple ways.</p>"},{"location":"advance-python/matplotlib/make_plots/#line-plot","title":"Line Plot","text":"<p>A line plot is used to represent data points connected by straight lines. It\u2019s useful for showing trends over time.</p> <pre><code>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 6, 8, 10]\n\nplt.plot(x, y, color=\"blue\", marker=\"o\", linestyle=\"-\")\nplt.title(\"Line Plot Example\")\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"Y-axis\")\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#scatter-plot","title":"Scatter Plot","text":"<p>A scatter plot shows individual data points on the graph. It\u2019s useful for finding patterns, correlations, or outliers.</p> <pre><code>x = [5, 7, 8, 7, 6, 9, 5, 6, 7, 8]\ny = [99, 86, 87, 88, 100, 86, 103, 87, 94, 78]\n\nplt.scatter(x, y, color=\"red\")\nplt.title(\"Scatter Plot Example\")\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"Y-axis\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#bar-plot","title":"Bar Plot","text":"<p>A bar plot is used to compare quantities between categories.</p> <pre><code>categories = [\"A\", \"B\", \"C\", \"D\"]\nvalues = [3, 7, 2, 5]\n\nplt.bar(categories, values, color=\"purple\")\nplt.title(\"Bar Plot Example\")\nplt.xlabel(\"Categories\")\nplt.ylabel(\"Values\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#horizontal-bar-plot","title":"Horizontal Bar Plot","text":"<p>You can also plot horizontal bars using <code>barh()</code>.</p> <pre><code>categories = [\"A\", \"B\", \"C\", \"D\"]\nvalues = [3, 7, 2, 5]\n\nplt.barh(categories, values, color=\"green\")\nplt.title(\"Horizontal Bar Plot Example\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Categories\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#histogram","title":"Histogram","text":"<p>A histogram shows the distribution of data by dividing it into intervals (bins).</p> <pre><code>import numpy as np\n\ndata = np.random.randn(1000)\n\nplt.hist(data, bins=30, color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"Histogram Example\")\nplt.xlabel(\"Bins\")\nplt.ylabel(\"Frequency\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#pie-chart","title":"Pie Chart","text":"<p>A pie chart represents data as slices of a circle, useful for showing proportions.</p> <pre><code>sizes = [20, 30, 25, 25]\nlabels = [\"A\", \"B\", \"C\", \"D\"]\ncolors = [\"gold\", \"lightcoral\", \"lightskyblue\", \"yellowgreen\"]\n\nplt.pie(sizes, labels=labels, colors=colors, autopct=\"%1.1f%%\", startangle=90)\nplt.title(\"Pie Chart Example\")\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/make_plots/#best-practices-for-basic-plots","title":"Best Practices for Basic Plots","text":"<ul> <li>Use line plots for trends.  </li> <li>Use scatter plots for correlations.  </li> <li>Use bar plots for categorical comparisons.  </li> <li>Use histograms for distributions.  </li> <li>Use pie charts carefully \u2014 they are less precise than bar plots.  </li> </ul> <p>\u2705 You now know how to create the most common types of plots in Matplotlib. In the next chapter, we\u2019ll learn how to customize plots to make them more informative and visually appealing.</p>"},{"location":"advance-python/matplotlib/multiple_plots/","title":"Chapter 4 \u2014 Working with Multiple Plots and Subplots","text":"<p>When analyzing data, we often need to visualize multiple plots side by side or stacked together for comparison. Matplotlib makes this possible using figures and subplots.</p>"},{"location":"advance-python/matplotlib/multiple_plots/#figure-and-axes-the-basics","title":"Figure and Axes: The Basics","text":"<ul> <li>Figure: The entire window or canvas that holds your plots.  </li> <li>Axes: The actual plot area inside the figure (including x-axis, y-axis, labels, and data).  </li> <li>A single figure can contain multiple Axes (plots).</li> </ul>"},{"location":"advance-python/matplotlib/multiple_plots/#creating-multiple-plots-with-subplot","title":"Creating Multiple Plots with <code>subplot()</code>","text":"<p>The <code>plt.subplot(nrows, ncols, index)</code> function divides the figure into a grid.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\nplt.subplot(2, 1, 1)  # 2 rows, 1 column, first plot\nplt.plot(x, y1, 'b')\nplt.title(\"Sine Wave\")\n\nplt.subplot(2, 1, 2)  # second plot\nplt.plot(x, y2, 'r')\nplt.title(\"Cosine Wave\")\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This creates two vertically stacked plots.</p>"},{"location":"advance-python/matplotlib/multiple_plots/#creating-grids-of-plots-with-subplots","title":"Creating Grids of Plots with <code>subplots()</code>","text":"<p>The <code>plt.subplots()</code> method is more flexible and is the recommended approach.</p> <pre><code>fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n\nx = np.linspace(0, 5, 100)\n\naxes[0, 0].plot(x, np.sin(x))\naxes[0, 0].set_title(\"Sine\")\n\naxes[0, 1].plot(x, np.cos(x))\naxes[0, 1].set_title(\"Cosine\")\n\naxes[1, 0].plot(x, np.tan(x))\naxes[1, 0].set_title(\"Tangent\")\n\naxes[1, 1].plot(x, np.exp(x))\naxes[1, 1].set_title(\"Exponential\")\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Here we created a 2\u00d72 grid of subplots.</p>"},{"location":"advance-python/matplotlib/multiple_plots/#sharing-axes","title":"Sharing Axes","text":"<p>You can make plots share the same x-axis or y-axis for easier comparison.</p> <pre><code>fig, axes = plt.subplots(2, 1, sharex=True, figsize=(6, 6))\n\nt = np.linspace(0, 2*np.pi, 400)\naxes[0].plot(t, np.sin(t), 'g')\naxes[0].set_title(\"Sine\")\n\naxes[1].plot(t, np.sin(2*t), 'm')\naxes[1].set_title(\"Sine (double frequency)\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/multiple_plots/#different-plot-types-in-one-figure","title":"Different Plot Types in One Figure","text":"<p>You can mix multiple chart types in one figure using subplots.</p> <pre><code>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\nx = np.linspace(0, 10, 100)\n\n# Line plot\nax1.plot(x, np.sin(x), label=\"Sine\")\nax1.set_title(\"Line Plot\")\nax1.legend()\n\n# Histogram\ndata = np.random.randn(1000)\nax2.hist(data, bins=30, color=\"skyblue\", edgecolor=\"black\")\nax2.set_title(\"Histogram\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/multiple_plots/#advanced-layouts-with-gridspec","title":"Advanced Layouts with <code>GridSpec</code>","text":"<p>For more control over subplot positioning, Matplotlib offers <code>GridSpec</code>.</p> <pre><code>import matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(8, 6))\ngs = gridspec.GridSpec(3, 3, figure=fig)\n\nax1 = fig.add_subplot(gs[0, :])       # top row (spans all columns)\nax2 = fig.add_subplot(gs[1, :-1])     # middle row, first 2 columns\nax3 = fig.add_subplot(gs[1:, -1])     # right column (last 2 rows)\nax4 = fig.add_subplot(gs[2, 0])       # bottom-left\nax5 = fig.add_subplot(gs[2, 1])       # bottom-middle\n\nax1.plot(np.random.rand(10))\nax2.hist(np.random.randn(100))\nax3.scatter(np.random.rand(20), np.random.rand(20))\nax4.bar([1, 2, 3], [3, 2, 5])\nax5.plot(np.cumsum(np.random.randn(50)), 'r')\n\nfig.suptitle(\"Complex Layout with GridSpec\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/multiple_plots/#practical-example-comparing-stock-trends","title":"Practical Example: Comparing Stock Trends","text":"<pre><code>days = np.arange(1, 11)\ncompany_a = np.random.randint(50, 100, size=10)\ncompany_b = np.random.randint(60, 110, size=10)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\nax1.plot(days, company_a, marker=\"o\", label=\"Company A\")\nax1.set_title(\"Company A Stock\")\nax1.set_xlabel(\"Day\")\nax1.set_ylabel(\"Price\")\nax1.legend()\n\nax2.plot(days, company_b, marker=\"s\", label=\"Company B\", color=\"orange\")\nax2.set_title(\"Company B Stock\")\nax2.set_xlabel(\"Day\")\nax2.set_ylabel(\"Price\")\nax2.legend()\n\nplt.suptitle(\"Stock Comparison\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"advance-python/matplotlib/multiple_plots/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Use <code>subplot()</code> for quick simple grids.  </li> <li>Use <code>subplots()</code> for flexibility and array-like access to Axes.  </li> <li>Use <code>sharex</code>/<code>sharey</code> to align scales.  </li> <li>Use <code>GridSpec</code> for complex layouts.  </li> <li>Always apply <code>tight_layout()</code> to fix overlapping text.</li> </ul>"},{"location":"advance-python/numpy/numpy_creating_list/","title":"NumPy: Creating Arrays (from lists)","text":""},{"location":"advance-python/numpy/numpy_creating_list/#learning-objectives","title":"Learning objectives","text":"<p>After this chapter you will be able to:</p> <ul> <li>Create NumPy <code>ndarray</code> objects from Python lists, tuples and other iterable sources.</li> <li>Understand <code>np.array</code> vs <code>np.asarray</code> vs <code>np.asanyarray</code> and when copies are made.</li> <li>Create multi-dimensional arrays from nested Python sequences and handle ragged input.</li> <li>Use NumPy convenience constructors (<code>arange</code>, <code>linspace</code>, <code>zeros</code>, <code>ones</code>, <code>full</code>, <code>empty</code>, <code>eye</code>, <code>identity</code>, <code>frombuffer</code>, <code>fromfile</code>) and know when to prefer each.</li> <li>Specify and convert <code>dtype</code> at creation time and understand implicit upcasting rules.</li> <li>Detect and avoid common pitfalls (object-dtype arrays, unexpected shapes, memory/layout concerns).</li> </ul>"},{"location":"advance-python/numpy/numpy_creating_list/#basic-creation-from-python-lists-and-tuples","title":"Basic creation from Python lists and tuples","text":"<p>The simplest way to create an array is from a Python list or tuple using <code>np.array</code>.</p> <pre><code>import numpy as np\n\n# 1D array from list\narr1 = np.array([1, 2, 3])        # dtype inferred, usually int64 or int32\n\n# 2D array from nested lists (list of rows)\narr2 = np.array([[1, 2, 3], [4, 5, 6]])  # shape (2, 3)\n\n# from tuple\narr3 = np.array((7, 8, 9))\n</code></pre> <p>Key points:</p> <ul> <li><code>np.array</code> will try to infer the best common dtype. If the list mixes <code>int</code> and <code>float</code>, the resulting dtype will be a float (upcasting).</li> <li>If nested lists have equal-length sublists, a regular 2D <code>ndarray</code> will be produced. If lengths are unequal, NumPy will create a 1D array with <code>dtype=object</code> (a ragged array).</li> </ul> <pre><code># ragged example\nragged = np.array([[1, 2], [3]])\nprint(ragged.dtype)   # object\nprint(ragged.shape)   # (2,)\n</code></pre> <p>If you want a 2D array with missing values, provide explicit padding (e.g. <code>np.nan</code>) and a float dtype, or construct arrays with <code>np.full</code> then fill values.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#choosing-dtype-explicitly","title":"Choosing dtype explicitly","text":"<p>You can request a dtype at creation time:</p> <pre><code>arr = np.array([1, 2, 3], dtype=np.float32)\n</code></pre> <p>Why set dtype explicitly?</p> <ul> <li>Control memory footprint (e.g., <code>float32</code> vs <code>float64</code>).</li> <li>Avoid accidental downcasts or upcasts later.</li> <li>Ensure compatibility with other libraries (some expect specific dtypes).</li> </ul> <p>Converting dtype after creation uses <code>astype</code> which creates a copy:</p> <pre><code>arr_f64 = arr.astype(np.float64)\n</code></pre>"},{"location":"advance-python/numpy/numpy_creating_list/#npasarray-vs-nparray-vs-npasanyarray","title":"<code>np.asarray</code> vs <code>np.array</code> vs <code>np.asanyarray</code>","text":"<ul> <li><code>np.array(x)</code>: Always tries to create a new <code>ndarray</code>. It will copy data if necessary (for example when <code>dtype</code> conversion is needed or the input is not an <code>ndarray</code>).</li> <li><code>np.asarray(x)</code>: Avoids copying when the input is already an <code>ndarray</code> with the required dtype. Use this when you want to wrap inputs without unnecessary copies.</li> <li><code>np.asanyarray(x)</code>: Similar to <code>asarray</code> but will preserve subclasses of <code>ndarray</code> (like <code>np.matrix</code>).</li> </ul> <p>Examples:</p> <pre><code>lst = [1, 2, 3]\narr = np.asarray(lst)   # creates an ndarray\n\n# if you call with an array, asarray returns the same object (no copy) unless dtype change required\na = np.array([1,2,3], dtype=np.int32)\nb = np.asarray(a)\nprint(a is b)  # True -&gt; no copy\n\n# np.array would copy unless you pass copy=False explicitly (numpy sometimes still copies)\nc = np.array(a, copy=False)\n</code></pre> <p>Use <code>np.asarray</code> in functions that accept array-like input to minimize copies.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#convenience-constructors","title":"Convenience constructors","text":"<p>NumPy provides many factory functions for common arrays.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#arange","title":"<code>arange</code>","text":"<p>Like Python <code>range</code>, but returns an array:</p> <pre><code>np.arange(0, 10, 2)     # array([0,2,4,6,8])\n</code></pre> <p>Be cautious with floating step sizes (like <code>0.1</code>) because of floating point rounding: prefer <code>linspace</code> when you want a specific number of evenly spaced values.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#linspace","title":"<code>linspace</code>","text":"<p>Generates <code>num</code> evenly spaced samples between <code>start</code> and <code>stop</code> (inclusive by default):</p> <pre><code>np.linspace(0, 1, 5)    # array([0. ,0.25,0.5 ,0.75,1. ])\n</code></pre>"},{"location":"advance-python/numpy/numpy_creating_list/#zeros-ones-full-empty","title":"<code>zeros</code>, <code>ones</code>, <code>full</code>, <code>empty</code>","text":"<pre><code>np.zeros((2,3))    # zeros with float dtype by default\nnp.ones(5)         # ones\nnp.full((2,2), 7)  # filled with 7\nnp.empty((3,3))    # uninitialized memory \u2014 fast but contains garbage\n</code></pre> <p><code>np.empty</code> is useful for performance when you will fill the entries later; do not read uninitialized entries.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#identity-and-diagonal","title":"Identity and diagonal","text":"<pre><code>np.eye(3)          # 3x3 identity (float dtype)\nnp.identity(3)     # same as eye\nnp.diag([1,2,3])   # diagonal matrix from vector\n</code></pre>"},{"location":"advance-python/numpy/numpy_creating_list/#frombuffer-and-fromfile","title":"<code>frombuffer</code> and <code>fromfile</code>","text":"<p>Used to create arrays from raw binary data \u2014 advanced and often faster for large binary files. Example:</p> <pre><code># from a bytes-like object\nb = b\"\\x01\\x00\\x02\\x00\"\nnp.frombuffer(b, dtype=np.int16)\n</code></pre> <p><code>fromfile</code> reads directly from a binary file but is platform-dependent and less flexible than using Python's <code>open</code> + <code>np.frombuffer</code> on <code>mmap</code> or using <code>np.load</code>/<code>np.save</code> for NumPy binary files (<code>.npy</code>).</p>"},{"location":"advance-python/numpy/numpy_creating_list/#creating-arrays-with-a-specific-shape","title":"Creating arrays with a specific shape","text":"<p>Often you want an array of a certain shape and dtype. Use <code>reshape</code> on an existing array or create directly:</p> <pre><code># create 12 values then reshape\na = np.arange(12)\na2 = a.reshape((3,4))   # shape (3,4)\n\n# direct creation\nb = np.zeros((3,4))\n</code></pre> <p>When reshaping, ensure the total size matches: product of shape dims must equal number of elements.</p>"},{"location":"advance-python/numpy/numpy_creating_list/#multi-dimensional-arrays-from-nested-lists","title":"Multi-dimensional arrays from nested lists","text":"<p>When creating arrays from nested sequences, NumPy expects consistent nesting depths and lengths for regular arrays.</p> <pre><code>regular = np.array([[1,2,3], [4,5,6]])   # shape (2,3)\n\n# inconsistent lengths -&gt; object array\nbad = np.array([[1,2], [3,4,5]])\n</code></pre> <p>If you need to create an array from nested lists but force a shape or dtype, consider:</p> <ul> <li>Pad shorter rows with <code>np.nan</code> and use a floating dtype.</li> <li>Build an empty array with <code>np.empty((nrows, ncols))</code> and fill row-by-row.</li> </ul>"},{"location":"advance-python/numpy/numpy_creating_list/#performance-considerations-at-creation-time","title":"Performance considerations at creation time","text":"<ul> <li>Creating arrays from Python lists has overhead because NumPy must iterate the Python objects and convert them; creating arrays from already-binary sources (binary files, memoryviews, <code>np.frombuffer</code>) is much faster.</li> <li>If you repeatedly build large arrays by appending Python lists, prefer collecting into a list and calling <code>np.array</code> once, or use functions like <code>np.concatenate</code> on a list of arrays.</li> </ul> <p>Example (bad):</p> <pre><code>arr = np.array([])\nfor i in range(1000):\n    arr = np.append(arr, i)   # repeatedly reallocates \u2014 slow\n</code></pre> <p>Better:</p> <pre><code>lst = [i for i in range(1000)]\narr = np.array(lst)\n</code></pre>"},{"location":"advance-python/numpy/numpy_creating_list/#reading-arrays-from-text-and-binary-files","title":"Reading arrays from text and binary files","text":"<ul> <li><code>np.loadtxt</code> / <code>np.genfromtxt</code> \u2014 load numerical data from text files (CSV-like). <code>genfromtxt</code> handles missing values but is slower.</li> <li><code>np.load</code> / <code>np.save</code> \u2014 read and write NumPy <code>.npy</code> and <code>.npz</code> binary formats (fast, recommended for NumPy-only workflows).</li> </ul> <p>Examples:</p> <pre><code>arr = np.loadtxt('data.csv', delimiter=',')\nnp.save('arr.npy', arr)\narr2 = np.load('arr.npy')\n</code></pre>"},{"location":"advance-python/numpy/numpy_creating_list/#common-pitfalls-and-debugging-tips","title":"Common pitfalls and debugging tips","text":"<ul> <li>If you see <code>dtype=object</code>, inspect your source lists for inconsistent shapes or mixed types.</li> <li>Use <code>np.asarray</code> if you want to avoid copies when the input might already be an <code>ndarray</code>.</li> <li>For reproducible behavior across platforms, prefer explicit dtypes like <code>np.int32</code> or <code>np.float64</code>.</li> <li>When using <code>fromfile</code>, be mindful of endianness and struct alignment \u2014 prefer <code>np.load</code> for portability.</li> </ul>"},{"location":"advance-python/numpy/numpy_indexing/","title":"NumPy: Indexing","text":""},{"location":"advance-python/numpy/numpy_indexing/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this chapter you will be able to:</p> <ul> <li>Use basic slicing and indexing to select subarrays.</li> <li>Distinguish between views and copies produced by different indexing methods.</li> <li>Apply advanced (fancy) indexing with integer arrays and boolean masks.</li> <li>Use <code>np.newaxis</code>, <code>...</code> (ellipsis), and <code>np.ix_</code> to reshape and select across axes.</li> <li>Understand indexing performance implications and when to prefer different approaches.</li> </ul>"},{"location":"advance-python/numpy/numpy_indexing/#indexing-fundamentals","title":"Indexing fundamentals","text":"<p>NumPy arrays use zero-based indexing and support multi-dimensional indexing via a comma-separated tuple.</p> <pre><code>import numpy as np\nA = np.arange(24).reshape(4,6)\n# A is shape (4,6)\n# element at row 1, column 2\nx = A[1, 2]\n# equivalent using nested brackets\ny = A[1][2]\n</code></pre> <p>Tip: <code>A[1, 2]</code> is preferred because <code>A[1]</code> returns a view of row 1 and then <code>[2]</code> indexes that row \u2014 the end result is same value but <code>A[1, 2]</code> is clearer and slightly more efficient.</p>"},{"location":"advance-python/numpy/numpy_indexing/#slicing-basic-and-multi-axis","title":"Slicing (basic and multi-axis)","text":"<p>Slicing follows <code>start:stop:step</code> semantics like Python lists. A slice returns a view (no copy) when possible.</p> <pre><code>arr = np.arange(10)\narr[2:8:2]    # elements at indices 2,4,6\n\n# 2D slicing\nA = np.arange(20).reshape(4,5)\nA[1:3, 2:5]   # rows 1-2 and columns 2-4 -&gt; shape (2,3)\n</code></pre> <p>A slice preserves the original array's memory when possible, so modifying the slice can modify the original array.</p> <pre><code>s = A[0:2, 0:2]\ns[0,0] = 99\n# A[0,0] is now 99\n</code></pre> <p>Use <code>.copy()</code> if you need an independent array.</p>"},{"location":"advance-python/numpy/numpy_indexing/#negative-indices-and-steps","title":"Negative indices and steps","text":"<p>Negative indices count from the end. A negative step can reverse an axis.</p> <pre><code>arr = np.arange(6)\narr[-1]     # last element (5)\narr[::-1]   # reversed array\n\n# 2D reverse rows\nA[::-1, :]  # rows reversed\n</code></pre>"},{"location":"advance-python/numpy/numpy_indexing/#boolean-indexing-masking","title":"Boolean indexing (masking)","text":"<p>Boolean indexing selects elements where a boolean array is <code>True</code>. The boolean index can be the same shape as the array (elementwise) or broadcastable.</p> <pre><code>x = np.arange(10)\nmask = x % 2 == 0\nx[mask]           # even numbers: array([0,2,4,6,8])\n\n# use mask to assign\nx[mask] = -1\n</code></pre> <p>Boolean indexing returns a copy (a 1D array) of matching elements, not a view. Assignments using boolean indexing affect the original array where the mask is <code>True</code>.</p>"},{"location":"advance-python/numpy/numpy_indexing/#integer-fancy-indexing","title":"Integer (fancy) indexing","text":"<p>Integer arrays allow selecting arbitrary elements or subarrays \u2014 and they always return copies.</p> <pre><code>A = np.arange(12).reshape(3,4)\nrows = np.array([0,2])\ncols = np.array([1,3])\nA[rows]         # selects rows 0 and 2 -&gt; shape (2,4)\nA[:, cols]      # selects columns 1 and 3 -&gt; shape (3,2)\n\n# elementwise selection (paired indices)\nA[rows, cols]   # picks elements (0,1) and (2,3) -&gt; shape (2,)\n</code></pre> <p>Fancy indexing with multiple index arrays follows broadcasting rules: if you pass two 2D index arrays of the same shape, you get an array of that shape where each entry is the selected element.</p>"},{"location":"advance-python/numpy/numpy_indexing/#mixing-integer-and-slice-indexing","title":"Mixing integer and slice indexing","text":"<p>When mixing slices and integer arrays, result shape is determined by the integer arrays and the remaining slices.</p> <pre><code>A = np.arange(24).reshape(4,6)\nA[[0,2], 1:4]  # select rows 0 and 2, and columns 1..3 -&gt; shape (2,3)\n</code></pre> <p>Important: fancy indexing always makes a copy; slicing returns a view. This affects both memory and whether in-place assignment modifies the source.</p>"},{"location":"advance-python/numpy/numpy_indexing/#using-npnewaxis-none-and-ellipsis","title":"Using <code>np.newaxis</code> / <code>None</code> and <code>...</code> (ellipsis)","text":"<p><code>np.newaxis</code> (or <code>None</code>) adds a new axis to turn a 1D array into 2D or to align shapes for broadcasting.</p> <pre><code>x = np.array([1,2,3])        # shape (3,)\nx[:, None]                   # shape (3,1)\nx[None, :]                   # shape (1,3)\n</code></pre> <p>Ellipsis <code>...</code> is a convenient shorthand to represent \":<code>:</code> until the last axis\".</p> <pre><code>A = np.zeros((2,3,4,5))\nA[1, ..., 2]   # A[1, :, :, 2]\n</code></pre>"},{"location":"advance-python/numpy/numpy_indexing/#npix_-for-cross-product-indexing","title":"<code>np.ix_</code> for cross product indexing","text":"<p><code>np.ix_</code> builds open meshes to select a cross-product of indices.</p> <pre><code>A = np.arange(12).reshape(3,4)\nrows = [0,2]\ncols = [1,3]\nA[np.ix_(rows, cols)]   # shape (2,2) with elements at row/col cross-product\n</code></pre> <p>This is useful when you want the full outer selection, not elementwise pairing.</p>"},{"location":"advance-python/numpy/numpy_indexing/#advanced-helpers-take-put-choose","title":"Advanced helpers: <code>take</code>, <code>put</code>, <code>choose</code>","text":"<ul> <li><code>np.take(a, indices, axis=None)</code> extracts elements along an axis (similar to fancy indexing but often faster and clearer).</li> <li><code>np.put(a, indices, values, axis=None)</code> places values into array positions.</li> <li><code>np.choose</code> picks elements from multiple choices along an index array.</li> </ul> <pre><code>np.take(A, [0,2], axis=0)\n</code></pre>"},{"location":"advance-python/numpy/numpy_indexing/#indexing-and-broadcasting-selecting-with-broadcastable-masks","title":"Indexing and broadcasting: selecting with broadcastable masks","text":"<p>Boolean masks can be broadcast to match an axis.</p> <pre><code>A = np.arange(12).reshape(3,4)\nmask = np.array([True, False, True])[:, None]  # shape (3,1)\nA[mask]   # flattened array of selected rows (rows 0 and 2)\n</code></pre>"},{"location":"advance-python/numpy/numpy_indexing/#views-vs-copies-summary-and-examples","title":"Views vs copies \u2014 summary and examples","text":"<ul> <li>Slicing (<code>start:stop</code>) \u2192 view (no copy) when possible.</li> <li>Fancy indexing (integer arrays) \u2192 copy.</li> <li>Boolean indexing \u2192 copy of matching elements (1D) but assignment uses mask to modify original.</li> <li><code>np.take</code> often returns a copy.</li> </ul> <p>When in doubt, test with <code>is</code> or <code>np.shares_memory</code>.</p> <pre><code>s = A[0:2]\nnp.shares_memory(A, s)   # True -&gt; view\nf = A[[0,1]]\nnp.shares_memory(A, f)   # False -&gt; copy\n</code></pre>"},{"location":"advance-python/numpy/numpy_indexing/#performance-considerations","title":"Performance considerations","text":"<ul> <li>Prefer slices and views for memory efficiency and speed when operating on contiguous subarrays.</li> <li>Fancy and boolean indexing create copies \u2014 avoid in tight loops if you can restructure to use slicing or vectorized masking.</li> <li>Use <code>np.take</code> with <code>mode</code> parameter for safety and sometimes better performance.</li> </ul>"},{"location":"advance-python/numpy/numpy_indexing/#common-pitfalls-and-debugging-tips","title":"Common pitfalls and debugging tips","text":"<ul> <li>Unexpected <code>dtype=object</code> after indexing often means you created an array of Python objects earlier.</li> <li>Using chained indexing like <code>A[0][1:3] = ...</code> can be harder to reason about; prefer <code>A[0, 1:3] = ...</code>.</li> <li>After fancy indexing remember you have a copy \u2014 assignments to the result won't affect the source.</li> </ul>"},{"location":"advance-python/numpy/numpy_indexing/#exercises","title":"Exercises","text":"<ol> <li>Given <code>A = np.arange(30).reshape(5,6)</code>: select rows 1,3 and columns 2,4 as a (2,2) array using <code>np.ix_</code>.</li> <li>Use boolean indexing to set all negative values in an array to zero.</li> <li>Demonstrate that slicing returns a view (modify slice and show original changed) and that fancy indexing returns a copy.</li> <li>Use <code>np.newaxis</code> to convert a shape <code>(10,)</code> vector to <code>(10,1)</code> and <code>(1,10)</code> then compute their outer product.</li> <li>Time selecting a large contiguous block using slicing vs using fancy indexing with an integer array. Observe memory usage.</li> </ol>"},{"location":"advance-python/numpy/numpy_intro/","title":"NumPy: Introduction","text":""},{"location":"advance-python/numpy/numpy_intro/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this chapter you will be able to:</p> <ul> <li>Explain what NumPy is and why it is the foundational numerical library in Python.</li> <li>Install and import NumPy properly in different environments.</li> <li>Create and inspect <code>ndarray</code> objects (NumPy arrays) and understand their core attributes.</li> <li>Perform simple, idiomatic array operations and understand why NumPy is faster than plain Python lists.</li> <li>Learn common terminology used in later chapters (dtype, shape, ndim, broadcasting, ufuncs).</li> </ul>"},{"location":"advance-python/numpy/numpy_intro/#what-is-numpy","title":"What is NumPy?","text":"<p>NumPy (Numerical Python) is a fundamental package for scientific computing in Python. It provides:</p> <ul> <li>A powerful N-dimensional array object, <code>ndarray</code>, which stores elements of the same data type in contiguous memory.</li> <li>Efficient, vectorized operations implemented in C, which are much faster than equivalent pure-Python loops.</li> <li>A large collection of mathematical functions (universal functions, or ufuncs), random number capabilities, linear algebra helpers, FFTs, and tools for memory-efficient data handling.</li> </ul> <p>NumPy is the basis for most scientific Python libraries (Pandas, SciPy, scikit-learn, TensorFlow, etc.), so understanding it unlocks a large part of the scientific Python ecosystem.</p>"},{"location":"advance-python/numpy/numpy_intro/#why-use-numpy-instead-of-python-lists","title":"Why use NumPy instead of Python lists?","text":"<p>Performance</p> <ul> <li>NumPy arrays store elements in contiguous memory and use a fixed data type. This enables low-level optimizations and vectorized operations (operations applied elementwise in native machine code).</li> </ul> <p>Memory efficiency</p> <ul> <li><code>ndarray</code> uses a fixed-size data type (<code>dtype</code>) per array, so memory is compact and predictable.</li> </ul> <p>Convenience</p> <ul> <li>Built-in broadcasting rules, slicing, boolean indexing, reduction operations, and a large collection of numerics utilities make code concise and expressive.</li> </ul> <p>Example comparison (conceptual):</p> <ul> <li>Adding two lists element-wise with Python loops: <code>O(n)</code> Python-level operations with interpreter overhead for each element.</li> <li>Adding two NumPy arrays: one fast C loop, minimal Python overhead.</li> </ul>"},{"location":"advance-python/numpy/numpy_intro/#installation-and-import","title":"Installation and import","text":""},{"location":"advance-python/numpy/numpy_intro/#using-pip","title":"Using pip","text":"<pre><code>pip install numpy\n</code></pre>"},{"location":"advance-python/numpy/numpy_intro/#using-conda","title":"Using conda","text":"<pre><code>conda install numpy\n</code></pre>"},{"location":"advance-python/numpy/numpy_intro/#import-convention","title":"Import convention","text":"<pre><code>import numpy as np\n</code></pre> <p>This is the standard alias used in most code and documentation.</p>"},{"location":"advance-python/numpy/numpy_intro/#the-core-object-ndarray","title":"The core object: <code>ndarray</code>","text":"<p>An <code>ndarray</code> (N-dimensional array) is the main data structure in NumPy. Key characteristics:</p> <ul> <li>Homogeneous: every element has the same <code>dtype</code> (data type).</li> <li>Contiguous memory (usually): efficient for low-level operations.</li> <li>Shape: tuple describing length along each axis, e.g. <code>(3, 4)</code> for 2D.</li> </ul>"},{"location":"advance-python/numpy/numpy_intro/#creating-arrays","title":"Creating arrays","text":"<pre><code>import numpy as np\n\n# from a Python list\narr = np.array([1, 2, 3])\n\n# explicit dtype\narr_f = np.array([1, 2, 3], dtype=np.float64)\n\n# common convenience constructors\nzeros = np.zeros((2, 3))          # 2x3 array filled with 0.0\nones = np.ones(5)                 # 1D array with five 1.0s\narange = np.arange(0, 10, 2)      # like range(), returns array([0,2,4,6,8])\nlin = np.linspace(0, 1, 5)        # 5 values spaced between 0 and 1\neye = np.eye(3)                   # 3x3 identity matrix\nrand = np.random.default_rng().random((2, 2))  # random numbers (preferred RNG API)\n</code></pre>"},{"location":"advance-python/numpy/numpy_intro/#inspecting-arrays","title":"Inspecting arrays","text":"<pre><code>arr = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int32)\narr.shape      # (2, 3)\narr.ndim       # 2 (number of dimensions)\narr.size       # 6 (total number of elements)\narr.dtype      # dtype('int32')\narr.itemsize   # bytes per element (4 for int32)\narr.nbytes     # total bytes (size * itemsize)\n</code></pre>"},{"location":"advance-python/numpy/numpy_intro/#data-types-dtype","title":"Data types (<code>dtype</code>)","text":"<p>NumPy uses <code>dtype</code> objects to describe the type of the array\u2019s elements (e.g., <code>int32</code>, <code>float64</code>, <code>bool</code>, <code>complex128</code>).</p> <ul> <li>You can request a dtype at array creation. If not provided, NumPy infers from the input.</li> <li>Converting dtypes: <code>arr.astype(np.float32)</code> (creates a copy with new dtype).</li> <li>Common pitfalls: mixing Python <code>int</code> and <code>float</code> in a list will upcast to float when creating an array.</li> </ul> <pre><code>mixed = np.array([1, 2.5])\nprint(mixed.dtype)  # float64\n</code></pre>"},{"location":"advance-python/numpy/numpy_intro/#vectorized-operations-ufuncs-universal-functions","title":"Vectorized operations &amp; ufuncs (universal functions)","text":"<p>NumPy performs elementwise arithmetic without Python-level loops using ufuncs. This is the major source of speed.</p> <pre><code>a = np.array([1, 2, 3])\nb = np.array([10, 20, 30])\n\n# elementwise\nc = a + b      # array([11,22,33])\nd = a * 2      # array([2,4,6])\n\n# math functions are vectorized\nnp.sqrt(a)     # array([1.0, 1.41421356, 1.732...])\nnp.exp(a)      # elementwise e**x\n\n# reductions\na.sum()        # 6\nb.mean()       # 20.0\n</code></pre> <p>Because these operations are executed in optimized C loops, they are significantly faster for large arrays than Python loops.</p>"},{"location":"advance-python/numpy/numpy_intro/#broadcasting-brief-introduction","title":"Broadcasting (brief introduction)","text":"<p>Broadcasting is a set of rules NumPy follows to perform arithmetic between arrays of different shapes. If the shapes are compatible, NumPy \"stretches\" the smaller array across the larger one without copying data.</p> <p>Example:</p> <pre><code># a is shape (3,)\n# b is shape (3,)\n# they broadcast naturally\n\nrow = np.array([1, 2, 3])      # shape (3,)\ncol = np.array([[10], [20]])   # shape (2,1)\n\n# adding row to col: result shape (2,3)\nresult = col + row\n</code></pre> <p>We will cover broadcasting in depth in later chapters because it\u2019s crucial for writing compact and efficient numerical code.</p>"},{"location":"advance-python/numpy/numpy_intro/#memory-view-vs-copy","title":"Memory view vs copy","text":"<p>Some NumPy operations return views (no data copied) and some return copies (independent memory). Knowing which operations create views helps avoid unintended side-effects and excessive memory use.</p> <pre><code>a = np.arange(10)\nb = a[2:5]      # b is a view on a\nb[0] = 99\nprint(a[2])     # 99 -&gt; original changed\n\n# to force a copy\nc = a[2:5].copy()\n</code></pre> <p>Slicing always creates a view when possible; operations that change shape in most cases create a copy.</p>"},{"location":"advance-python/numpy/numpy_intro/#performance-tip-avoid-python-loops","title":"Performance tip \u2014 avoid Python loops","text":"<p>Prefer vectorized operations and ufuncs. When you must loop, try using <code>np.nditer</code> or write the hot loop in C/Cython, Numba, or use libraries built on top of NumPy.</p> <p>Quick benchmark (conceptual):</p> <pre><code># not to run here \u2014 conceptual example\n# Using list comprehension\nlst = [i * 2 for i in range(1_000_000)]\n\n# Using numpy\narr = np.arange(1_000_000)\narr2 = arr * 2\n</code></pre> <p>On large arrays, the NumPy version will be orders of magnitude faster.</p>"},{"location":"advance-python/numpy/numpy_intro/#common-gotchas","title":"Common gotchas","text":"<ul> <li>Mixing dtypes leads to upcasting (e.g., int + float -&gt; float).</li> <li>Use <code>.copy()</code> if you need an independent array, since slices are views.</li> <li>Be mindful of memory when creating many large intermediate arrays.</li> <li>Floating point precision: <code>.dtype</code> matters for numerical stability and memory usage.</li> </ul>"},{"location":"advance-python/numpy/numpy_intro/#suggested-exercises","title":"Suggested exercises","text":"<ol> <li>Install NumPy and print its version: <code>np.__version__</code>.</li> <li>Create a 1D array from a Python list and print its <code>.shape</code>, <code>.dtype</code>, <code>.nbytes</code>.</li> <li>Create a 3x3 identity matrix using <code>np.eye</code> and multiply it by a vector.</li> <li>Time adding two lists using Python vs adding two NumPy arrays (use <code>timeit</code> or <code>%%timeit</code> in Jupyter).</li> <li>Create a large array and practice slicing and making copies vs views. Observe when the original changes.</li> </ol>"},{"location":"advance-python/numpy/numpy_intro/#further-reading","title":"Further reading","text":"<ul> <li>Official NumPy documentation: https://numpy.org/doc</li> <li>\"NumPy Beginner's Guide\" and online tutorials</li> <li>Practice problems on Kaggle and local datasets</li> </ul>"},{"location":"advance-python/numpy/numpy_reshaping/","title":"NumPy: Reshaping","text":""},{"location":"advance-python/numpy/numpy_reshaping/#learning-objectives","title":"Learning objectives","text":"<p>After this chapter you will be able to:</p> <ul> <li>Explain the difference between shape, strides, and memory layout (C vs Fortran order).</li> <li>Use <code>reshape</code>, <code>resize</code>, <code>ravel</code>, <code>flatten</code>, <code>transpose</code>, <code>swapaxes</code>, <code>moveaxis</code>, <code>expand_dims</code>, and <code>squeeze</code> appropriately.</li> <li>Understand when operations return views vs copies and why that matters for performance and memory.</li> <li>Use <code>-1</code> in <code>reshape</code> and know its constraints.</li> <li>Convert arrays between C-contiguous and Fortran-contiguous layouts and when to prefer either.</li> <li>Recognize common pitfalls (in-place reshape failures, non-contiguous arrays, ambiguous reshape) and how to resolve them.</li> </ul>"},{"location":"advance-python/numpy/numpy_reshaping/#why-reshape-matters","title":"Why reshape matters","text":"<p>Reshaping changes the view of array dimensions without necessarily altering the underlying data. Many numerical algorithms expect specific shapes (e.g., matrix ops, CNN inputs), so reshaping is a frequent and important task. Efficient reshaping avoids copying memory and relies on adjusting shape and strides.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#core-api-reshape","title":"Core API: <code>reshape</code>","text":"<pre><code>b = a.reshape(new_shape)\n</code></pre> <ul> <li><code>np.reshape(a, newshape)</code> or <code>a.reshape(newshape)</code> returns an array with the requested shape if possible.</li> <li>If possible, NumPy will return a view (no data copied); otherwise it will return a copy.</li> <li><code>newshape</code> may include one <code>-1</code> which tells NumPy to infer that dimension.</li> </ul> <p>Examples:</p> <pre><code>import numpy as np\nx = np.arange(12)\nx.shape        # (12,)\nX = x.reshape((3,4))   # shape (3,4), no copy for contiguous x\nY = x.reshape((2,2,-1)) # -1 inferred -&gt; (2,2,3)\n</code></pre> <p>Constraints when using <code>-1</code>:</p> <ul> <li>Only one <code>-1</code> allowed.</li> <li>The inferred dimension must be an integer (the total size must be divisible by the product of specified dimensions).</li> </ul> <p>Ambiguous reshape cases will raise an error if the total sizes mismatch.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#reshape-vs-resize","title":"<code>reshape</code> vs <code>resize</code>","text":"<ul> <li><code>np.reshape</code> / <code>ndarray.reshape</code> returns a new view or copy and does not change <code>a</code>.</li> <li><code>ndarray.resize(new_shape)</code> modifies the array in-place and can change the total size; if the new size is larger, the array is filled with zeros. <code>np.resize(a, new_shape)</code> returns a new array (copy) with repeated data if needed.</li> </ul> <p>Examples:</p> <pre><code>a = np.arange(6)\nb = a.reshape((2,3))   # a unchanged\n\na.resize((3,2))       # a itself changes shape (in-place)\n</code></pre> <p>Be careful with <code>resize</code> as it mutates the original.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#flattening-ravel-vs-flatten","title":"Flattening: <code>ravel</code> vs <code>flatten</code>","text":"<ul> <li><code>ravel()</code> returns a view whenever possible (no copy) \u2014 it\u2019s the preferred fast way to flatten when you don\u2019t need an independent copy.</li> <li><code>flatten()</code> always returns a copy.</li> </ul> <pre><code>x = np.arange(6).reshape(2,3)\nflat_view = x.ravel()\nflat_copy = x.flatten()\n</code></pre> <p>If you modify <code>flat_view</code>, the change may reflect in <code>x</code> (if ravel returned a view).</p>"},{"location":"advance-python/numpy/numpy_reshaping/#transpose-and-axis-manipulation","title":"Transpose and axis manipulation","text":""},{"location":"advance-python/numpy/numpy_reshaping/#transpose","title":"<code>transpose</code>","text":"<p>Reorders axes. Shorthand: <code>a.T</code> for reversing axes of a 2D array.</p> <pre><code>A = np.arange(12).reshape(3,4)\nA.T.shape  # (4,3)\n</code></pre> <p><code>transpose</code> generally returns a view by adjusting strides; no copy for contiguous arrays.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#swapaxes-and-moveaxis","title":"<code>swapaxes</code> and <code>moveaxis</code>","text":"<ul> <li><code>swapaxes(a, i, j)</code> swaps two axes.</li> <li><code>moveaxis(a, source, destination)</code> moves axes to new positions while preserving order of others.</li> </ul> <pre><code>np.swapaxes(A, 0, 1)        # same as A.T for 2D\nnp.moveaxis(A, 0, -1)       # move axis 0 to last position\n</code></pre>"},{"location":"advance-python/numpy/numpy_reshaping/#using-npnewaxis-expand_dims-squeeze","title":"Using <code>np.newaxis</code> / <code>expand_dims</code> / <code>squeeze</code>","text":"<ul> <li><code>np.newaxis</code> (or <code>None</code>) adds a dimension:</li> </ul> <pre><code>v = np.array([1,2,3])      # shape (3,)\nv[:, None].shape          # (3,1)\n</code></pre> <ul> <li><code>np.expand_dims(a, axis)</code> is an explicit function to add axes.</li> <li><code>np.squeeze(a)</code> removes axes of length 1.</li> </ul> <p>These are commonly used to prepare inputs for broadcasting or functions that expect particular dimensionality.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#memory-layout-c-order-vs-fortran-order-and-strides","title":"Memory layout: C-order vs Fortran-order and strides","text":"<ul> <li>C-order (row-major): last index changes fastest. <code>np.arange(6).reshape((2,3), order='C')</code>.</li> <li>Fortran-order (column-major): first index changes fastest. <code>order='F'</code>.</li> </ul> <p><code>a.flags</code> tells you about contiguity:</p> <ul> <li><code>a.flags['C_CONTIGUOUS']</code> (or <code>a.flags.c_contiguous</code>)</li> <li><code>a.flags['F_CONTIGUOUS']</code></li> </ul> <p>Reshaping may fail to produce a view if the array is not contiguous in the required order. Use <code>np.ascontiguousarray(a)</code> or <code>np.asfortranarray(a)</code> to get contiguous copies when needed.</p> <p>Example where reshape requires copy:</p> <pre><code>A = np.arange(6).reshape(2,3)\nB = A.T            # B is non-contiguous in C-order\nB.reshape(6)       # may return a copy if strides incompatible\n</code></pre> <p>Understanding <code>strides</code> helps reason about views and reshape compatibility. <code>a.strides</code> gives a tuple of bytes to step in each dimension.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#order-argument-in-reshaperavelflatten","title":"Order argument in reshape/ravel/flatten","text":"<p>Most reshape-like functions accept an <code>order</code> argument: <code>'C'</code>, <code>'F'</code>, <code>'A'</code>, <code>'K'</code>.</p> <ul> <li><code>'C'</code>: C-order (row-major)</li> <li><code>'F'</code>: Fortran-order (column-major)</li> <li><code>'A'</code>: Fortran if input is Fortran contiguous, C otherwise</li> <li><code>'K'</code>: Keep order (attempt to preserve memory layout)</li> </ul> <pre><code>x.reshape((3,4), order='F')\n</code></pre> <p><code>ravel(order='F')</code> will flatten in column-major order.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#reshape-with-broadcasting-and-views","title":"Reshape with broadcasting and views","text":"<p>Reshaping to add singleton dimensions and using broadcasting can achieve many transformations without copying data.</p> <pre><code>x = np.arange(6)              # shape (6,)\nx = x.reshape((2,3))          # shape (2,3)\n# add singleton dimension for broadcasting\nx[:, :, None]                 # shape (2,3,1)\n</code></pre> <p>When you broadcast, NumPy behaves as if smaller arrays are repeated across axes, but it does not actually copy data.</p>"},{"location":"advance-python/numpy/numpy_reshaping/#common-pitfalls-and-how-to-fix-them","title":"Common pitfalls and how to fix them","text":"<ul> <li>Error: cannot reshape array of size N into shape M \u2014 check that product of dimensions matches.</li> <li>Unexpected copy: reshape returned a copy because array is non-contiguous \u2014 use <code>np.ascontiguousarray</code> before reshaping or use appropriate <code>order</code>.</li> <li>Memory blowup: creating many copies with <code>reshape</code> + operations can double memory usage. Use views when possible and delete intermediates.</li> </ul>"},{"location":"advance-python/numpy/numpy_reshaping/#practical-recipes","title":"Practical recipes","text":"<ul> <li>Ensure C-contiguous before reshaping without copy: <code>a = np.ascontiguousarray(a)</code>.</li> <li>Flatten safely (copy): <code>flat = a.flatten()</code>.</li> <li>Flatten view (fast, may alias): <code>flat_view = a.ravel()</code>.</li> <li>Convert between layouts: <code>a_c = np.ascontiguousarray(a)</code>; <code>a_f = np.asfortranarray(a)</code>.</li> <li>Insert/remove axes: <code>np.expand_dims(a, axis)</code> and <code>np.squeeze(a)</code>.</li> </ul>"},{"location":"advance-python/numpy/numpy_split/","title":"NumPy: Split","text":""},{"location":"advance-python/numpy/numpy_split/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this chapter you will be able to:</p> <ul> <li>Split arrays along any axis using <code>np.split</code>, <code>np.array_split</code>, and convenience functions (<code>hsplit</code>, <code>vsplit</code>, <code>dsplit</code>).</li> <li>Use integer indices and sections to control where splits occur.</li> <li>Understand when splits return views vs copies and why that matters.</li> <li>Reconstruct arrays after splitting using <code>np.concatenate</code>, <code>np.stack</code>, and <code>np.vstack</code>/<code>hstack</code>.</li> <li>Apply splitting in practical workflows (batching, cross-validation, tiling images).</li> </ul>"},{"location":"advance-python/numpy/numpy_split/#overview","title":"Overview","text":"<p>Splitting an array means dividing it into multiple sub-arrays along a specified axis. NumPy provides several functions for controlled splitting. The basic functions are:</p> <ul> <li><code>np.split(ary, indices_or_sections, axis=0)</code></li> <li><code>np.array_split(ary, indices_or_sections, axis=0)</code> (handles uneven splits)</li> <li><code>np.hsplit</code>, <code>np.vsplit</code>, <code>np.dsplit</code> \u2014 convenience wrappers for splitting along common axes for 1D/2D/3D arrays.</li> </ul> <p>All return a list of sub-arrays.</p>"},{"location":"advance-python/numpy/numpy_split/#npsplit-equal-sections-required","title":"<code>np.split</code> (equal sections required)","text":"<p><code>np.split</code> divides an array into equal sized sub-arrays when <code>indices_or_sections</code> is an integer. If the array cannot be evenly divided, it raises <code>ValueError</code>.</p> <pre><code>import numpy as np\nx = np.arange(12)\nparts = np.split(x, 3)  # -&gt; [array([0,1,2,3]), array([4,5,6,7]), array([8,9,10,11])]\n\n# 2D split along rows (axis=0)\nA = np.arange(24).reshape(6,4)\nrows = np.split(A, 3, axis=0)  # returns 3 arrays of shape (2,4)\n</code></pre> <p>You can also pass a list of indices where the array will be split. These indices indicate the start of the next section.</p> <pre><code>x = np.arange(10)\nnp.split(x, [3,7])  # -&gt; [x[:3], x[3:7], x[7:]]\n</code></pre>"},{"location":"advance-python/numpy/numpy_split/#nparray_split-uneven-splits-allowed","title":"<code>np.array_split</code> (uneven splits allowed)","text":"<p><code>np.array_split</code> performs like <code>np.split</code> but allows uneven divisions when an integer is provided. The earlier sections will be one element larger when the size isn't divisible.</p> <pre><code>x = np.arange(10)\nnp.array_split(x, 3)  # -&gt; [array([0,1,2,3]), array([4,5,6]), array([7,8,9])]  # sizes 4,3,3\n</code></pre> <p>Use <code>array_split</code> when you expect possible uneven splits (e.g., batching data into N chunks).</p>"},{"location":"advance-python/numpy/numpy_split/#convenience-wrappers-hsplit-vsplit-dsplit","title":"Convenience wrappers: <code>hsplit</code>, <code>vsplit</code>, <code>dsplit</code>","text":"<p>These are shorthand functions for common split axes:</p> <ul> <li><code>np.hsplit(ary, sections)</code> \u2014 split horizontally (axis=1 for 2D arrays). For 1D input it behaves like <code>split</code>.</li> <li><code>np.vsplit(ary, sections)</code> \u2014 split vertically (axis=0). Only meaningful for arrays with <code>ndim &gt;= 2</code>.</li> <li><code>np.dsplit(ary, sections)</code> \u2014 split along the 3rd axis (axis=2), used for 3D arrays like images with channel dimension.</li> </ul> <p>Examples:</p> <pre><code>A = np.arange(12).reshape(3,4)\nnp.hsplit(A, 2)  # two arrays each with shape (3,2)\nnp.vsplit(A, 3)  # three arrays each with shape (1,4)\n</code></pre>"},{"location":"advance-python/numpy/numpy_split/#axis-argument-and-negative-axes","title":"Axis argument and negative axes","text":"<p>All split functions accept an <code>axis</code> argument. A negative axis counts from the end, e.g. <code>axis=-1</code> for the last axis.</p> <pre><code>B = np.arange(24).reshape(2,3,4)\n# split along last axis into 2 parts\nnp.split(B, 2, axis=-1)  # splits axis 2 into two arrays of shape (2,3,2)\n</code></pre>"},{"location":"advance-python/numpy/numpy_split/#views-vs-copies","title":"Views vs copies","text":"<p>Splitting often returns views when the requested sub-arrays correspond to contiguous memory regions in the original array. However, depending on strides and array contiguity, NumPy may return copies.</p> <ul> <li>For simple contiguous arrays and standard splits along major axes, results are usually views (no data copy).</li> <li>When using fancy indexing or splitting non-contiguous arrays, the result may be a copy.</li> </ul> <p>You can check with <code>np.shares_memory(a, sub)</code> to confirm whether a sub-array shares memory with the original.</p> <pre><code>A = np.arange(12).reshape(6,2)\nparts = np.split(A, 3, axis=0)\nnp.shares_memory(A, parts[0])  # True -&gt; view\n\n# after transpose, splits may produce copies\nB = A.T\nparts = np.split(B, 2, axis=1)\nnp.shares_memory(B, parts[0])  # may be False\n</code></pre> <p>Because views are lightweight, using <code>np.split</code> for tiling or batching large arrays is memory-friendly when it returns views.</p>"},{"location":"advance-python/numpy/numpy_split/#reconstructing-arrays-after-splitting","title":"Reconstructing arrays after splitting","text":"<p>To combine the pieces back into a single array, use concatenation functions:</p> <ul> <li><code>np.concatenate(seq, axis=...)</code></li> <li><code>np.stack(seq, axis=...)</code> (adds a new axis)</li> <li>Convenience: <code>np.vstack</code>, <code>np.hstack</code>, <code>np.dstack</code></li> </ul> <pre><code>parts = np.array_split(np.arange(10), 3)\nnp.concatenate(parts)    # reconstructs original order\n</code></pre> <p>Be mindful of shapes: concatenation requires matching dimensions except along the concatenation axis.</p>"},{"location":"advance-python/numpy/numpy_split/#practical-uses","title":"Practical uses","text":"<ul> <li>Batching: split data into minibatches for SGD: <code>batches = np.array_split(dataset, n_batches)</code></li> <li>Cross-validation folds: split indices into k folds for cross-validation.</li> <li>Image tiling: split large images into tiles for processing, and then recombine.</li> <li>Parallel processing: divide work into sections and process in parallel, then join results.</li> </ul>"},{"location":"advance-python/numpy/numpy_split/#common-pitfalls-and-tips","title":"Common pitfalls and tips","text":"<ul> <li><code>np.split</code> with integer sections requires exact divisibility; prefer <code>np.array_split</code> for robustness.</li> <li>When splitting along axis=1 for 1D arrays, you may get unexpected behavior; ensure correct dimensionality first.</li> <li>Always check shapes of parts before concatenation; shape mismatches cause errors.</li> <li>Use <code>np.shares_memory</code> to verify whether splits create views if you plan to modify sub-arrays in-place.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/","title":"Pandas: Cleaning &amp; Transforming Data","text":""},{"location":"advance-python/pandas/pandas_cleaning/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Recognize common real\u2011world data problems and decide principled ways to fix them.</li> <li>Clean strings, numbers, dates and categorical data with Pandas\u2019 vectorized APIs.</li> <li>Choose safe casting &amp; nullable dtypes to preserve missing data.</li> <li>Reshape awkward tables and expand nested values for tidy analysis.</li> <li>Prepare features for machine learning: handling categories, encoding, scaling, and avoiding leakage.</li> <li>Build reproducible, testable pipelines and save intermediate results with provenance.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#quick-overview-what-good-cleaning-achieves","title":"Quick overview (what good cleaning achieves)","text":"<ul> <li>Accurate downstream analysis and models.</li> <li>Reproducible steps so colleagues can re\u2011run your work.</li> <li>Reasonable memory usage and runtime for data at scale.</li> <li>Clear documentation and saved intermediate artifacts.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#inspecting-data-a-practical-checklist","title":"Inspecting data \u2014 a practical checklist","text":"<ul> <li> <p>Preview the data structure</p> <ul> <li><code>df.head()</code>, <code>df.tail()</code>, <code>df.sample(5)</code></li> <li><code>df.shape</code> and <code>df.columns</code></li> <li><code>df.info()</code> with <code>memory_usage='deep'</code></li> <li> <p>Check for missingness and uniques</p> </li> <li> <p><code>df.isna().sum()</code></p> </li> <li><code>df.nunique()</code> and <code>df['col'].value_counts(dropna=False).head()</code></li> <li> <p>Quick stats</p> </li> <li> <p><code>df.describe(include='all')</code> \u2014 notice <code>count</code> vs <code>len(df)</code> to spot missing rows</p> </li> <li> <p>Spot-check problem rows</p> </li> <li> <p><code>df[df['col'].isna()].sample(10)</code> and <code>df[df['col'].astype(str).str.len()&gt;100]</code></p> </li> </ul> </li> </ul> <p>Rule of thumb: never clean blindly \u2014 inspect, hypothesize why a problem exists, then apply a fix and re\u2011check.</p>"},{"location":"advance-python/pandas/pandas_cleaning/#missing-data-strategies-tradeoffs-and-examples","title":"Missing data \u2014 strategies, trade\u2011offs and examples","text":"<ul> <li> <p>Why it matters</p> <ul> <li>Missing values change aggregates, breaks ML algorithms that expect numeric input, and may bias results.</li> </ul> </li> <li> <p>Common strategies (pros/cons):</p> <ul> <li>Drop rows: simple, may bias sample if missingness is informative.</li> <li>Drop columns: useful when a column is mostly empty (&gt;90%) and not useful.</li> <li>Fill with constant: <code>0</code> or <code>'Unknown'</code> \u2014 simple but can distort distributions.</li> <li>Impute with mean/median/mode: preserves quantity of data but hides uncertainty.</li> <li>Model\u2011based imputation: uses other columns to predict missing values; more accurate but complex and may leak information.</li> <li>Flag missingness: create an indicator column \u2014 lets models learn from the fact that something was missing.</li> </ul> </li> <li> <p>Recipes</p> </li> </ul> <pre><code># drop rows missing 'age'\ndf = df.dropna(subset=['age'])\n\n# fill numeric with median\ndf['income'] = df['income'].fillna(df['income'].median())\n\n# group-wise fill (e.g., fill salary within each department)\ndf['salary'] = df.groupby('dept')['salary'].transform(lambda x: x.fillna(x.median()))\n\n# indicator column for missing phone\ndf['phone_missing'] = df['phone'].isna().astype('int8')\n</code></pre> <ul> <li> <p>When to use imputation vs dropping</p> <ul> <li>If the proportion of missing is small and not systematically related to outcome, impute.</li> <li>If missing is too frequent or the column is unreliable, prefer dropping or collecting better data.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#strings-and-text-cleaning-stepbystep","title":"Strings and text cleaning (step\u2011by\u2011step)","text":"<ul> <li> <p>Why vectorized string ops</p> <ul> <li><code>df['col'].str.*</code> methods are implemented in C and much faster than Python loops.</li> </ul> </li> <li> <p>Basic pipeline for a name column</p> <ul> <li>Trim whitespace, normalize spacing, fix encoding, standardize case, remove punctuation, correct common typos.</li> </ul> </li> </ul> <pre><code>s = df['name'].astype('string')\ns = s.str.strip()\ns = s.str.replace('\\s+', ' ', regex=True)\ns = s.str.normalize('NFKC')  # fix unicode normalization issues\ns = s.str.title()\n# correct common misspellings\ns = s.str.replace('Jonh', 'John')\ndf['name'] = s\n</code></pre> <ul> <li>Extract pieces</li> </ul> <pre><code># phone area code\ndf['area_code'] = df['phone'].str.extract(r'\\(?([0-9]{3})\\)?', expand=False)\n</code></pre> <ul> <li>Performance tip: convert high\u2011repetition text to <code>category</code> after cleaning for memory savings.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#categorical-data-deeper-dive","title":"Categorical data \u2014 deeper dive","text":"<ul> <li> <p>What happens under the hood</p> <ul> <li>Pandas stores categories as integer codes + category index. This reduces memory and makes comparisons fast.</li> </ul> </li> <li> <p>When to use</p> <ul> <li>Columns with many repeating values (country, product_id, status)</li> <li>Keys used in <code>groupby</code> or <code>merge</code> operations</li> </ul> </li> <li> <p>Creating and ordering categories</p> </li> </ul> <pre><code>df['color'] = df['color'].astype('category')\ndf['size'] = pd.Categorical(df['size'], categories=['S','M','L','XL'], ordered=True)\n</code></pre> <ul> <li> <p>Encoding for models</p> <ul> <li><code>cat.codes</code> gives ordinal codes (watch <code>-1</code> for missing)</li> <li><code>pd.get_dummies</code> or <code>OneHotEncoder</code> for many models</li> </ul> </li> <li> <p>Pitfalls</p> <ul> <li>Changing categories later can keep stale categories \u2014 use <code>df['col'] = df['col'].cat.remove_unused_categories()</code> or reset categories explicitly.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#safe-type-conversion-practical-rules","title":"Safe type conversion (practical rules)","text":"<ul> <li>Prefer <code>pd.to_numeric</code> and <code>pd.to_datetime</code> with <code>errors='coerce'</code> to convert safely and then handle <code>NaN</code>.</li> </ul> <pre><code># numbers with stray characters\ndf['price'] = pd.to_numeric(df['price'].str.replace('[^0-9\\.-]', '', regex=True), errors='coerce')\n\n# safely convert dates\ndf['order_date'] = pd.to_datetime(df['order_date'], errors='coerce', dayfirst=False)\n</code></pre> <ul> <li>Use nullable integer dtype (<code>Int64</code>) if integers may contain NA:</li> </ul> <pre><code>df['age'] = pd.to_numeric(df['age'], errors='coerce').astype('Int64')\n</code></pre> <ul> <li>Always inspect <code>df.dtypes</code> after conversions.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#duplicates-and-record-reconciliation","title":"Duplicates and record reconciliation","text":"<ul> <li>Detect duplicates</li> </ul> <pre><code># exact duplicate rows\ndf[df.duplicated(keep=False)]\n\n# duplicated by id\ndf[df.duplicated(subset=['id'], keep=False)]\n</code></pre> <ul> <li> <p>Strategies to reconcile</p> <ul> <li>Keep first/last (<code>keep='first'</code>), merge information (use <code>groupby.agg</code> to aggregate fields), or flag for manual review.</li> </ul> </li> </ul> <pre><code># keep most recent record by timestamp\ndf = df.sort_values('updated_at').drop_duplicates(subset=['id'], keep='last')\n</code></pre>"},{"location":"advance-python/pandas/pandas_cleaning/#reshaping-tools-with-cleaning-examples","title":"Reshaping tools with cleaning examples","text":"<ul> <li><code>melt</code> (wide\u2192long) helps when multiple measurement columns share semantics.</li> </ul> <pre><code>long = df.melt(id_vars=['id','date'], value_vars=['sales_A','sales_B'], var_name='store', value_name='sales')\n</code></pre> <ul> <li><code>pivot_table</code> to aggregate and reshape</li> </ul> <pre><code>summary = (long\n           .pivot_table(index=['id','date'], columns='store', values='sales', aggfunc='sum')\n           .reset_index())\n</code></pre> <ul> <li><code>explode</code> for list-like cells</li> </ul> <pre><code># tags column like 'a,b,c'\ndf['tags_list'] = df['tags'].str.split(',')\ndf = df.explode('tags_list')\n</code></pre>"},{"location":"advance-python/pandas/pandas_cleaning/#mapping-replacing-and-conditional-fixes","title":"Mapping, replacing and conditional fixes","text":"<ul> <li>Use <code>replace</code> for exact substitutions and <code>map</code> for mapping keys to values (map produces NaN for missing keys).</li> </ul> <pre><code># multiple replacements\ndf['country'] = df['country'].replace({'U.S.': 'USA', 'United states': 'USA'})\n\n# mapping to codes\ncodes = {'USA':'NA','India':'AS'}\ndf['region'] = df['country'].map(codes)\n</code></pre> <ul> <li>Conditional updates with <code>.loc</code></li> </ul> <pre><code>mask = df['email'].str.contains('@example.com', na=False)\ndf.loc[mask, 'is_example'] = True\n</code></pre>"},{"location":"advance-python/pandas/pandas_cleaning/#when-to-use-apply-map-iterrows","title":"When to use <code>apply</code> / <code>map</code> / <code>iterrows</code>","text":"<ul> <li>Avoid row-wise Python loops for large data. Prefer vectorized solutions.</li> <li>Use <code>.apply</code> for complex row logic when vectorization is infeasible, but test performance on a sample first.</li> </ul> <pre><code># slow: avoid if large\ndf['foo'] = df.apply(lambda r: expensive_calc(r['a'], r['b']), axis=1)\n</code></pre> <ul> <li>Benchmark with <code>%timeit</code> in notebooks; consider <code>swifter</code> or <code>dask</code> if apply is a bottleneck.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#units-currencies-and-consistent-measures","title":"Units, currencies and consistent measures","text":"<ul> <li>Always store a canonical unit column (e.g., <code>weight_kg</code>) and keep original unit metadata if needed.</li> <li>For currency conversion, get reliable exchange rates and apply reproducibly.</li> </ul> <pre><code># convert grams to kg\ndf.loc[df['unit']=='g', 'weight_kg'] = df.loc[df['unit']=='g', 'weight'] / 1000\n</code></pre>"},{"location":"advance-python/pandas/pandas_cleaning/#outlier-detection-methods-and-tradeoffs","title":"Outlier detection: methods and trade\u2011offs","text":"<ul> <li>IQR rule (simple and robust): flag values outside <code>Q1 - 1.5*IQR</code> \u2026 <code>Q3 + 1.5*IQR</code>.</li> <li>Z\u2011score (assumes approximate normality) \u2014 use only when distribution roughly normal.</li> <li>Robust methods: median absolute deviation (MAD).</li> </ul> <pre><code># IQR example\nQ1 = df['amount'].quantile(0.25)\nQ3 = df['amount'].quantile(0.75)\nIQR = Q3 - Q1\nmask = (df['amount'] &lt; Q1 - 1.5*IQR) | (df['amount'] &gt; Q3 + 1.5*IQR)\ndf_out = df[mask]\n</code></pre> <ul> <li>Decide per business rules: sometimes outliers are important signals, not errors.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#preparing-features-for-modeling-encoding-scaling","title":"Preparing features for modeling: encoding &amp; scaling","text":"<ul> <li> <p>Encoding strategies</p> <ul> <li>Low-cardinality nominal \u2192 one\u2011hot (<code>pd.get_dummies</code>)</li> <li>Ordered categories \u2192 ordinal encoding (<code>cat.codes</code>)</li> <li>High-cardinality \u2192 target encoding, hashing, or embeddings (careful with leakage)</li> </ul> </li> <li> <p>Scaling</p> <ul> <li><code>StandardScaler</code> for mean\u2011centered algorithms</li> <li><code>MinMaxScaler</code> for bounded scaling</li> <li>Fit on training set only, apply same transform to validation/test</li> </ul> </li> <li> <p>Example workflow with scikit\u2011learn</p> </li> </ul> <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\nnum_cols = ['age','income']\ncat_cols = ['color','region']\n\npre = ColumnTransformer([\n    ('num', StandardScaler(), num_cols),\n    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols)\n])\n\npipe = Pipeline([('pre', pre), ('clf', SomeEstimator())])\n</code></pre>"},{"location":"advance-python/pandas/pandas_cleaning/#pipelines-provenance-and-testing","title":"Pipelines, provenance and testing","text":"<ul> <li>Encapsulate cleaning steps into functions and unit\u2011test them (example: <code>clean_names</code>, <code>impute_income</code>).</li> <li>Use <code>pipe()</code> to chain transformations in a readable way:</li> </ul> <pre><code>cleaned = (raw\n           .pipe(clean_names)\n           .pipe(fill_missing)\n           .pipe(encode_features))\n</code></pre> <ul> <li>Save intermediate artifacts (Parquet) with clear filenames and timestamps. Keep a small README describing transformations.</li> <li>Add simple assertions in pipelines to verify invariants (<code>assert df['id'].is_unique</code>) and raise early if expectations fail.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#logging-and-monitoring-cleaning-jobs","title":"Logging and monitoring cleaning jobs","text":"<ul> <li>For long runs, log progress (rows processed, chunks, anomalies found).</li> <li>Example: log counts of missing values and number of rows written per chunk.</li> <li>In production, emit metrics (counts of dropped rows, imputed values) to monitoring dashboards.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#real-world-mini-case-study-cleaning-a-customer-dataset-walkthrough","title":"Real-world mini case study: cleaning a customer dataset (walkthrough)","text":"<ul> <li> <p>Problem: CSV from marketing with columns: <code>cust_id, name, email, phone, country, signup_date, spend_usd</code> with various issues:</p> <ul> <li>stray whitespace and bad capitalization in <code>name</code></li> <li>missing emails and inconsistent phone formats</li> <li><code>country</code> values contain typos</li> <li><code>signup_date</code> in <code>dd/mm/yyyy</code> format</li> <li><code>spend_usd</code> stored as strings with <code>$</code> and <code>,</code></li> </ul> </li> <li> <p>Steps (apply, check, repeat):</p> <ul> <li>Inspect sample lines in the file (first 20 rows)</li> <li>Read with <code>dtype={'cust_id': 'string'}</code> and <code>parse_dates=['signup_date']</code> using <code>dayfirst=True</code></li> <li>Clean <code>name</code>: strip/normalize/title-case and remove punctuation</li> <li>Clean <code>email</code>: <code>str.lower()</code> and <code>str.contains('@')</code> to flag invalids</li> <li>Normalize <code>phone</code>: remove non-digit chars, extract country code</li> <li>Standardize <code>country</code> using a mapping dict and convert to <code>category</code></li> <li>Convert <code>spend_usd</code> with <code>str.replace('[^0-9\\.-]','')</code> then <code>pd.to_numeric</code></li> <li>Save cleaned dataset to <code>cleaned_customers.parquet</code></li> </ul> </li> </ul> <p>This stepwise approach (inspect \u2192 parse \u2192 transform \u2192 validate \u2192 save) is reusable across datasets.</p>"},{"location":"advance-python/pandas/pandas_cleaning/#tests-and-validation-checks-to-add-to-pipelines","title":"Tests and validation checks to add to pipelines","text":"<ul> <li>Row\u2011count sanity: input vs output (allow for expected drops).</li> <li>Unique key check: <code>assert df['cust_id'].is_unique</code>.</li> <li>Range checks for numeric columns: <code>assert df['age'].between(0,120).all()</code>.</li> <li>Null checks for required columns: <code>assert df['email'].notna().sum() &gt;= threshold</code> or log the shortfall.</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#exercises-expanded-and-guided","title":"Exercises (expanded and guided)","text":"<ul> <li>Guided: clean a toy customer CSV (provided or self\u2011created). Include a step where you intentionally introduce a few bad rows to test <code>on_bad_lines='skip'</code> and then recover them for manual inspection.</li> <li>Exploratory: take a messy dataset, write three small cleaning functions (<code>normalize_names</code>, <code>fill_missing_values</code>, <code>encode_categorical</code>), and unit test them on small examples.</li> <li>Performance: compare runtime of <code>df.apply(func, axis=1)</code> vs vectorized operations on a 1\u2011million row sample (use <code>%timeit</code>).</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#quick-checklist-to-copy-into-your-pipeline-scripts","title":"Quick checklist to copy into your pipeline scripts","text":"<ul> <li> Inspect first 100 rows and top 10 problematic rows</li> <li> Log initial <code>df.shape</code>, <code>df.info()</code> and <code>df.isna().sum()</code></li> <li> Standardize strings and strip whitespace</li> <li> Convert datetimes and numeric columns with <code>errors='coerce'</code></li> <li> Handle missing values and add indicators where appropriate</li> <li> Convert repeated strings to <code>category</code></li> <li> Validate primary keys and critical ranges</li> <li> Save cleaned artifact (Parquet) and a short transformation README</li> </ul>"},{"location":"advance-python/pandas/pandas_cleaning/#further-reading-and-tools","title":"Further reading and tools","text":"<ul> <li>Pandas documentation on IO and indexes</li> <li>\"Feature Engineering for Machine Learning\" \u2014 recipes for transformations and encoding</li> <li>Dask for scaling Pandas workflows out\u2011of\u2011core</li> <li><code>great_expectations</code> for data validation in pipelines</li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/","title":"Reading &amp; Writing Data; Parsing Strategies","text":""},{"location":"advance-python/pandas/pandas_create_df/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understand the common file formats used for tabular data and their trade-offs.</li> <li>Load data from CSV, Excel, JSON, SQL, Parquet, compressed files, and web APIs into Pandas safely and efficiently.</li> <li>Parse dates, numeric formats, encodings, and missing values correctly.</li> <li>Read very large files without running out of memory (chunking, iterators, streaming).</li> <li>Write DataFrames back to disk or databases using sensible defaults with attention to reproducibility and performance.</li> <li>Diagnose and fix common parsing errors and messy input files.</li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#quick-format-guide-when-to-use-what","title":"Quick format guide \u2014 when to use what","text":"<ul> <li> <p>CSV / TSV</p> <ul> <li>Human\u2011readable, very common. Good for small\u2192medium files and easy sharing.</li> <li>Slower to parse and larger on disk than binary formats; fields may require careful parsing (quotes, separators).</li> </ul> </li> <li> <p>Excel (<code>.xls</code> / <code>.xlsx</code>)</p> <ul> <li>Business friendly (multiple sheets, formatting). Good for small\u2192medium ad\u2011hoc datasets.</li> <li>Slower to parse programmatically and may include merged cells or headers that need cleanup.</li> </ul> </li> <li> <p>JSON / NDJSON</p> <ul> <li>Flexible for nested or hierarchical data and APIs. Use newline\u2011delimited JSON (NDJSON) for large streams.</li> <li> <p>Parquet / Feather</p> </li> <li> <p>Columnar binary formats \u2014 fast I/O, compression, and efficient for analytics. Prefer for large datasets and repeated reads.</p> </li> </ul> </li> <li> <p>SQL databases</p> <ul> <li>Best for data that needs indexing, concurrent access, or partial queries. Pull only what you need with SQL.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#reading-csv-files-pdread_csv-the-essential-knobs","title":"Reading CSV files (<code>pd.read_csv</code>) \u2014 the essential knobs","text":"<ul> <li>Basic usage</li> </ul> <pre><code>import pandas as pd\n\ndf = pd.read_csv('data.csv')\n</code></pre> <ul> <li> <p>Important options and why they matter</p> <ul> <li><code>sep</code> / <code>delimiter</code> \u2014 set the column separator (<code>,</code>, <code>\\t</code>, <code>;</code>). Wrong <code>sep</code> means all data ends up in one column.</li> <li><code>header</code> / <code>names</code> \u2014 control column names when your file has no header or has extra header rows.</li> <li><code>dtype</code> \u2014 pass a dict like <code>{'id': 'int32', 'amount': 'float32'}</code> to avoid slow type inference and reduce memory.</li> <li><code>parse_dates</code> \u2014 parse date columns into <code>datetime64[ns]</code> so you can slice, resample, and extract date parts.</li> <li><code>usecols</code> \u2014 only read needed columns to save memory and time.</li> <li><code>na_values</code> \u2014 tell Pandas which strings should be treated as missing (e.g., <code>['', 'NA', 'n/a', '-']</code>).</li> <li><code>encoding</code> / <code>encoding_errors</code> \u2014 fix Unicode problems like <code>UnicodeDecodeError</code> (try <code>latin-1</code> or <code>cp1252</code>).</li> <li><code>engine='c'</code> or <code>engine='python'</code> \u2014 the C engine is much faster; use <code>python</code> for complex parsing options like unusual quoting or regex separators.</li> <li><code>chunksize</code> \u2014 read in row\u2011based chunks (returns an iterator of DataFrames) for streaming large files.</li> <li><code>compression</code> \u2014 <code>'gzip'</code>, <code>'bz2'</code>, <code>'xz'</code>, or <code>'zip'</code> when reading compressed files.</li> <li><code>low_memory</code> \u2014 if True (default) Pandas may infer dtypes in chunks and result in mixed dtypes. Set <code>low_memory=False</code> when you plan to supply <code>dtype</code> or want single\u2011pass inference.</li> </ul> </li> <li> <p>Practical examples</p> </li> </ul> <pre><code># read only useful columns, parse a date, and force types\ndf = pd.read_csv(\n    'sales.csv',\n    usecols=['order_id','order_date','amount','country'],\n    dtype={'order_id': 'int64', 'amount': 'float32'},\n    parse_dates=['order_date']\n)\n\n# read a tab separated file\ndf = pd.read_csv('data.tsv', sep='\\t')\n\n# read a gzipped CSV directly\ndf = pd.read_csv('data.csv.gz', compression='gzip')\n</code></pre> <ul> <li>Tips for international number formats</li> </ul> <pre><code># numbers like \"1.234,56\" (dot thousands, comma decimal)\ndf = pd.read_csv('euro.csv', thousands='.', decimal=',')\n</code></pre> <ul> <li> <p>Dealing with malformed rows</p> <ul> <li>Use <code>on_bad_lines='skip'</code> (pandas &gt;= 1.3) to skip bad rows and inspect later.</li> <li>Use <code>engine='python'</code> and <code>error_bad_lines=False</code> for older pandas versions (deprecated keywords).</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#practical-date-parsing-strategies","title":"Practical date parsing strategies","text":"<ul> <li> <p>Why parse dates</p> <ul> <li>Converting strings to datetimes unlocks time\u2011aware operations: slicing by date, <code>resample</code>, <code>.dt</code> accessors, timezone handling.</li> </ul> </li> <li> <p>Common approaches</p> <ul> <li>Simple column: <code>parse_dates=['date_col']</code>.</li> <li>Multiple columns to combine: <code>parse_dates={'date': ['year','month','day']}</code> or combine after load with <code>pd.to_datetime</code>.</li> <li>Use <code>pd.to_datetime(df['col'], format='%Y-%m-%d')</code> when you know the exact format \u2014 it is much faster and more reliable.</li> </ul> </li> <li> <p>Ambiguous formats</p> <ul> <li>Use <code>dayfirst=True</code> or <code>yearfirst=True</code> for ambiguous day/month parsing (e.g., <code>05/06/2020</code>).</li> </ul> </li> <li> <p>Large datasets</p> <ul> <li>Read date columns as strings first (<code>dtype={'date_col': 'string'}</code>), then convert with <code>pd.to_datetime(..., format=...)</code> in a second pass when you can guarantee format and speed.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#encodings-boms-and-stray-characters","title":"Encodings, BOMs, and stray characters","text":"<ul> <li> <p>Symptoms of encoding issues</p> <ul> <li><code>UnicodeDecodeError</code> when reading.</li> <li>Strange characters like <code>\u00c3\u00a9</code> instead of <code>\u00e9</code>.</li> </ul> </li> <li> <p>Fixes</p> <ul> <li>Try <code>encoding='latin-1'</code> or <code>encoding='cp1252'</code> if <code>utf-8</code> fails.</li> <li>Use <code>encoding_errors='replace'</code> (pandas &gt;= 1.4) to replace invalid bytes.</li> <li>If file has a Byte Order Mark (BOM), <code>pd.read_csv</code> usually handles it; otherwise use <code>encoding='utf-8-sig'</code>.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#reading-excel-files-read_excel-practical-notes","title":"Reading Excel files (<code>read_excel</code>) \u2014 practical notes","text":"<ul> <li>Use <code>sheet_name</code> (<code>None</code> for all sheets) and <code>usecols</code> / <code>skiprows</code> to extract the table area you need.</li> <li>Excel files may contain merged cells and headers in multiple rows; inspect visually and use <code>skiprows</code> / <code>header</code> to pick the right row for column names.</li> <li>Excel reading is slower \u2014 for repeatable automated workflows, prefer converting to CSV or Parquet beforehand.</li> </ul> <pre><code># read all sheets into a dict of DataFrames\nall_sheets = pd.read_excel('workbook.xlsx', sheet_name=None)\n</code></pre>"},{"location":"advance-python/pandas/pandas_create_df/#json-and-nested-data-read_json-and-json_normalize","title":"JSON and nested data: <code>read_json</code> and <code>json_normalize</code>","text":"<ul> <li>NDJSON (newline delimited) is easy to stream: <code>pd.read_json('file.ndjson', lines=True)</code>.</li> <li>For nested JSON, use <code>pd.json_normalize</code> to flatten records:</li> </ul> <pre><code>from pandas import json_normalize\nimport json\n\nwith open('nested.json') as f:\n    data = json.load(f)\nflat = json_normalize(data, record_path='items', meta=['order_id','customer'])\n</code></pre> <ul> <li>When consuming APIs, use <code>requests</code> to fetch JSON and normalize into a DataFrame.</li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#parquet-and-feather-fast-columnar-formats","title":"Parquet and Feather \u2014 fast columnar formats","text":"<ul> <li> <p>Why use them</p> <ul> <li>Faster read/write than CSV, smaller disk footprint due to compression, and better for analytics because they are columnar (you can read just the columns you need).</li> </ul> </li> <li> <p>Usage</p> </li> </ul> <pre><code>df.to_parquet('data.parquet', index=False)\ndf = pd.read_parquet('data.parquet')\n</code></pre> <ul> <li> <p>Partitioning</p> <ul> <li>When writing large datasets, partitioning by a column (e.g., <code>year=2020/ month=01/...</code>) can speed filters in downstream tools.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#sql-databases-and-read_sql-patterns","title":"SQL databases and <code>read_sql</code> patterns","text":"<ul> <li>Use <code>sqlalchemy.create_engine</code> for a connection and let the database filter/aggregate data when possible.</li> <li>For very large tables, read with <code>chunksize</code> and process each chunk, or push heavy aggregation into SQL to avoid transferring massive raw tables.</li> </ul> <pre><code>from sqlalchemy import create_engine\nengine = create_engine('postgresql://user:pass@host/db')\nfor chunk in pd.read_sql_query('SELECT * FROM big_table', engine, chunksize=10000):\n    process(chunk)\n</code></pre>"},{"location":"advance-python/pandas/pandas_create_df/#reading-from-web-apis","title":"Reading from web APIs","text":"<ul> <li>Fetch JSON with <code>requests</code>, handle pagination, and normalize responses into rows.</li> <li>Respect API rate limits and authentication.</li> </ul> <pre><code>import requests\nr = requests.get('https://api.example.com/data', params={'page': 1})\nrows = r.json()['results']\ndf = pd.json_normalize(rows)\n</code></pre>"},{"location":"advance-python/pandas/pandas_create_df/#working-with-very-large-files-streaming-patterns","title":"Working with very large files \u2014 streaming patterns","text":"<ul> <li> <p>Chunked processing</p> <ul> <li>Use <code>chunksize</code> in <code>read_csv</code> to iterate over the file and update aggregates, write partial results to disk, or populate a database. Never build a giant list of chunks in memory.</li> </ul> </li> </ul> <pre><code>agg = {}\nfor chunk in pd.read_csv('big.csv', chunksize=200_000, usecols=['country','amount']):\n    s = chunk.groupby('country')['amount'].sum()\n    for k,v in s.items():\n        agg[k] = agg.get(k, 0) + v\n</code></pre> <ul> <li> <p>Memory tricks</p> <ul> <li>Use <code>usecols</code> to drop unnecessary columns.</li> <li>Supply <code>dtype</code> to prevent mixed types and <code>object</code> columns.</li> <li>Convert repeated string columns to <code>category</code> immediately: <code>chunk['col'] = chunk['col'].astype('category')</code>.</li> <li>If you need random access or complex analytics on huge datasets, consider using a database, Dask, or reading Parquet with partitioned layout instead of a single giant CSV.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#writing-data-to_csv-to_parquet-to_sql-good-defaults","title":"Writing data (<code>to_csv</code>, <code>to_parquet</code>, <code>to_sql</code>) \u2014 good defaults","text":"<ul> <li> <p>CSV</p> <ul> <li><code>df.to_csv('out.csv', index=False)</code> \u2014 avoid writing the index unless you need it.</li> <li>Use <code>compression='gzip'</code> to save space: <code>df.to_csv('out.csv.gz', compression='gzip', index=False)</code>.</li> <li> <p>Parquet</p> </li> <li> <p><code>df.to_parquet('out.parquet', index=False)</code> \u2014 preserve dtypes and use compression.</p> </li> <li> <p>SQL</p> </li> <li> <p>Use <code>df.to_sql('table', engine, if_exists='append', index=False)</code> to append; for large writes consider batching and disabling indexes during load for speed.</p> </li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#common-parsing-errors-symptoms-and-fixes","title":"Common parsing errors, symptoms and fixes","text":"<ul> <li> <p>ParserError / tokenizing errors</p> </li> <li> <p>Symptom: <code>Error tokenizing data</code> or <code>EOF inside string</code>.</p> <ul> <li>Cause: inconsistent quoting, embedded newlines, bad separators.</li> <li>Fixes: try <code>engine='python'</code> with <code>sep</code> and <code>quoting=csv.QUOTE_NONE</code>, or open file and inspect bad lines; use <code>on_bad_lines='skip'</code> to skip and log problematic rows.</li> </ul> </li> <li> <p>UnicodeDecodeError</p> <ul> <li>Symptom: decoding error when reading file.</li> <li>Fix: try <code>encoding='latin-1'</code> or <code>encoding='utf-8-sig'</code> (handles BOM); set <code>encoding_errors='replace'</code> to avoid failures.</li> </ul> </li> <li> <p>Mixed dtypes in column</p> <ul> <li>Symptom: column shows <code>object</code> dtype or warnings about mixed types.</li> <li>Fix: pass <code>dtype</code> or <code>converters</code> to coerce types at read time, or sanitize values after reading and convert types explicitly.</li> </ul> </li> <li> <p>Dates read as strings or <code>NaT</code></p> <ul> <li>Symptom: dates are strings or missing after read.</li> <li>Fix: supply <code>parse_dates</code> or convert post-read with <code>pd.to_datetime(..., format=...)</code>.</li> </ul> </li> <li> <p>Large memory usage</p> <ul> <li>Symptom: your machine runs out of RAM or swaps.</li> <li>Fix: use <code>usecols</code>, <code>dtype</code> optimization, read with <code>chunksize</code>, or switch to Parquet / database / Dask.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#step-by-step-recipes-copy-run","title":"Step-by-step recipes (copy &amp; run)","text":"<ul> <li>Inspect the first few lines before loading</li> </ul> <pre><code># fast preview using Python (no Pandas)\nwith open('messy.csv', 'r', encoding='utf-8', errors='replace') as f:\n    for _ in range(20):\n        print(f.readline().rstrip('\\n'))\n</code></pre> <ul> <li>Load a messy CSV with tuned options</li> </ul> <pre><code>df = pd.read_csv(\n    'messy.csv',\n    sep=';',\n    decimal=',',\n    thousands='.',\n    encoding='latin-1',\n    parse_dates=['order_date'],\n    dayfirst=True,\n    na_values=['', 'NA', 'n/a', '-']\n)\n</code></pre> <ul> <li>Stream process and write partial aggregates</li> </ul> <pre><code>out_path = 'totals_by_region.csv'\nfirst_write = True\nfor chunk in pd.read_csv('big_sales.csv', chunksize=100_000, usecols=['region','amount'], dtype={'region':'category','amount':'float32'}):\n    sums = chunk.groupby('region')['amount'].sum().reset_index()\n    sums.to_csv(out_path, mode='a', header=first_write, index=False)\n    first_write = False\n</code></pre>"},{"location":"advance-python/pandas/pandas_create_df/#exercises-practical-friendly-to-non-programmers","title":"Exercises (practical, friendly to non-programmers)","text":"<ul> <li>Open a sample CSV in a plain text editor and identify: the delimiter, header row, and examples of missing values.</li> <li>Load a CSV with <code>pd.read_csv('file.csv', nrows=100)</code> to inspect types, then reload with <code>dtype</code> and <code>usecols</code> to reduce memory. Compare <code>df.memory_usage(deep=True)</code> before and after.</li> <li>Read an Excel workbook with multiple sheets using <code>sheet_name=None</code> and explore the dictionary of DataFrames.</li> <li>Read a large CSV using <code>chunksize=50000</code> and compute the total of a numeric column using chunked aggregation.</li> </ul>"},{"location":"advance-python/pandas/pandas_create_df/#troubleshooting-checklist-keep-this-handy","title":"Troubleshooting checklist (keep this handy)","text":"<ul> <li>Inspect the top 20 lines of the file manually when parsing fails.</li> <li>Try <code>encoding='latin-1'</code> or <code>encoding='utf-8-sig'</code> for Unicode errors.</li> <li>Use <code>usecols</code> to isolate problematic columns and save memory.</li> <li>If parser fails, try <code>engine='python'</code> and <code>on_bad_lines='skip'</code> to continue while you inspect bad lines.</li> <li>For performance: sample the file with <code>nrows=1000</code>, infer good <code>dtype</code> mappings, then reload full data with <code>dtype</code> specified.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/","title":"Pandas: Grouping, Aggregation &amp; Joins","text":""},{"location":"advance-python/pandas/pandas_grouping/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understand the purpose of grouping and aggregation: turning row\u2011level data into meaningful summaries.</li> <li>Use <code>groupby</code> patterns: <code>agg</code>, <code>transform</code>, <code>filter</code>, and <code>apply</code> and know when to use each.</li> <li>Compute multiple aggregations in one pass and produce tidy results ready for analysis or plotting.</li> <li>Join (merge) DataFrames with <code>merge</code>, <code>join</code>, and use <code>concat</code> for stacking tables; understand <code>how</code> and <code>on</code> semantics.</li> <li>Use specialized joins: <code>merge_asof</code>, <code>merge_ordered</code>, and database-style joins for real-world workflows.</li> <li>Understand performance and memory tradeoffs; use categorical keys and indexes to speed groupby and joins.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#why-grouping-and-joins-matter","title":"Why grouping and joins matter","text":"<ul> <li>Grouping converts detailed records into summaries (totals, averages, counts) that are easier to understand and visualize.</li> <li>Joins combine data from different tables (e.g., customer info + transactions) to enrich analysis.</li> <li>Real-world analysis often alternates between grouping and joining to assemble final datasets for reporting and modeling.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#the-groupby-concept-intuitive-explanation","title":"The <code>groupby</code> concept \u2014 intuitive explanation","text":"<ul> <li> <p><code>groupby</code> follows a three\u2011step mental model:</p> <ul> <li>split the data into groups by one or more keys,</li> <li>apply an aggregation or transformation to each group,</li> <li>combine the results back into a DataFrame or Series.</li> </ul> </li> <li> <p>Example intuition: \"group transactions by customer, sum the amounts\".</p> </li> </ul> <pre><code>grouped = df.groupby('customer_id')['amount'].sum()\n</code></pre> <ul> <li><code>groupby</code> does not modify the original DataFrame; it returns a <code>DataFrameGroupBy</code>/<code>SeriesGroupBy</code> object that you then aggregate/transform.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#common-groupby-operations-and-when-to-use-them","title":"Common <code>groupby</code> operations and when to use them","text":"<ul> <li> <p><code>agg</code> (aggregate)</p> <ul> <li>Use to compute summary statistics that reduce each group to a single value per column (sum, mean, count, min, max, custom functions).</li> </ul> </li> </ul> <pre><code># multiple aggregations in one call\nsummary = df.groupby('store').agg(\n    total_sales=('amount','sum'),\n    avg_order=('amount','mean'),\n    orders=('order_id','nunique')\n)\n</code></pre> <ul> <li> <p><code>transform</code></p> <ul> <li>Use when you want to produce an output aligned to the original index (same shape as input) \u2014 useful for group\u2011wise normalization or filling.</li> </ul> </li> </ul> <pre><code># subtract group mean from each row (demean)\ndf['amount_demeaned'] = df.groupby('store')['amount'].transform(lambda x: x - x.mean())\n</code></pre> <ul> <li> <p><code>filter</code></p> <ul> <li>Use to drop or keep entire groups based on group\u2011level criteria (e.g., keep stores with &gt;100 orders).</li> </ul> </li> </ul> <pre><code>big_stores = df.groupby('store').filter(lambda g: len(g) &gt; 100)\n</code></pre> <ul> <li> <p><code>apply</code></p> <ul> <li>Powerful but slower: runs a function on each group and concatenates results. Use when <code>agg</code>/<code>transform</code> cannot express the logic.</li> <li>Prefer <code>agg</code>/<code>transform</code> for performance when possible.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#multiple-aggregations-and-reshaping-results","title":"Multiple aggregations and reshaping results","text":"<ul> <li>Use named aggregations (Pandas &gt;= 0.25) to produce tidy columns with meaningful names. This avoids awkward column tuples.</li> </ul> <pre><code>agg = df.groupby(['region','product']).agg(\n    revenue=('amount','sum'),\n    avg_price=('price','mean'),\n    orders=('order_id','nunique')\n).reset_index()\n</code></pre> <ul> <li>If you use a list of aggregations without names, Pandas may produce MultiIndex columns. Use <code>reset_index()</code> and <code>rename</code> for clarity.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#grouped-time-series-and-resampling","title":"Grouped time series and resampling","text":"<ul> <li>For time series data, <code>resample</code> works like <code>groupby</code> but for fixed time bins (requires a <code>DatetimeIndex</code>).</li> </ul> <pre><code># daily totals from minute-level data\ndaily = df.resample('D')['amount'].sum()\n\n# combine resample with groupby: daily sales per store\ndaily_store = df.set_index('timestamp').groupby('store').resample('D')['amount'].sum().unstack(0)\n</code></pre> <ul> <li>Use <code>rolling</code> for moving-window statistics (e.g., 7\u2011day moving average) and <code>expanding</code> for cumulative calculations.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#joins-and-merges-the-basics","title":"Joins and merges \u2014 the basics","text":"<ul> <li><code>merge</code> is the most flexible and common way to join two tables. Think in SQL terms: <code>inner</code>, <code>left</code>, <code>right</code>, <code>outer</code>.</li> </ul> <pre><code># add customer details to transactions\ntx = transactions.merge(customers, on='customer_id', how='left')\n</code></pre> <ul> <li> <p><code>how</code> semantics:</p> <ul> <li><code>inner</code>: keep rows with keys in both tables.</li> <li><code>left</code>: keep all rows from left table, add matching rows from right or NaN.</li> <li><code>right</code>: symmetric to left.</li> <li><code>outer</code>: union of keys from both tables.</li> </ul> </li> <li> <p><code>on</code>, <code>left_on</code>, <code>right_on</code></p> <ul> <li>Use <code>on</code> when the key column has the same name in both tables. Use <code>left_on/right_on</code> for different names.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#index-vs-column-joins-and-join","title":"Index vs column joins and <code>join</code>","text":"<ul> <li><code>merge</code> works on columns; <code>join</code> is a convenience for index\u2011based joins.</li> </ul> <pre><code>left.set_index('id').join(right.set_index('id'), how='left')\n</code></pre> <ul> <li>When joining large tables repeatedly, setting an index on the join key can speed operations. Remember to <code>.reset_index()</code> if you need the key back as a column afterwards.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#ordered-joins-merge_asof-and-merge_ordered","title":"Ordered joins: <code>merge_asof</code> and <code>merge_ordered</code>","text":"<ul> <li><code>merge_asof</code> matches each row in the left table to the last row in the right table whose key is less than or equal to the left key \u2014 useful for time series alignment (e.g., match trades to most recent quote).</li> </ul> <pre><code>pd.merge_asof(buys.sort_values('time'), quotes.sort_values('time'), on='time', by='symbol', direction='backward')\n</code></pre> <ul> <li><code>merge_ordered</code> performs a merge that preserves ordering and can forward/backward fill keys; useful for longitudinal tables.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#concatenating-and-appending-tables","title":"Concatenating and appending tables","text":"<ul> <li><code>pd.concat</code> stacks tables vertically (<code>axis=0</code>) or horizontally (<code>axis=1</code>). Use when you have partitioned outputs (e.g., monthly files) to combine into one table.</li> </ul> <pre><code>combined = pd.concat([jan, feb, mar], ignore_index=True)\n</code></pre> <ul> <li>Use <code>ignore_index=True</code> if you do not want to keep original row indices.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#performance-tips-for-grouping-and-joins","title":"Performance tips for grouping and joins","text":"<ul> <li>Convert join/group keys to <code>category</code> dtype when there are many repeated values; this can reduce memory and speed up operations.</li> <li>For very large datasets, sort by the key and use <code>merge_asof</code> or database systems (SQL) to push joins into the database.</li> <li>Avoid expensive Python-level functions inside <code>groupby.apply</code>; prefer built-in aggregations or <code>transform</code>.</li> <li>Use <code>split-apply-combine</code> carefully: avoid creating many small DataFrames inside loops.</li> <li>When merging many small tables into a big one, consider building a dictionary keyed by join column and mapping values, or use database bulk operations.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#common-pitfalls-and-how-to-diagnose-them","title":"Common pitfalls and how to diagnose them","text":"<ul> <li>Unexpected duplicates after join: inspect the join keys to see if they are unique in the right table. Use <code>right.duplicated(subset=['key']).any()</code> to test.</li> <li>Memory blow-up during <code>merge</code>: ensure you <code>usecols</code> when reading data and convert dtypes to be compact before merging.</li> <li>Losing rows unintentionally: check <code>how</code> and key alignment; use <code>indicator=True</code> in <code>merge</code> to see where rows came from.</li> </ul> <pre><code>merged = left.merge(right, on='id', how='left', indicator=True)\nmerged['_merge'].value_counts()\n</code></pre> <ul> <li>Slow joins: try setting the join key as an index on both tables and use <code>join</code>, or perform join in a database engine.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#practical-examples-and-step-by-step-recipes","title":"Practical examples and step-by-step recipes","text":"<ul> <li>Summarize sales by store and category with multiple aggregations</li> </ul> <pre><code>summary = (\n    sales\n    .groupby(['store','category'])\n    .agg(total_revenue=('amount','sum'),\n         avg_price=('price','mean'),\n         orders=('order_id','nunique'))\n    .reset_index()\n)\n</code></pre> <ul> <li>Add customer demographic info to transactions and compute average basket value by segment</li> </ul> <pre><code>tx = transactions.merge(customers[['customer_id','segment']], on='customer_id', how='left')\navg_basket = tx.groupby('segment')['amount'].mean()\n</code></pre> <ul> <li>Align trades to most recent price quote using <code>merge_asof</code></li> </ul> <pre><code>quotes = quotes.sort_values(['symbol','time'])\nbuys = buys.sort_values(['symbol','time'])\nmatched = pd.merge_asof(buys, quotes, on='time', by='symbol', direction='backward')\n</code></pre> <ul> <li>Combine monthly parquet files into a single DataFrame</li> </ul> <pre><code>import pathlib\nfiles = list(pathlib.Path('data/').glob('sales_2025-*.parquet'))\nmonthly = [pd.read_parquet(f) for f in files]\nall_sales = pd.concat(monthly, ignore_index=True)\n</code></pre>"},{"location":"advance-python/pandas/pandas_grouping/#exercises-hands-on","title":"Exercises (hands-on)","text":"<ul> <li>Compute the top 5 products by revenue per region and present a tidy table with region, product, revenue.</li> <li>Given customer and transaction tables, merge them and find customers with transactions but missing demographics \u2014 count them and inspect sample rows.</li> <li>Simulate quote and trade data, then use <code>merge_asof</code> to attach the latest quote to each trade and compute slippage (trade price vs quote price).</li> <li>Read a directory of CSVs for each month, concatenate them, and compute year\u2011to\u2011date metrics using <code>groupby</code>.</li> </ul>"},{"location":"advance-python/pandas/pandas_grouping/#quick-checklist-for-safe-joins-and-group-operations","title":"Quick checklist for safe joins and group operations","text":"<ul> <li>Inspect keys for uniqueness before joining (<code>.duplicated()</code>)</li> <li>Convert keys to categorical if repeated many times</li> <li>Use <code>indicator=True</code> in debug runs to validate join behavior</li> <li>Reduce memory before merge by selecting required columns and compact dtypes</li> <li>Use <code>reset_index()</code> after groupby if you want keys back as columns</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/","title":"Pandas: Indexing, Advanced Selection &amp; Reshaping","text":""},{"location":"advance-python/pandas/pandas_indexing/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Know the difference between label\u2011based and position\u2011based indexing and when to use each.</li> <li>Use <code>loc</code>, <code>iloc</code>, <code>at</code>, <code>iat</code>, boolean masks, and <code>query</code> for efficient selection.</li> <li>Work safely with assignment to subsets of a DataFrame and avoid <code>SettingWithCopyWarning</code>.</li> <li>Use hierarchical indexes (<code>MultiIndex</code>) for multi\u2011level selection and learn helpful utilities like <code>xs</code> and <code>swaplevel</code>.</li> <li>Reshape tables using <code>stack</code>/<code>unstack</code>, <code>melt</code>/<code>pivot</code>, <code>pivot_table</code>, and combine with <code>groupby</code> for tidy workflows.</li> <li>Apply advanced selection patterns: partial string indexing for <code>DatetimeIndex</code>, <code>between_time</code>, <code>truncate</code>, and <code>merge_asof</code> for ordered joins.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#label-vs-position-the-foundational-distinction","title":"Label vs position \u2014 the foundational distinction","text":"<ul> <li>Labels refer to the index or column names (what you see printed). Positions are integer positions (0, 1, 2...).</li> <li><code>loc</code> is label\u2011based: <code>df.loc[row_label, col_label]</code>.</li> <li><code>iloc</code> is integer position\u2011based: <code>df.iloc[row_pos, col_pos]</code>.</li> <li>Use <code>at</code> and <code>iat</code> for fast scalar access:</li> </ul> <pre><code>val = df.at['row123', 'amount']   # label-based scalar access (fast)\nval2 = df.iat[5, 2]               # integer-based scalar access (fast)\n</code></pre> <ul> <li> <p>Why it matters:</p> </li> <li> <p>Using the wrong method can silently select unexpected rows/columns (e.g., integer labels that look like positions).</p> </li> <li>For clarity, use <code>loc</code> when you think in terms of labels and <code>iloc</code> when you want positional slicing.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#basic-selection-patterns","title":"Basic selection patterns","text":"<ul> <li> <p>Column access:</p> </li> <li> <p><code>df['col']</code> returns a <code>Series</code> for a column.</p> </li> <li> <p><code>df[['a','b']]</code> returns a <code>DataFrame</code> with selected columns.</p> </li> <li> <p>Row selection:</p> </li> <li> <p><code>df.loc['label']</code> or <code>df.iloc[0]</code> for a single row.</p> </li> <li>Slicing by label with <code>loc</code> is inclusive of the stop label; slicing by position with <code>iloc</code> follows Python semantics (stop exclusive).</li> </ul> <pre><code># label slice includes endpoint\ndf.loc['2020-01-01':'2020-01-31']\n# positional slice excludes endpoint\ndf.iloc[0:10]\n</code></pre> <ul> <li>Selecting rows and columns together:</li> </ul> <pre><code>sub = df.loc['id_1':'id_4', ['name','amount']]\n</code></pre>"},{"location":"advance-python/pandas/pandas_indexing/#boolean-indexing-masking","title":"Boolean indexing (masking)","text":"<ul> <li>Create boolean masks and apply them to select rows:</li> </ul> <pre><code>mask = df['amount'] &gt; 100\ndf_large = df[mask]\n</code></pre> <ul> <li>Combine conditions with <code>&amp;</code> / <code>|</code> remembering to parenthesize each condition:</li> </ul> <pre><code>df[(df['amount'] &gt; 100) &amp; (df['country'] == 'USA')]\n</code></pre> <ul> <li>Use <code>.loc</code> for assignment with boolean masks to avoid ambiguity:</li> </ul> <pre><code># preferred\ndf.loc[df['amount'] &lt; 0, 'amount'] = 0\n</code></pre> <ul> <li>Note: boolean indexing returns a copy of the matching rows (1\u2011D for Series, 2\u2011D for DataFrame). Assigning to that copy will not modify the original unless you use <code>.loc</code> on the original object.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#fancyadvanced-indexing-with-integer-arrays","title":"Fancy/advanced indexing with integer arrays","text":"<ul> <li>Use integer arrays to select arbitrary rows/columns by position. This is fancy indexing and returns a copy:</li> </ul> <pre><code>rows = [0, 2, 5]\ncols = [1, 3]\nsubset = df.iloc[rows, cols]\n</code></pre> <ul> <li>Remember that fancy indexing always makes a copy \u2014 changes to <code>subset</code> will not change <code>df</code>.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#at-iat-for-fast-scalar-access","title":"<code>at</code> / <code>iat</code> for fast scalar access","text":"<ul> <li>When you need to read or write a single value, prefer <code>at</code> (label) or <code>iat</code> (position) because they are optimized:</li> </ul> <pre><code># read\nv = df.at['rowA','colX']\n# set\ndf.at['rowA','colX'] = 42\n</code></pre> <ul> <li>These are much faster than <code>loc</code>/<code>iloc</code> for single\u2011element access in tight loops.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#query-and-eval-for-readable-boolean-selections","title":"<code>query</code> and <code>eval</code> for readable boolean selections","text":"<ul> <li><code>df.query('amount &gt; 100 and country == \"USA\"')</code> offers readable expressions using column names directly.</li> <li><code>eval</code> can evaluate expressions efficiently and with lower memory overhead for complex column operations.</li> <li>Use <code>@</code> to reference Python variables inside <code>query</code>.</li> </ul> <pre><code>threshold = 100\ndf.query('amount &gt; @threshold and country == \"USA\"')\n</code></pre> <ul> <li><code>query</code> is convenient and often clearer for non\u2011programmers, but be cautious with column names that have spaces or conflict with Python keywords.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#setting-values-safely-avoid-settingwithcopywarning","title":"Setting values safely \u2014 avoid <code>SettingWithCopyWarning</code>","text":"<ul> <li>Pandas sometimes cannot tell whether you are working on a view or a copy; this raises <code>SettingWithCopyWarning</code> when assigning through chained indexing like <code>df[cond]['col'] = val</code>.</li> <li>Always use <code>.loc</code> to be explicit about modifying the original DataFrame:</li> </ul> <pre><code># fragile (may warn and may not modify original)\ndf[df['x'] &gt; 0]['y'] = 0\n# safe\ndf.loc[df['x'] &gt; 0, 'y'] = 0\n</code></pre> <ul> <li>If you intentionally want an independent copy to mutate, call <code>.copy()</code> first:</li> </ul> <pre><code>sub = df[df['x']&gt;0].copy()\nsub['y'] = 0\n</code></pre>"},{"location":"advance-python/pandas/pandas_indexing/#partial-string-indexing-with-datetimeindex-and-index-convenience","title":"Partial string indexing with <code>DatetimeIndex</code> and <code>Index</code> convenience","text":"<ul> <li>If your DataFrame has a <code>DatetimeIndex</code>, you can slice by partial dates:</li> </ul> <pre><code># df indexed by datetime\ndf.loc['2020-01']   # all rows in January 2020\n</code></pre> <ul> <li>Use <code>between_time</code> to select rows by time of day and <code>truncate</code> to cut at endpoints:</li> </ul> <pre><code>df.between_time('09:00','17:00')\ndf.truncate(before='2020-01-01', after='2020-03-31')\n</code></pre> <ul> <li>These operations are concise and fast when the index is sorted and a <code>DatetimeIndex</code>.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#multiindex-hierarchical-index-powerful-but-needs-care","title":"MultiIndex (hierarchical index) \u2014 powerful but needs care","text":"<ul> <li><code>MultiIndex</code> lets you index on multiple levels (e.g., <code>country</code>, <code>city</code>, <code>store</code>). Create from columns or during grouping/pivoting.</li> </ul> <pre><code>mi = df.set_index(['country','city'])\n</code></pre> <ul> <li> <p>Helpful selection methods:</p> </li> <li> <p><code>mi.loc[('USA','Seattle')]</code> \u2014 select a specific tuple.</p> </li> <li><code>mi.xs('Seattle', level='city')</code> \u2014 cross\u2011section to select all entries for a sublevel.</li> <li> <p><code>mi.swaplevel(0,1)</code> and <code>mi.sort_index()</code> for reorganizing and ensuring efficient selection.</p> </li> <li> <p>Use <code>pd.IndexSlice</code> for slicing across multiple levels elegantly:</p> </li> </ul> <pre><code>idx = pd.IndexSlice\nmi.loc[idx['USA':'UK', 'London':'York'], :]  # slice across levels\n</code></pre> <ul> <li> <p>Pitfalls:</p> </li> <li> <p>Some operations return <code>Series</code> when selecting single columns; be explicit with <code>mi.reset_index()</code> if needed.</p> </li> <li>MultiIndex can make joins and merges more complex; prefer a flat index for simpler pipelines unless hierarchical indexing provides clear benefits.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#reshaping-stack-and-unstack","title":"Reshaping: <code>stack</code> and <code>unstack</code>","text":"<ul> <li><code>stack</code> pivots columns into the index (wide \u2192 long). <code>unstack</code> reverses the operation.</li> </ul> <pre><code>wide = pd.DataFrame({('sales','A'):[1,2], ('sales','B'):[3,4]}, index=['d1','d2'])\nwide.columns = pd.MultiIndex.from_tuples(wide.columns)\nlong = wide.stack(level=0)    # move outer column level into index\n</code></pre> <ul> <li>Use <code>stack</code>/<code>unstack</code> for grouped time series or multi\u2011level pivoting.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#reshaping-melt-pivot-and-pivot_table","title":"Reshaping: <code>melt</code>, <code>pivot</code>, and <code>pivot_table</code>","text":"<ul> <li><code>melt</code> converts wide tables to long (tidy) format \u2014 useful prior to groupby/aggregation or plotting.</li> <li><code>pivot</code> rearranges long data back to wide; <code>pivot_table</code> aggregates when there are duplicates.</li> </ul> <pre><code>long = df.melt(id_vars=['id','date'], value_vars=['sales_A','sales_B'], var_name='store', value_name='sales')\nwide = long.pivot(index=['id','date'], columns='store', values='sales')\nsummary = long.pivot_table(index='id', columns='store', values='sales', aggfunc='sum')\n</code></pre> <ul> <li><code>pivot_table</code> is more robust than <code>pivot</code> because it can aggregate duplicates instead of raising an error.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#combining-selection-and-reshaping-in-common-workflows","title":"Combining selection and reshaping in common workflows","text":"<ul> <li>Common pattern: read data \u2192 <code>melt</code> to long \u2192 <code>groupby</code> + <code>agg</code> \u2192 <code>pivot_table</code> or <code>unstack</code> for a report.</li> <li>Example: sales by store and month</li> </ul> <pre><code>long = df.melt(id_vars=['date','store'], value_vars=['sales'])\nmonthly = (long\n           .assign(month=lambda d: d['date'].dt.to_period('M'))\n           .groupby(['month','store'])['sales'].sum()\n           .unstack('store'))\n</code></pre>"},{"location":"advance-python/pandas/pandas_indexing/#joining-and-alignment-with-indexing-in-mind","title":"Joining and alignment with indexing in mind","text":"<ul> <li>Indexes are used for alignment during arithmetic and for <code>join</code>/<code>merge</code> operations.</li> <li><code>merge</code> is SQL\u2011like and works on columns; <code>join</code> is index\u2011based by default.</li> </ul> <pre><code># column-based join\nout = left.merge(right, on='id', how='left')\n# index-based join\nout = left.join(right, how='left')\n</code></pre> <ul> <li><code>merge_asof</code> performs ordered (time) joins that match nearest keys \u2014 useful for event alignment or combining time series with different timestamps.</li> </ul> <pre><code>pd.merge_asof(left.sort_values('time'), right.sort_values('time'), on='time', direction='backward')\n</code></pre>"},{"location":"advance-python/pandas/pandas_indexing/#performance-and-memory-considerations-for-indexingreshaping","title":"Performance and memory considerations for indexing/reshaping","text":"<ul> <li>Prefer selecting columns before filtering rows to reduce memory footprint: <code>df[['col1','col2']].loc[mask]</code> instead of selecting all columns then slicing.</li> <li>Ensure indexes used for frequent lookups are appropriate (<code>set_index('id')</code>) \u2014 lookups by index are much faster than by column scan.</li> <li>Use <code>inplace=False</code> operations (default) and assign the result; chained <code>inplace=True</code> is discouraged and is often removed from APIs.</li> <li>Sorting an index (<code>sort_index()</code>) before repeated slicing on labels improves performance.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#common-pitfalls-and-debugging-tips","title":"Common pitfalls and debugging tips","text":"<ul> <li><code>SettingWithCopyWarning</code>: avoid chained assignment; use <code>.loc</code> or <code>.copy()</code>.</li> <li>Off-by-one errors: remember <code>loc</code> includes end label, <code>iloc</code> excludes end position.</li> <li>Ambiguous integer index: if your index is integers that look like positions, prefer <code>loc</code> with labels or convert index to <code>RangeIndex</code> for positional semantics.</li> <li>Unexpected dtype changes after unstack/pivot: check <code>dtypes</code> and coerce explicitly if needed.</li> </ul>"},{"location":"advance-python/pandas/pandas_indexing/#mini-recipes-copy-run","title":"Mini recipes (copy &amp; run)","text":"<ul> <li>Select rows by label range and specific columns</li> </ul> <pre><code>report = df.loc['2021-01-01':'2021-01-31', ['store','amount']]\n</code></pre> <ul> <li>Filter, assign safely, and save</li> </ul> <pre><code>mask = (df['amount'] &gt; 100) &amp; (df['country']=='USA')\ndf.loc[mask, 'flag_high'] = True\ndf.to_parquet('high_sales.parquet')\n</code></pre> <ul> <li>Create MultiIndex from columns and select a cross\u2011section</li> </ul> <pre><code>mi = df.set_index(['country','city'])\nmi.xs('Mumbai', level='city')\n</code></pre> <ul> <li>Melt wide sales table and compute monthly totals</li> </ul> <pre><code>long = wide.reset_index().melt(id_vars=['date'], value_vars=['sales_A','sales_B'], var_name='store', value_name='sales')\nmonthly = long.groupby([long['date'].dt.to_period('M'),'store'])['sales'].sum().unstack('store')\n</code></pre>"},{"location":"advance-python/pandas/pandas_indexing/#exercises-practical","title":"Exercises (practical)","text":"<ul> <li>Using a time\u2011indexed sales DataFrame, select all rows for March 2020 and compute daily totals.</li> <li>Given a DataFrame with columns <code>['id','region','Q1','Q2','Q3','Q4']</code>, reshape to long format with <code>melt</code> and compute total quarterly sales per region.</li> <li>Create a <code>MultiIndex</code> on <code>['country','city','store']</code> and practice selecting different levels using <code>loc</code>, <code>xs</code>, and <code>IndexSlice</code>.</li> <li>Demonstrate <code>merge_asof</code> by aligning trade events (orders) with the latest price quote before each order.</li> </ul>"},{"location":"advance-python/pandas/pandas_intro/","title":"Pandas Essentials &amp; Data Model","text":""},{"location":"advance-python/pandas/pandas_intro/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understand what Pandas is and why it complements NumPy for tabular data tasks.</li> <li>Know the two core data structures: <code>Series</code> and <code>DataFrame</code>, and when to use each.</li> <li>Create <code>Series</code> and <code>DataFrame</code> from lists, NumPy arrays, and dictionaries.</li> <li>Inspect and manipulate <code>index</code>, <code>columns</code>, and <code>dtypes</code> (including <code>Categorical</code> and datetime types).</li> <li>Understand alignment, broadcasting-like behavior, and basic memory considerations.</li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#what-is-pandas-and-when-to-use-it","title":"What is Pandas and when to use it","text":"<ul> <li>Pandas is a high-level library for working with structured/tabular data in Python.</li> <li>It builds on NumPy but provides labelled axes (<code>index</code>, <code>columns</code>), richer IO, and convenient data manipulation primitives.</li> <li>Use Pandas for data cleaning, transformation, exploratory data analysis, basic stats, and preparing data for machine learning.</li> </ul> <p>Checkout official documentation at https://pandas.pydata.org/docs/index.html</p>"},{"location":"advance-python/pandas/pandas_intro/#core-data-structures","title":"Core data structures","text":"<ul> <li> <p><code>Series</code></p> <ul> <li>1D labeled array that holds a sequence of values and an associated <code>index</code>.</li> <li>Useful for time series, a single column of data, or results of computations.</li> </ul> </li> <li> <p><code>DataFrame</code></p> <ul> <li>2D labeled tabular data structure with rows (<code>index</code>) and columns (<code>columns</code>).</li> <li>Each column is effectively a <code>Series</code> with a shared index.</li> </ul> </li> <li> <p><code>Index</code> objects</p> <ul> <li>Immutable labels for axes. There are specialised index types (<code>RangeIndex</code>, <code>DatetimeIndex</code>, <code>CategoricalIndex</code>).</li> <li>Indexes enable fast alignment and lookups.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#import-convention","title":"Import convention","text":"<pre><code>import pandas as pd\n</code></pre> <ul> <li><code>pd</code> is the standard alias. Make sure Pandas is installed (<code>pip install pandas</code> or <code>conda install pandas</code>).</li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#creating-series-and-dataframes-examples","title":"Creating Series and DataFrames (examples)","text":"<ul> <li>From a Python list or NumPy array:</li> </ul> <pre><code>import numpy as np\nimport pandas as pd\n\ns = pd.Series([10, 20, 30])                 # index defaults to RangeIndex(0, 3)\narr = np.array([1.0, 2.0, 3.0])\ns2 = pd.Series(arr, index=['a','b','c'])\n</code></pre> <ul> <li>From a dictionary (keys \u2192 index or columns):</li> </ul> <pre><code>data = {'name': ['alice', 'bob'], 'age': [25, 30]}\ndf = pd.DataFrame(data)\n# or create a Series from mapping index-&gt;value\ns3 = pd.Series({'a': 1, 'b': 2, 'c': 3})\n</code></pre> <ul> <li>From a list of dicts (orient rows):</li> </ul> <pre><code>df2 = pd.DataFrame([{'x':1,'y':2}, {'x':3,'y':4}])\n</code></pre> <ul> <li>From NumPy structured arrays or other tabular sources (CSV, SQL, Excel):</li> </ul> <pre><code>df_csv = pd.read_csv('file.csv')\n</code></pre>"},{"location":"advance-python/pandas/pandas_intro/#inspecting-data","title":"Inspecting data","text":"<ul> <li> <p>Attributes and quick look:</p> <ul> <li><code>df.head()</code>, <code>df.tail()</code> \u2014 peek at rows.</li> <li><code>df.shape</code> \u2014 (rows, columns).</li> <li><code>df.dtypes</code> \u2014 dtype per column.</li> <li><code>df.info()</code> \u2014 compact summary including memory usage and non-null counts.</li> <li><code>df.describe()</code> \u2014 summary statistics for numeric columns.</li> </ul> </li> <li> <p>Accessing columns and rows:</p> <ul> <li><code>df['col']</code> or <code>df.col</code> (dot notation works for simple names) \u2192 returns a <code>Series</code>.</li> <li><code>df[['a','b']]</code> \u2192 returns a <code>DataFrame</code> with selected columns.</li> <li><code>df.loc[label]</code> and <code>df.iloc[position]</code> \u2014 label- and integer-location-based indexing (expanded in later chapters).</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#indexes-and-alignment","title":"Indexes and alignment","text":"<ul> <li>Index labels align automatically in arithmetic and joins. This means operations between two <code>Series</code> or <code>DataFrame</code> objects match rows/columns by label, not by position.</li> </ul> <pre><code>s1 = pd.Series([1,2], index=['a','b'])\ns2 = pd.Series([10,20], index=['b','c'])\ns1 + s2  # result index -&gt; union of labels: a,b,c (NaN where missing)\n</code></pre> <ul> <li> <p>Reindexing:</p> <ul> <li><code>s.reindex(new_index)</code> changes the labels and inserts <code>NaN</code> for missing entries.</li> <li><code>df.set_index('col')</code> and <code>df.reset_index()</code> convert columns to/from index.</li> </ul> </li> <li> <p>Index types matter:</p> <ul> <li><code>RangeIndex</code> is compact and efficient for default integer indexes.</li> <li><code>DatetimeIndex</code> enables fast date-based slicing and resampling.</li> <li><code>Categorical</code> dtype saves memory and speeds up groupby/joins when there are repeated values.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#dtypes-and-memory-considerations","title":"Dtypes and memory considerations","text":"<ul> <li> <p>Column-wise dtypes are crucial for performance and memory:</p> <ul> <li><code>int64</code>, <code>float64</code>, <code>bool</code>, <code>object</code> (python objects / strings), <code>category</code>, <code>datetime64[ns]</code>.</li> <li>Avoid <code>object</code> columns for repeated string values \u2014 use <code>category</code> if the set of unique values is small relative to rows.</li> <li>Convert numeric columns to smaller integer types (<code>int32</code> / <code>float32</code>) when appropriate to save memory.</li> <li><code>df.memory_usage(deep=True)</code> shows memory used per column (deep inspects object arrays).</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#missing-data-nan-pdna-and-null-handling","title":"Missing data (<code>NaN</code>, <code>pd.NA</code>) and null handling","text":"<ul> <li> <p>Pandas uses <code>NaN</code> for floats and <code>pd.NA</code> (nullable dtypes) for newer nullable integer/boolean/string types.</p> </li> <li> <p>Common operations:</p> <ul> <li><code>df.isna()</code>, <code>df.notna()</code> \u2014 boolean masks for missingness.</li> <li><code>df.dropna()</code> \u2014 drop rows/columns with missing values.</li> <li><code>df.fillna(value)</code> \u2014 fill missing values.</li> </ul> </li> <li> <p>Best practices:</p> <ul> <li>Inspect missingness early with <code>df.info()</code> and <code>df.isna().sum()</code>.</li> <li>Prefer dtype-aware nullable integers (<code>Int64</code>) if you need integer columns with missing values.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#column-operations-and-vectorized-behavior","title":"Column operations and vectorized behavior","text":"<ul> <li>Column arithmetic is vectorized (leverages NumPy under the hood):</li> </ul> <pre><code>df['total'] = df['price'] * df['quantity']\n</code></pre> <ul> <li> <p>Broadcasting-like behavior applies across aligned indexes. Mixing mismatched indexes yields <code>NaN</code> where labels are missing.</p> </li> <li> <p>Adding a scalar to a column is fast and does not change the index:</p> </li> </ul> <pre><code>df['price'] += 1.5\n</code></pre>"},{"location":"advance-python/pandas/pandas_intro/#views-vs-copies-important-subtlety","title":"Views vs copies (important subtlety)","text":"<ul> <li>Slicing a <code>DataFrame</code> or selecting a single column often returns a view or a copy depending on context \u2014 pandas may warn with a <code>SettingWithCopyWarning</code> when chained assignment could fail.</li> <li>Avoid chained assignment like <code>df[df['x']&gt;0]['y'] = 0</code> \u2014 prefer <code>loc</code> assignment:</li> </ul> <pre><code># fragile (may raise SettingWithCopyWarning)\ndf[df['x']&gt;0]['y'] = 0\n# preferred\ndf.loc[df['x']&gt;0, 'y'] = 0\n</code></pre> <ul> <li>When in doubt, use <code>df.copy()</code> to get an explicit copy you can mutate safely.</li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#basic-io-quick-recipes-teaser-for-chapter-2","title":"Basic I/O quick recipes (teaser for Chapter 2)","text":"<ul> <li>Read CSV:</li> </ul> <pre><code>df = pd.read_csv('data.csv', parse_dates=['date_col'])\n</code></pre> <ul> <li>Write to CSV/Excel/Parquet:</li> </ul> <pre><code>df.to_csv('out.csv', index=False)\ndf.to_parquet('out.parquet')\n</code></pre> <ul> <li>Use <code>dtype=</code> and <code>parse_dates=</code> options on read functions to control memory and parsing.</li> </ul>"},{"location":"advance-python/pandas/pandas_intro/#quick-practical-examples","title":"Quick practical examples","text":"<ul> <li>Creating a small DataFrame and computing group totals:</li> </ul> <pre><code>df = pd.DataFrame({'city': ['A','A','B'], 'sales': [100,150,200]})\ngrouped = df.groupby('city')['sales'].sum()\n</code></pre> <ul> <li>Merging two DataFrames (teaser for later):</li> </ul> <pre><code>left = pd.DataFrame({'id':[1,2], 'x':[10,20]})\nright = pd.DataFrame({'id':[2,3], 'y':[30,40]})\nmerged = left.merge(right, on='id', how='outer')\n</code></pre>"},{"location":"advance-python/pandas/pandas_intro/#exercises","title":"Exercises","text":"<ul> <li>Create a <code>DataFrame</code> from a list of dictionaries and inspect <code>dtypes</code>, <code>shape</code>, and <code>memory_usage</code>.</li> <li>Convert a string column with repeated values into <code>category</code> dtype and observe memory usage before and after.</li> <li>Demonstrate automatic alignment by adding two <code>Series</code> with different indexes and explain the result.</li> <li>Practice safe assignment using <code>loc</code> instead of chained assignment; show a case that triggers <code>SettingWithCopyWarning</code> and fix it.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/","title":"Pandas: Time Series, Window Functions &amp; Performance Engineering","text":""},{"location":"advance-python/pandas/pandas_time_series/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understand Pandas' time series types and <code>DatetimeIndex</code> basics.</li> <li>Index and slice data by time efficiently using date strings and partial indexing.</li> <li>Use <code>resample</code>, <code>rolling</code>, <code>expanding</code>, and <code>ewm</code> (exponential windows) for common time\u2011based summaries.</li> <li>Align and shift time series with <code>shift</code>, <code>tshift</code> (legacy), and <code>asof</code> patterns.</li> <li>Handle irregular timestamps: interpolation, reindexing, forward/backward fill, and up/down sampling.</li> <li>Apply common analyses: moving averages, rolling correlations, cumulative sums, and lag features for modeling.</li> <li>Learn practical performance engineering: dtype choice, memory profiling, chunked processing, Parquet, Dask, vectorization, and avoiding common slow patterns.</li> <li>Know how to productionize pipelines: checkpointing, monitoring, and basic parallel patterns.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#time-series-basics-and-datetimeindex","title":"Time series basics and <code>DatetimeIndex</code>","text":"<ul> <li> <p>Time-aware dtype:</p> <ul> <li>Pandas uses <code>datetime64[ns]</code> for timestamps and <code>Timedelta</code> for durations. Use <code>pd.to_datetime()</code> to convert strings.</li> </ul> </li> <li> <p>Creating and setting a <code>DatetimeIndex</code>:</p> </li> </ul> <pre><code>df['ts'] = pd.to_datetime(df['timestamp'])\ndf = df.set_index('ts').sort_index()\n</code></pre> <ul> <li>Partial date indexing is convenient and readable:</li> </ul> <pre><code># selects all rows in January 2021\ndf.loc['2021-01']\n# selects a full day\ndf.loc['2021-01-15']\n</code></pre> <ul> <li> <p>Ensure the index is sorted for many operations (<code>df.sort_index()</code>); some functions rely on monotonic time.</p> </li> <li> <p>Inspect frequency and gaps:</p> </li> </ul> <pre><code>df.index.freq          # may be None for irregular data\npd.infer_freq(df.index)\n</code></pre>"},{"location":"advance-python/pandas/pandas_time_series/#resampling-changing-the-frequency","title":"Resampling \u2014 changing the frequency","text":"<ul> <li><code>resample</code> groups by fixed time bins (like <code>groupby</code> but for time):</li> </ul> <pre><code># convert minute-level to hourly sums\nhourly = df.resample('H')['value'].sum()\n\n# resample with custom aggregation and fill\ndaily = df.resample('D').agg({'value':'sum', 'temperature':'mean'})\ndaily = daily.fillna(method='ffill')\n</code></pre> <ul> <li> <p>Upsampling vs downsampling:</p> <ul> <li>Downsampling aggregates many rows into fewer bins (e.g., minute \u2192 hour) \u2014 use <code>sum</code>, <code>mean</code>, etc.</li> <li>Upsampling creates higher frequency rows (e.g., daily \u2192 hourly) \u2014 you must decide how to fill new rows (<code>ffill</code>, <code>bfill</code>, <code>interpolate</code>).</li> </ul> </li> <li> <p>Use <code>label</code> and <code>closed</code> arguments to control which bin edge is used for labeling and inclusion.</p> </li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#rolling-expanding-and-exponentially-weighted-windows","title":"Rolling, expanding and exponentially weighted windows","text":"<ul> <li><code>rolling(window='7D')</code> or <code>rolling(window=7)</code> computes statistics over a sliding window.</li> </ul> <pre><code># 7-day moving average (on daily index)\ndf['ma7'] = df['value'].rolling(window=7, min_periods=1).mean()\n\n# rolling std and correlation\ndf['std7'] = df['value'].rolling(7).std()\ndf['corr7'] = df['value'].rolling(7).corr(df['other'])\n</code></pre> <ul> <li><code>expanding()</code> computes cumulative statistics from the start:</li> </ul> <pre><code>df['cummean'] = df['value'].expanding().mean()\n</code></pre> <ul> <li>Exponential moving windows (<code>ewm</code>) weight recent observations more:</li> </ul> <pre><code>df['ewm12'] = df['value'].ewm(span=12, adjust=False).mean()\n</code></pre> <ul> <li> <p>Use <code>min_periods</code> to control how many observations are required before yielding a result.</p> </li> <li> <p>For time\u2011aware rolling windows use <code>rolling('7D')</code> on a <code>DatetimeIndex</code> which counts time span rather than number of rows.</p> </li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#shifts-differences-and-lag-features","title":"Shifts, differences and lag features","text":"<ul> <li><code>shift()</code> moves data forward/backward by periods \u2014 useful for lag features and differences.</li> </ul> <pre><code>df['lag1'] = df['value'].shift(1)\ndf['diff1'] = df['value'] - df['lag1']\n</code></pre> <ul> <li> <p>For time\u2011based shifts use <code>shift(freq='1D')</code> to shift the index.</p> </li> <li> <p>Beware of missing values introduced by shift \u2014 handle by filling or dropping depending on modeling needs.</p> </li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#aligning-irregular-time-series-interpolation-and-filling","title":"Aligning irregular time series, interpolation and filling","text":"<ul> <li>Reindex to a desired frequency and fill:</li> </ul> <pre><code>idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq='H')\ndf_hourly = df.reindex(idx)\ndf_hourly['value'] = df_hourly['value'].interpolate(method='time')\n</code></pre> <ul> <li> <p>Interpolation methods:</p> <ul> <li><code>method='time'</code> (time-aware linear interpolation), <code>'linear'</code>, <code>'polynomial'</code>, <code>'nearest'</code>.</li> <li>Use <code>limit</code> to control maximum consecutive NaNs to fill.</li> </ul> </li> <li> <p>Forward/backward fill:</p> </li> </ul> <pre><code>df.ffill(limit=2)\n</code></pre> <ul> <li>When working with measurements, prefer interpolation that respects domain knowledge (e.g., piecewise linear for sensor readings, not cubic splines without reason).</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#time-zone-handling-and-dst","title":"Time zone handling and DST","text":"<ul> <li>Localize naive timestamps and convert between zones:</li> </ul> <pre><code># localize naive index as UTC then convert to a zone\ndf.index = df.index.tz_localize('UTC').tz_convert('Asia/Kolkata')\n</code></pre> <ul> <li>Be careful when resampling across DST transitions \u2014 prefer UTC for storage and convert to local timezone for display.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#seasonal-decomposition-and-basic-time-series-diagnostics","title":"Seasonal decomposition and basic time series diagnostics","text":"<ul> <li>Simple decomposition using <code>statsmodels</code> (optional dependency):</li> </ul> <pre><code>from statsmodels.tsa.seasonal import seasonal_decompose\nres = seasonal_decompose(df['value'].asfreq('D'), model='additive')\nres.plot()\n</code></pre> <ul> <li>Autocorrelation and partial autocorrelation (ACF/PACF) help identify lags to include in models; use <code>statsmodels.graphics.tsaplots.plot_acf</code>.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#feature-engineering-for-time-series-models","title":"Feature engineering for time series models","text":"<ul> <li>Create lag features, rolling statistics, time-of-day and day-of-week indicators, and holiday flags.</li> </ul> <pre><code>df['hour'] = df.index.hour\ndf['dow'] = df.index.dayofweek\ndf['lag24'] = df['value'].shift(24)\ndf['rolling7_mean'] = df['value'].rolling(7).mean()\n</code></pre> <ul> <li> <p>Beware of look\u2011ahead bias: build features only using information that would have been available at prediction time.</p> </li> <li> <p>For categorical cyclical features (hour of day, day of week) consider encoding as sine/cosine pairs for many models.</p> </li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#working-with-irregular-event-series-merge_asof-and-event-alignment","title":"Working with irregular event series: <code>merge_asof</code> and event alignment","text":"<ul> <li>Use <code>merge_asof</code> to align events to the most recent prior state (e.g., attach last price quote to each trade). Sort both tables by time and use <code>by</code> for per\u2011symbol matching.</li> </ul> <pre><code>pd.merge_asof(trades.sort_values('time'), quotes.sort_values('time'), on='time', by='symbol')\n</code></pre> <ul> <li>For nearest neighbor matching in time, <code>direction='nearest'</code> is available.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#performance-engineering-practical-tactics","title":"Performance engineering \u2014 practical tactics","text":"<ul> <li>Inspect memory usage:</li> </ul> <pre><code>df.memory_usage(deep=True)\n</code></pre> <ul> <li> <p>Choose efficient dtypes:</p> <ul> <li>Use <code>int32</code> / <code>float32</code> if precision allows.</li> <li>Use <code>category</code> for repeated strings (IDs, symbols).</li> <li>Use nullable dtypes (<code>Int64</code>, <code>boolean</code>) when you need to preserve missing data without <code>object</code> dtype.</li> </ul> </li> <li> <p>Avoid <code>object</code> dtype where possible: it stores generic Python objects and is slow to process.</p> </li> <li> <p>Read and write using efficient binary formats (Parquet, Feather) for repeated analysis; they preserve dtypes and are faster than CSV.</p> </li> <li> <p>Vectorize heavy computations using NumPy operations instead of Python loops.</p> </li> <li> <p>Use <code>eval()</code> and <code>query()</code> for some expressions \u2014 they can be faster and use less memory by avoiding intermediate Python objects.</p> </li> <li> <p>Profile where the time is spent:</p> <ul> <li>Use <code>%timeit</code> in notebooks for quick timings.</li> <li>Use <code>cProfile</code> or <code>line_profiler</code> for deeper investigation.</li> </ul> </li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#scaling-beyond-a-single-machine","title":"Scaling beyond a single machine","text":"<ul> <li> <p>If data does not fit in memory, consider:</p> <ul> <li>Dask DataFrame \u2014 familiar Pandas-like API but operates out-of-core and supports distributed execution.</li> <li>Incremental/streaming approaches using <code>chunksize</code> or databases.</li> <li>Spark/PySpark if you have a cluster and need wide ecosystem integration.</li> </ul> </li> <li> <p>Typical pattern with Dask:</p> </li> </ul> <pre><code>import dask.dataframe as dd\nddf = dd.read_parquet('s3://bucket/path/*.parquet')\n# apply rolling/window operations carefully \u2014 some operations require known partitioning and indexing\n</code></pre> <ul> <li>For simple parallelism, use <code>concurrent.futures</code> to process independent time partitions (e.g., per symbol) and then concatenate results. Beware of memory duplication.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#checkpointing-and-reproducibility-in-pipelines","title":"Checkpointing and reproducibility in pipelines","text":"<ul> <li>Save intermediate transforms (Parquet) frequently so failed runs can resume from a checkpoint instead of restarting from raw data.</li> <li>Record the index frequency, timezone, and any resampling choices in pipeline metadata.</li> <li>Validate invariants after each major step (row counts, ranges, no negative values where impossible).</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#recipes-common-tasks-copy-run","title":"Recipes: common tasks (copy &amp; run)","text":"<ul> <li>Compute 7-day rolling average on daily data and save to Parquet</li> </ul> <pre><code>df = df.set_index('date').sort_index()\ndf['ma7'] = df['value'].rolling(window=7, min_periods=1).mean()\ndf.to_parquet('daily_with_ma7.parquet')\n</code></pre> <ul> <li>Upsample daily to hourly and interpolate values</li> </ul> <pre><code>hr_idx = pd.date_range(df.index.min(), df.index.max(), freq='H')\ndf_hr = df.reindex(hr_idx)\ndf_hr['value'] = df_hr['value'].interpolate(method='time')\n</code></pre> <ul> <li>Compute lag features for modeling (lags 1..3)</li> </ul> <pre><code>for lag in range(1,4):\n    df[f'lag_{lag}'] = df['value'].shift(lag)\n</code></pre> <ul> <li>Chunked processing: compute monthly aggregates on a large CSV using <code>chunksize</code></li> </ul> <pre><code>import pandas as pd\nfrom collections import defaultdict\nsums = defaultdict(float)\nfor chunk in pd.read_csv('big_events.csv', parse_dates=['time'], chunksize=200_000):\n    chunk = chunk.set_index('time').resample('M')['value'].sum()\n    for idx, val in chunk.items():\n        sums[idx.to_timestamp()] += val\nmonthly = pd.Series(sums).sort_index()\n</code></pre>"},{"location":"advance-python/pandas/pandas_time_series/#monitoring-and-alerting-for-production-jobs","title":"Monitoring and alerting for production jobs","text":"<ul> <li>Log progress and anomaly counts (missing data, imputed rows, dropped rows) during ETL.</li> <li>Emit metrics (rows processed per second, time per chunk) to monitoring systems.</li> <li>Add simple health checks: ensure no data skew, check for new/unexpected categories in categorical columns.</li> </ul>"},{"location":"advance-python/pandas/pandas_time_series/#exercises-practical","title":"Exercises (practical)","text":"<ul> <li>Given a minute\u2011level sensor dataset, compute hourly means, 1\u2011hour rolling std, and create lag features for the previous 24 hours. Evaluate how many NaNs are introduced and propose a handling strategy.</li> <li>Simulate trade and quote streams and use <code>merge_asof</code> to attach quotes to trades. Compute average slippage by symbol and time of day.</li> <li>Timezone exercise: convert a UTC index to a local timezone, resample to daily and compare results near DST transitions.</li> <li>Benchmark: read a 5 GB Parquet file, compute a small aggregation (groupby + sum) and time it. Experiment with casting to <code>category</code> for the group key and measure the speedup.</li> </ul>"},{"location":"intro-to-python/conditions/","title":"Conditions in Python","text":""},{"location":"intro-to-python/conditions/#what-are-conditions","title":"What are Conditions?","text":"<p>Conditions are programming constructs that allow your code to make decisions and execute different blocks of code based on whether certain conditions are true or false. Python uses <code>if</code>, <code>elif</code>, and <code>else</code> statements to implement conditional logic, enabling programs to respond dynamically to different situations.</p>"},{"location":"intro-to-python/conditions/#basic-if-statement","title":"Basic If Statement","text":"<p>The <code>if</code> statement executes a block of code only when a specified condition evaluates to <code>True</code>.</p>"},{"location":"intro-to-python/conditions/#basic-if-syntax","title":"Basic If Syntax","text":"<pre><code># Basic structure\nif condition:\n    # code to execute if condition is True\n    pass\n</code></pre>"},{"location":"intro-to-python/conditions/#simple-if-examples","title":"Simple If Examples","text":"<p>Basic comparisons: <pre><code>age = 18\nif age &gt;= 18:\n    print(\"You are an adult\")\n\nscore = 85\nif score &gt;= 90:\n    print(\"Excellent score!\")\n\ntemperature = 30\nif temperature &gt; 25:\n    print(\"It's a warm day\")\n    print(\"Consider wearing light clothes\")\n</code></pre>  The condition after <code>if</code> must evaluate to a boolean value (<code>True</code> or <code>False</code>). If <code>True</code>, the indented code block executes. Indentation is crucial in Python - it defines which code belongs to the if statement.</p> <p>Working with variables: <pre><code>username = \"admin\"\nif username == \"admin\":\n    print(\"Welcome, administrator!\")\n\npassword = \"secret123\"\nif password == \"secret123\":\n    print(\"Login successful\")\n\nhas_permission = True\nif has_permission:\n    print(\"Access granted\")\n\nitems_in_cart = 5\nif items_in_cart &gt; 0:\n    print(f\"You have {items_in_cart} items in your cart\")\n</code></pre>  Conditions can check variable values, compare strings, test boolean variables, or evaluate any expression that returns <code>True</code> or <code>False</code>.</p>"},{"location":"intro-to-python/conditions/#if-else-statement","title":"If-Else Statement","text":"<p>The <code>else</code> statement provides an alternative block of code to execute when the <code>if</code> condition is <code>False</code>.</p>"},{"location":"intro-to-python/conditions/#basic-if-else-syntax","title":"Basic If-Else Syntax","text":"<pre><code># Basic structure\nif condition:\n    # code to execute if condition is True\nelse:\n    # code to execute if condition is False\n</code></pre>"},{"location":"intro-to-python/conditions/#if-else-examples","title":"If-Else Examples","text":"<p>Simple either/or decisions: <pre><code>age = 16\nif age &gt;= 18:\n    print(\"You can vote\")\nelse:\n    print(\"You cannot vote yet\")\n\ntemperature = 15\nif temperature &gt; 20:\n    print(\"It's warm outside\")\nelse:\n    print(\"It's cool outside\")\n    print(\"You might need a jacket\")\n\nnumber = 7\nif number % 2 == 0:\n    print(f\"{number} is even\")\nelse:\n    print(f\"{number} is odd\")\n</code></pre>  Exactly one of the two blocks will execute - either the <code>if</code> block (when condition is <code>True</code>) or the <code>else</code> block (when condition is <code>False</code>).</p> <p>User input validation: <pre><code>user_input = input(\"Enter a number: \")\nif user_input.isdigit():\n    number = int(user_input)\n    print(f\"You entered the number: {number}\")\nelse:\n    print(\"That's not a valid number\")\n\npassword = input(\"Enter password: \")\nif len(password) &gt;= 8:\n    print(\"Password is strong enough\")\nelse:\n    print(\"Password must be at least 8 characters long\")\n</code></pre>  If-else is perfect for validation scenarios where you need to handle both valid and invalid cases.</p>"},{"location":"intro-to-python/conditions/#if-elif-else-statement","title":"If-Elif-Else Statement","text":"<p>The <code>elif</code> (short for \"else if\") allows you to check multiple conditions in sequence.</p>"},{"location":"intro-to-python/conditions/#basic-if-elif-else-syntax","title":"Basic If-Elif-Else Syntax","text":"<pre><code># Basic structure\nif condition1:\n    # code for condition1\nelif condition2:\n    # code for condition2\nelif condition3:\n    # code for condition3\nelse:\n    # code if no condition is True\n</code></pre>"},{"location":"intro-to-python/conditions/#multiple-condition-examples","title":"Multiple Condition Examples","text":"<p>Grade classification: <pre><code>score = 87\nif score &gt;= 90:\n    grade = \"A\"\n    print(\"Excellent work!\")\nelif score &gt;= 80:\n    grade = \"B\"\n    print(\"Good job!\")\nelif score &gt;= 70:\n    grade = \"C\"\n    print(\"Satisfactory\")\nelif score &gt;= 60:\n    grade = \"D\"\n    print(\"Needs improvement\")\nelse:\n    grade = \"F\"\n    print(\"Please see instructor\")\n\nprint(f\"Your grade is: {grade}\")\n</code></pre>  Conditions are checked in order from top to bottom. Once a condition is <code>True</code>, its code block executes and the remaining conditions are skipped.</p> <p>Weather responses: <pre><code>temperature = 32\nif temperature &gt; 35:\n    print(\"It's very hot! Stay hydrated.\")\n    clothing = \"shorts and t-shirt\"\nelif temperature &gt; 25:\n    print(\"It's warm and pleasant.\")\n    clothing = \"light clothing\"\nelif temperature &gt; 15:\n    print(\"It's cool but comfortable.\")\n    clothing = \"long sleeves\"\nelif temperature &gt; 5:\n    print(\"It's cold. Bundle up!\")\n    clothing = \"warm jacket\"\nelse:\n    print(\"It's freezing! Stay indoors if possible.\")\n    clothing = \"heavy winter coat\"\n\nprint(f\"Recommended clothing: {clothing}\")\n</code></pre>  Each <code>elif</code> provides an additional condition to check. You can have as many <code>elif</code> statements as needed.</p> <p>User menu system: <pre><code>choice = input(\"Choose an option (1-4): \")\n\nif choice == \"1\":\n    print(\"You selected: View Profile\")\n    print(\"Loading profile...\")\nelif choice == \"2\":\n    print(\"You selected: Settings\")\n    print(\"Opening settings menu...\")\nelif choice == \"3\":\n    print(\"You selected: Help\")\n    print(\"Displaying help information...\")\nelif choice == \"4\":\n    print(\"You selected: Exit\")\n    print(\"Goodbye!\")\nelse:\n    print(\"Invalid choice. Please enter 1, 2, 3, or 4.\")\n</code></pre>  Menu systems commonly use if-elif-else to handle different user choices with a default case for invalid input.</p>"},{"location":"intro-to-python/conditions/#comparison-operators","title":"Comparison Operators","text":"<p>Comparison operators are used to compare values and return boolean results (<code>True</code> or <code>False</code>).</p>"},{"location":"intro-to-python/conditions/#basic-comparison-operators","title":"Basic Comparison Operators","text":"<p><pre><code>a = 10\nb = 20\n\n# Equal to\nprint(a == b)       # False\nprint(a == 10)      # True\n\n# Not equal to\nprint(a != b)       # True\nprint(a != 10)      # False\n\n# Less than\nprint(a &lt; b)        # True\nprint(b &lt; a)        # False\n\n# Less than or equal to\nprint(a &lt;= b)       # True\nprint(a &lt;= 10)      # True\n\n# Greater than\nprint(a &gt; b)        # False\nprint(b &gt; a)        # True\n\n# Greater than or equal to\nprint(a &gt;= b)       # False\nprint(a &gt;= 10)      # True\n</code></pre>  Comparison operators compare two values and return a boolean result. Use <code>==</code> for equality testing (not <code>=</code> which is assignment).</p>"},{"location":"intro-to-python/conditions/#comparing-different-data-types","title":"Comparing Different Data Types","text":"<p>String comparisons: <pre><code>name1 = \"Alice\"\nname2 = \"Bob\"\nname3 = \"alice\"\n\nif name1 == name2:\n    print(\"Names are the same\")\nelse:\n    print(\"Names are different\")\n\n# Case-sensitive comparison\nif name1 == name3:\n    print(\"Names match\")\nelse:\n    print(\"Names don't match (case-sensitive)\")\n\n# Case-insensitive comparison\nif name1.lower() == name3.lower():\n    print(\"Names match (ignoring case)\")\n\n# Alphabetical comparison\nif name1 &lt; name2:\n    print(f\"{name1} comes before {name2} alphabetically\")\n</code></pre>  String comparisons are case-sensitive by default. Use <code>.lower()</code> or <code>.upper()</code> methods for case-insensitive comparisons.</p> <p>List and other comparisons: <pre><code>list1 = [1, 2, 3]\nlist2 = [1, 2, 3]\nlist3 = [1, 2, 4]\n\nif list1 == list2:\n    print(\"Lists are identical\")  # This will print\n\nif list1 == list3:\n    print(\"Lists match\")\nelse:\n    print(\"Lists are different\")  # This will print\n\n# Length comparison\nif len(list1) &gt; 2:\n    print(\"List has more than 2 elements\")\n\n# Check if list is empty\nmy_list = []\nif len(my_list) == 0:\n    print(\"List is empty\")\n# or more pythonic:\nif not my_list:\n    print(\"List is empty\")\n</code></pre>  You can compare lists element by element, check lengths, or test for emptiness using various approaches.</p>"},{"location":"intro-to-python/conditions/#logical-operators","title":"Logical Operators","text":"<p>Logical operators combine multiple conditions to create more complex conditional statements.</p>"},{"location":"intro-to-python/conditions/#and-operator","title":"And Operator","text":"<p>Both conditions must be True: <pre><code>age = 25\nhas_license = True\n\nif age &gt;= 18 and has_license:\n    print(\"You can drive\")\nelse:\n    print(\"You cannot drive\")\n\nscore1 = 85\nscore2 = 90\nif score1 &gt;= 80 and score2 &gt;= 80:\n    print(\"Both scores are excellent\")\n\n# Multiple conditions with and\ntemperature = 25\nis_sunny = True\nis_weekend = False\n\nif temperature &gt; 20 and is_sunny and is_weekend:\n    print(\"Perfect day for a picnic!\")\nelif temperature &gt; 20 and is_sunny:\n    print(\"Nice day, but you might be working\")\nelse:\n    print(\"Not ideal outdoor weather\")\n</code></pre>  The <code>and</code> operator returns <code>True</code> only when all conditions are <code>True</code>. If any condition is <code>False</code>, the entire expression is <code>False</code>.</p>"},{"location":"intro-to-python/conditions/#or-operator","title":"Or Operator","text":"<p>At least one condition must be True: <pre><code>weather = \"rainy\"\nhas_umbrella = True\n\nif weather == \"sunny\" or has_umbrella:\n    print(\"You can go outside\")\nelse:\n    print(\"Better stay indoors\")\n\nday = \"Saturday\"\nif day == \"Saturday\" or day == \"Sunday\":\n    print(\"It's the weekend!\")\n\n# Emergency contact check\nhas_phone = False\nhas_email = True\nhas_address = True\n\nif has_phone or has_email or has_address:\n    print(\"We can contact you\")\nelse:\n    print(\"We need at least one contact method\")\n</code></pre>  The <code>or</code> operator returns <code>True</code> if any condition is <code>True</code>. It only returns <code>False</code> when all conditions are <code>False</code>.</p>"},{"location":"intro-to-python/conditions/#not-operator","title":"Not Operator","text":"<p>Inverts the boolean value: <pre><code>is_logged_in = False\n\nif not is_logged_in:\n    print(\"Please log in first\")\nelse:\n    print(\"Welcome back!\")\n\npassword = \"\"\nif not password:  # Empty string is falsy\n    print(\"Password cannot be empty\")\n\nitems = []\nif not items:  # Empty list is falsy\n    print(\"Shopping cart is empty\")\n\n# Double negative (avoid in practice)\nis_not_admin = False\nif not is_not_admin:  # Confusing - better to use positive logic\n    print(\"User is admin\")\n</code></pre>  The <code>not</code> operator flips <code>True</code> to <code>False</code> and <code>False</code> to <code>True</code>. It's useful for checking negative conditions.</p>"},{"location":"intro-to-python/conditions/#combining-logical-operators","title":"Combining Logical Operators","text":"<p>Complex conditions with precedence: <pre><code>age = 20\nhas_job = True\nhas_savings = False\ncredit_score = 650\n\n# Loan approval logic\nif (age &gt;= 18 and has_job) or (has_savings and credit_score &gt; 600):\n    print(\"Loan pre-approved\")\nelse:\n    print(\"Loan application needs review\")\n\n# User access control\nis_admin = False\nis_moderator = True\nis_premium_user = True\n\nif is_admin or (is_moderator and is_premium_user):\n    print(\"Access to advanced features granted\")\nelse:\n    print(\"Basic access only\")\n\n# Complex validation\nusername = \"user123\"\npassword = \"securepass\"\ntwo_factor_enabled = True\ntrusted_device = False\n\nif (username and password) and (two_factor_enabled or trusted_device):\n    print(\"Login successful\")\nelse:\n    print(\"Additional verification required\")\n</code></pre>  Use parentheses to control the order of evaluation. <code>and</code> has higher precedence than <code>or</code>, but explicit parentheses make intentions clearer.</p>"},{"location":"intro-to-python/conditions/#truthiness-and-falsiness","title":"Truthiness and Falsiness","text":"<p>Python evaluates many values as <code>True</code> or <code>False</code> in boolean contexts, even if they're not explicitly boolean.</p>"},{"location":"intro-to-python/conditions/#falsy-values","title":"Falsy Values","text":"<p>Values that evaluate to False: <pre><code># These all evaluate to False in boolean context\nfalsy_values = [\n    False,      # Boolean False\n    0,          # Zero (integer)\n    0.0,        # Zero (float)\n    \"\",         # Empty string\n    [],         # Empty list\n    {},         # Empty dictionary\n    set(),      # Empty set\n    None        # None value\n]\n\nfor value in falsy_values:\n    if not value:\n        print(f\"{repr(value)} is falsy\")\n\n# Practical examples\nuser_input = \"\"\nif user_input:\n    print(\"User entered something\")\nelse:\n    print(\"User entered nothing\")  # This prints\n\nitems_in_cart = 0\nif items_in_cart:\n    print(\"Cart has items\")\nelse:\n    print(\"Cart is empty\")  # This prints\n</code></pre>  These values are considered \"falsy\" and evaluate to <code>False</code> in boolean contexts. This allows for concise checks.</p>"},{"location":"intro-to-python/conditions/#truthy-values","title":"Truthy Values","text":"<p>Values that evaluate to True: <pre><code># These all evaluate to True in boolean context\ntruthy_values = [\n    True,           # Boolean True\n    1,              # Any non-zero number\n    -1,             # Negative numbers\n    \"hello\",        # Non-empty string\n    \" \",            # String with whitespace\n    [1, 2, 3],      # Non-empty list\n    {\"a\": 1},       # Non-empty dictionary\n    {1, 2, 3}       # Non-empty set\n]\n\nfor value in truthy_values:\n    if value:\n        print(f\"{repr(value)} is truthy\")\n\n# Practical examples\nuser_name = \"Alice\"\nif user_name:\n    print(f\"Hello, {user_name}!\")  # This prints\n\nnumbers = [1, 2, 3, 4, 5]\nif numbers:\n    print(f\"Processing {len(numbers)} numbers\")  # This prints\n</code></pre>  Any value that isn't falsy is considered \"truthy\" and evaluates to <code>True</code> in boolean contexts.</p>"},{"location":"intro-to-python/conditions/#using-truthiness-effectively","title":"Using Truthiness Effectively","text":"<p><pre><code># Check for non-empty data\ndata = input(\"Enter some data: \")\nif data:  # More concise than: if data != \"\"\n    print(\"Processing your data...\")\nelse:\n    print(\"No data provided\")\n\n# Validate list has content\nresults = get_search_results()  # Assume this returns a list\nif results:  # More concise than: if len(results) &gt; 0\n    print(f\"Found {len(results)} results\")\n    for result in results:\n        print(f\"- {result}\")\nelse:\n    print(\"No results found\")\n\n# Default value pattern\nusername = user_input or \"guest\"  # Use \"guest\" if user_input is falsy\nprint(f\"Welcome, {username}\")\n\ndef get_search_results():\n    # Placeholder function\n    return [\"result1\", \"result2\"]\n</code></pre>  Using truthiness makes code more concise and readable. The <code>or</code> operator can provide default values when the first value is falsy.</p>"},{"location":"intro-to-python/conditions/#nested-conditions","title":"Nested Conditions","text":"<p>You can nest if statements inside other if statements to create more complex decision logic.</p>"},{"location":"intro-to-python/conditions/#basic-nested-conditions","title":"Basic Nested Conditions","text":"<p>Conditions within conditions: <pre><code>age = 25\nhas_license = True\nhas_car = False\n\nif age &gt;= 18:\n    print(\"You are old enough to drive\")\n    if has_license:\n        print(\"You have a license\")\n        if has_car:\n            print(\"You can drive your own car\")\n        else:\n            print(\"You need to borrow or rent a car\")\n    else:\n        print(\"You need to get a license first\")\nelse:\n    print(\"You are too young to drive\")\n</code></pre>  Nested conditions allow you to check additional conditions only when outer conditions are met. Each level of nesting adds another layer of indentation.</p>"},{"location":"intro-to-python/conditions/#complex-decision-trees","title":"Complex Decision Trees","text":"<p>Multi-level validation: <pre><code>username = \"admin\"\npassword = \"correct123\"\nis_account_active = True\nlogin_attempts = 2\n\nif username:\n    print(\"Username provided\")\n    if password:\n        print(\"Password provided\")\n        if username == \"admin\" and password == \"correct123\":\n            print(\"Credentials are correct\")\n            if is_account_active:\n                print(\"Account is active\")\n                if login_attempts &lt; 3:\n                    print(\"LOGIN SUCCESSFUL\")\n                    print(\"Welcome to the system!\")\n                else:\n                    print(\"Too many failed attempts. Account locked.\")\n            else:\n                print(\"Account is inactive. Contact administrator.\")\n        else:\n            print(\"Invalid username or password\")\n    else:\n        print(\"Password is required\")\nelse:\n    print(\"Username is required\")\n</code></pre>  Nested conditions create decision trees where each level depends on the previous level's outcome.</p>"},{"location":"intro-to-python/conditions/#avoiding-deep-nesting","title":"Avoiding Deep Nesting","text":"<p>Using early returns (in functions): <pre><code>def check_access(username, password, is_active, attempts):\n    if not username:\n        return \"Username is required\"\n\n    if not password:\n        return \"Password is required\"\n\n    if username != \"admin\" or password != \"correct123\":\n        return \"Invalid credentials\"\n\n    if not is_active:\n        return \"Account inactive\"\n\n    if attempts &gt;= 3:\n        return \"Account locked\"\n\n    return \"Access granted\"\n\n# Usage\nresult = check_access(\"admin\", \"correct123\", True, 1)\nprint(result)\n</code></pre>  Early returns can make deeply nested conditions more readable by handling error cases first.</p> <p>Using logical operators instead of nesting: <pre><code># Instead of deep nesting:\nif age &gt;= 18:\n    if has_license:\n        if has_insurance:\n            print(\"Can drive\")\n\n# Use logical operators:\nif age &gt;= 18 and has_license and has_insurance:\n    print(\"Can drive\")\n\n# Complex example\nage = 25\nhas_license = True\nhas_insurance = True\ncar_is_working = True\n\nif age &gt;= 18 and has_license and has_insurance and car_is_working:\n    print(\"Ready to drive!\")\nelse:\n    print(\"Cannot drive right now\")\n    if age &lt; 18:\n        print(\"- Too young\")\n    if not has_license:\n        print(\"- No license\")\n    if not has_insurance:\n        print(\"- No insurance\")\n    if not car_is_working:\n        print(\"- Car needs repair\")\n</code></pre>  Logical operators can often replace nested conditions, making code more readable and maintainable.</p>"},{"location":"intro-to-python/conditions/#ternary-operator-conditional-expression","title":"Ternary Operator (Conditional Expression)","text":"<p>The ternary operator provides a concise way to assign values based on conditions.</p>"},{"location":"intro-to-python/conditions/#basic-ternary-syntax","title":"Basic Ternary Syntax","text":"<pre><code># Basic structure\nvariable = value_if_true if condition else value_if_false\n</code></pre>"},{"location":"intro-to-python/conditions/#simple-ternary-examples","title":"Simple Ternary Examples","text":"<p>Basic value assignment: <pre><code>age = 20\nstatus = \"adult\" if age &gt;= 18 else \"minor\"\nprint(f\"You are a {status}\")\n\nscore = 85\ngrade = \"Pass\" if score &gt;= 60 else \"Fail\"\nprint(f\"Result: {grade}\")\n\ntemperature = 30\nclothing = \"shorts\" if temperature &gt; 25 else \"pants\"\nprint(f\"Wear: {clothing}\")\n\n# Without ternary (more verbose):\nif temperature &gt; 25:\n    clothing = \"shorts\"\nelse:\n    clothing = \"pants\"\n</code></pre>  The ternary operator evaluates the condition and returns the first value if <code>True</code>, otherwise the second value. It's a shorthand for simple if-else assignments.</p>"},{"location":"intro-to-python/conditions/#ternary-with-function-calls","title":"Ternary with Function Calls","text":"<p><pre><code>numbers = [1, 2, 3, 4, 5]\nresult = max(numbers) if numbers else 0\nprint(f\"Maximum: {result}\")\n\nusername = input(\"Enter username: \")\ndisplay_name = username.title() if username else \"Guest\"\nprint(f\"Welcome, {display_name}!\")\n\n# Chained ternary (use sparingly)\nscore = 95\ngrade = \"A\" if score &gt;= 90 else \"B\" if score &gt;= 80 else \"C\" if score &gt;= 70 else \"F\"\nprint(f\"Grade: {grade}\")\n</code></pre>  Ternary operators can call functions and be chained, but chaining reduces readability and should be used sparingly.</p>"},{"location":"intro-to-python/conditions/#when-to-use-ternary","title":"When to Use Ternary","text":"<p>Good use cases: <pre><code># Simple value assignments\nis_weekend = True\nsleep_time = 10 if is_weekend else 7\n\n# Default values\nuser_input = \"\"\nname = user_input if user_input else \"Anonymous\"\n\n# Simple mathematical operations\nx = 10\nabs_x = x if x &gt;= 0 else -x\n\n# List comprehensions with conditions\nnumbers = [1, -2, 3, -4, 5]\nabsolute_numbers = [n if n &gt;= 0 else -n for n in numbers]\n</code></pre></p> <p>Avoid for complex logic: <pre><code># Avoid - too complex for ternary\nscore = 85\n# This is hard to read:\nresult = \"Excellent\" if score &gt;= 90 else \"Good\" if score &gt;= 80 else \"Average\" if score &gt;= 70 else \"Poor\"\n\n# Better as regular if-elif-else:\nif score &gt;= 90:\n    result = \"Excellent\"\nelif score &gt;= 80:\n    result = \"Good\"\nelif score &gt;= 70:\n    result = \"Average\"\nelse:\n    result = \"Poor\"\n</code></pre>  Use ternary operators for simple conditions. For complex logic, regular if-elif-else statements are more readable.</p>"},{"location":"intro-to-python/conditions/#common-patterns-and-best-practices","title":"Common Patterns and Best Practices","text":""},{"location":"intro-to-python/conditions/#input-validation-patterns","title":"Input Validation Patterns","text":"<p>Validating user input: <pre><code># Number validation\nuser_input = input(\"Enter a number: \")\nif user_input.isdigit():\n    number = int(user_input)\n    if 1 &lt;= number &lt;= 100:\n        print(f\"Valid number: {number}\")\n    else:\n        print(\"Number must be between 1 and 100\")\nelse:\n    print(\"Please enter a valid number\")\n\n# Email validation (simple)\nemail = input(\"Enter email: \")\nif \"@\" in email and \".\" in email:\n    if email.count(\"@\") == 1:\n        print(\"Email format looks valid\")\n    else:\n        print(\"Email should contain exactly one @ symbol\")\nelse:\n    print(\"Email must contain @ and . symbols\")\n\n# Password strength\npassword = input(\"Enter password: \")\nis_long_enough = len(password) &gt;= 8\nhas_digit = any(char.isdigit() for char in password)\nhas_letter = any(char.isalpha() for char in password)\n\nif is_long_enough and has_digit and has_letter:\n    print(\"Strong password!\")\nelif is_long_enough:\n    print(\"Password needs both letters and numbers\")\nelse:\n    print(\"Password must be at least 8 characters\")\n</code></pre>  Layer validation checks from basic to specific, providing helpful feedback for each failure case.</p>"},{"location":"intro-to-python/conditions/#error-handling-patterns","title":"Error Handling Patterns","text":"<p>Graceful error handling: <pre><code># File processing with validation\nfilename = input(\"Enter filename: \")\nif filename:\n    if filename.endswith('.txt'):\n        try:\n            with open(filename, 'r') as file:\n                content = file.read()\n                if content:\n                    print(f\"File contains {len(content)} characters\")\n                else:\n                    print(\"File is empty\")\n        except FileNotFoundError:\n            print(f\"File '{filename}' not found\")\n        except PermissionError:\n            print(\"Permission denied to read file\")\n    else:\n        print(\"Please provide a .txt file\")\nelse:\n    print(\"Filename cannot be empty\")\n\n# Division with error checking\ndividend = float(input(\"Enter dividend: \"))\ndivisor = float(input(\"Enter divisor: \"))\n\nif divisor != 0:\n    result = dividend / divisor\n    print(f\"{dividend} \u00f7 {divisor} = {result}\")\nelse:\n    print(\"Cannot divide by zero!\")\n</code></pre>  Check for error conditions before attempting operations that might fail.</p>"},{"location":"intro-to-python/conditions/#configuration-and-settings","title":"Configuration and Settings","text":"<p>Feature flags and configuration: <pre><code># Application configuration\nDEBUG_MODE = True\nMAINTENANCE_MODE = False\nUSER_ROLE = \"admin\"\n\n# Feature availability\nif DEBUG_MODE:\n    print(\"Debug information: Application starting...\")\n\nif not MAINTENANCE_MODE:\n    print(\"System is online and ready\")\n\n    if USER_ROLE == \"admin\":\n        print(\"Admin panel available\")\n        print(\"User management enabled\")\n    elif USER_ROLE == \"moderator\":\n        print(\"Moderation tools available\")\n    else:\n        print(\"Standard user interface\")\nelse:\n    print(\"System is under maintenance\")\n\n# Environment-based settings\nENVIRONMENT = \"development\"  # Could be \"development\", \"testing\", \"production\"\n\nif ENVIRONMENT == \"development\":\n    database_url = \"localhost:5432\"\n    log_level = \"DEBUG\"\n    cache_enabled = False\nelif ENVIRONMENT == \"testing\":\n    database_url = \"test-db:5432\"\n    log_level = \"INFO\"\n    cache_enabled = True\nelif ENVIRONMENT == \"production\":\n    database_url = \"prod-db:5432\"\n    log_level = \"ERROR\"\n    cache_enabled = True\nelse:\n    raise ValueError(f\"Unknown environment: {ENVIRONMENT}\")\n\nprint(f\"Database: {database_url}\")\nprint(f\"Log level: {log_level}\")\nprint(f\"Cache enabled: {cache_enabled}\")\n</code></pre>  Use conditions to adapt program behavior based on configuration settings or environment variables.</p>"},{"location":"intro-to-python/conditions/#performance-and-best-practices","title":"Performance and Best Practices","text":""},{"location":"intro-to-python/conditions/#efficient-condition-checking","title":"Efficient Condition Checking","text":"<p>Order conditions by likelihood: <pre><code># Put most likely conditions first\nuser_type = \"regular\"  # Most users are regular\n\nif user_type == \"regular\":\n    # Most common case first\n    apply_regular_discount()\nelif user_type == \"premium\":\n    # Less common\n    apply_premium_discount()\nelif user_type == \"vip\":\n    # Least common\n    apply_vip_discount()\n\ndef apply_regular_discount():\n    print(\"5% discount applied\")\n\ndef apply_premium_discount():\n    print(\"15% discount applied\")\n\ndef apply_vip_discount():\n    print(\"25% discount applied\")\n</code></pre>  Python evaluates conditions from top to bottom, so put the most likely conditions first for better performance.</p> <p>Short-circuit evaluation: <pre><code># Expensive operations last\ndef expensive_check():\n    print(\"Performing expensive check...\")\n    return True\n\ndef quick_check():\n    return False\n\n# Good: quick_check() is False, so expensive_check() never runs\nif quick_check() and expensive_check():\n    print(\"Both checks passed\")\n\n# Also works with 'or'\nif quick_check() or expensive_check():\n    print(\"At least one check passed\")\n</code></pre>  Python uses short-circuit evaluation - it stops checking conditions as soon as the result is determined.</p>"},{"location":"intro-to-python/conditions/#avoiding-common-mistakes","title":"Avoiding Common Mistakes","text":"<p>Comparison mistakes: <pre><code># Wrong: assignment instead of comparison\nx = 5\nif x = 10:  # SyntaxError - should be ==\n    print(\"x is 10\")\n\n# Correct:\nif x == 10:\n    print(\"x is 10\")\n\n# Wrong: comparing different types inconsistently\nage_string = \"25\"\nif age_string &gt; 18:  # Comparing string to number\n    print(\"Adult\")\n\n# Correct: convert types first\nage = int(age_string)\nif age &gt; 18:\n    print(\"Adult\")\n</code></pre></p> <p>Boolean comparison mistakes: <pre><code>is_active = True\n\n# Unnecessary - avoid\nif is_active == True:\n    print(\"Active\")\n\n# Better - direct boolean check\nif is_active:\n    print(\"Active\")\n\n# For false checks\nif not is_active:\n    print(\"Inactive\")\n\n# Not recommended\nif is_active == False:\n    print(\"Inactive\")\n</code></pre>  Don't compare boolean variables to <code>True</code> or <code>False</code> explicitly - just use the variable directly or with <code>not</code>.</p>"},{"location":"intro-to-python/conditions/#quick-reference-summary","title":"Quick Reference Summary","text":"Condition Type Syntax Use Case Simple if <code>if condition:</code> Execute code when condition is true If-else <code>if condition: ... else:</code> Choose between two options If-elif-else <code>if cond1: ... elif cond2: ... else:</code> Choose from multiple options Nested if <code>if cond1: if cond2:</code> Conditions within conditions Ternary <code>value_if_true if condition else value_if_false</code> Concise conditional assignment"},{"location":"intro-to-python/conditions/#comparison-operators_1","title":"Comparison Operators","text":"Operator Meaning Example <code>==</code> Equal to <code>x == 5</code> <code>!=</code> Not equal to <code>x != 5</code> <code>&lt;</code> Less than <code>x &lt; 5</code> <code>&lt;=</code> Less than or equal <code>x &lt;= 5</code> <code>&gt;</code> Greater than <code>x &gt; 5</code> <code>&gt;=</code> Greater than or equal <code>x &gt;= 5</code>"},{"location":"intro-to-python/conditions/#logical-operators_1","title":"Logical Operators","text":"Operator Meaning Example <code>and</code> Both conditions true <code>x &gt; 0 and x &lt; 10</code> <code>or</code> At least one condition true <code>x &lt; 0 or x &gt; 10</code> <code>not</code> Opposite of condition <code>not is_empty</code> <p>Comprehensive example combining multiple concepts: <pre><code># Student Management System\ndef process_student_application(name, age, gpa, has_recommendation, financial_aid_needed):\n    print(f\"=== Processing Application for {name} ===\")\n\n    # Basic eligibility check\n    if not name or not isinstance(age, int) or age &lt;= 0:\n        return \"Invalid application data\"\n\n    # Age requirements\n    if age &lt; 16:\n        return \"Applicant too young (minimum age: 16)\"\n    elif age &gt; 65:\n        print(\"\u26a0\ufe0f  Senior applicant - special review required\")\n\n    # Academic requirements\n    if gpa &lt; 0 or gpa &gt; 4.0:\n        return \"Invalid GPA (must be 0.0-4.0)\"\n\n    # Determine admission status\n    if gpa &gt;= 3.5:\n        admission_status = \"Accepted\"\n        scholarship_eligible = True\n        print(\"\ud83c\udf1f Excellent academic record!\")\n    elif gpa &gt;= 3.0:\n        admission_status = \"Accepted\" if has_recommendation else \"Conditional\"\n        scholarship_eligible = has_recommendation\n        print(\"\ud83d\udc4d Good academic standing\")\n    elif gpa &gt;= 2.5:\n        if has_recommendation:\n            admission_status = \"Conditional\"\n            scholarship_eligible = False\n            print(\"\ud83d\udccb Conditional acceptance with recommendation\")\n        else:\n            admission_status = \"Rejected\"\n            scholarship_eligible = False\n            print(\"\u274c Below minimum requirements without recommendation\")\n    else:\n        admission_status = \"Rejected\"\n        scholarship_eligible = False\n        print(\"\u274c GPA too low for admission\")\n\n    # Financial aid processing\n    if admission_status == \"Accepted\" and financial_aid_needed:\n        if gpa &gt;= 3.8:\n            aid_amount = 5000\n            print(\"\ud83d\udcb0 Full scholarship awarded!\")\n        elif gpa &gt;= 3.5:\n            aid_amount = 3000\n            print(\"\ud83d\udcb0 Partial scholarship awarded\")\n        elif scholarship_eligible:\n            aid_amount = 1000\n            print(\"\ud83d\udcb0 Need-based aid available\")\n        else:\n            aid_amount = 0\n            print(\"\ud83d\udcb8 No financial aid available\")\n    else:\n        aid_amount = 0\n\n    # Final summary\n    result = {\n        \"status\": admission_status,\n        \"scholarship_eligible\": scholarship_eligible,\n        \"financial_aid\": aid_amount,\n        \"message\": \"Welcome to our university!\" if admission_status == \"Accepted\" else \"Thank you for your application\"\n    }\n\n    print(f\"\ud83d\udccb Final Status: {admission_status}\")\n    if aid_amount &gt; 0:\n        print(f\"\ud83d\udcb0 Financial Aid: ${aid_amount}\")\n\n    return result\n\n# Example usage\nstudents = [\n    (\"Alice Johnson\", 18, 3.8, True, True),\n    (\"Bob Smith\", 17, 2.9, False, False),\n    (\"Charlie Brown\", 19, 3.2, True, True),\n    (\"Diana Prince\", 16, 4.0, True, False),\n    (\"Eve Wilson\", 20, 2.3, False, True)\n]\n\nprint(\"\ud83c\udf93 UNIVERSITY ADMISSION PROCESSING \ud83c\udf93\\n\")\n\nfor student_data in students:\n    name, age, gpa, has_rec, needs_aid = student_data\n    result = process_student_application(name, age, gpa, has_rec, needs_aid)\n    print(\"-\" * 50)\n\nprint(\"\\n\u2705 All applications processed!\")\n</code></pre></p>"},{"location":"intro-to-python/conditions/#falsy-values-quick-reference","title":"Falsy Values Quick Reference","text":"<pre><code># All these evaluate to False in boolean context:\nif not False:        print(\"False is falsy\")\nif not 0:           print(\"0 is falsy\")\nif not 0.0:         print(\"0.0 is falsy\")  \nif not \"\":          print(\"Empty string is falsy\")\nif not []:          print(\"Empty list is falsy\")\nif not {}:          print(\"Empty dict is falsy\")\nif not set():       print(\"Empty set is falsy\")\nif not None:        print(\"None is falsy\")\n</code></pre>"},{"location":"intro-to-python/conditions/#common-condition-patterns","title":"Common Condition Patterns","text":"<pre><code># 1. Range checking\ndef categorize_age(age):\n    if age &lt; 0:\n        return \"Invalid age\"\n    elif age &lt; 13:\n        return \"Child\"\n    elif age &lt; 20:\n        return \"Teenager\"  \n    elif age &lt; 65:\n        return \"Adult\"\n    else:\n        return \"Senior\"\n\n# 2. Multiple criteria validation\ndef validate_password(password):\n    if not password:\n        return \"Password cannot be empty\"\n\n    issues = []\n    if len(password) &lt; 8:\n        issues.append(\"must be at least 8 characters\")\n    if not any(c.isupper() for c in password):\n        issues.append(\"must contain uppercase letter\")\n    if not any(c.islower() for c in password):\n        issues.append(\"must contain lowercase letter\")\n    if not any(c.isdigit() for c in password):\n        issues.append(\"must contain a number\")\n\n    if issues:\n        return \"Password \" + \", \".join(issues)\n    return \"Password is valid\"\n\n# 3. State machine pattern\ndef process_order(current_state, action):\n    if current_state == \"cart\":\n        if action == \"checkout\":\n            return \"processing\"\n        elif action == \"add_item\":\n            return \"cart\"\n        elif action == \"clear\":\n            return \"empty\"\n    elif current_state == \"processing\":\n        if action == \"confirm\":\n            return \"confirmed\"\n        elif action == \"cancel\":\n            return \"cancelled\"\n    elif current_state == \"confirmed\":\n        if action == \"ship\":\n            return \"shipped\"\n        elif action == \"cancel\":\n            return \"cancelled\"\n    elif current_state == \"shipped\":\n        if action == \"deliver\":\n            return \"delivered\"\n        elif action == \"return\":\n            return \"returned\"\n\n    return current_state  # No state change\n\n# 4. Configuration-based behavior\ndef get_database_config(environment):\n    base_config = {\n        \"timeout\": 30,\n        \"pool_size\": 10\n    }\n\n    if environment == \"development\":\n        base_config.update({\n            \"host\": \"localhost\",\n            \"debug\": True,\n            \"ssl\": False\n        })\n    elif environment == \"testing\":\n        base_config.update({\n            \"host\": \"test-db.company.com\",\n            \"debug\": True,\n            \"ssl\": True\n        })\n    elif environment == \"production\":\n        base_config.update({\n            \"host\": \"prod-db.company.com\",\n            \"debug\": False,\n            \"ssl\": True,\n            \"pool_size\": 50\n        })\n    else:\n        raise ValueError(f\"Unknown environment: {environment}\")\n\n    return base_config\n\n# 5. Input sanitization and validation\ndef process_user_input(raw_input):\n    # Clean the input\n    if not raw_input:\n        return None, \"Input cannot be empty\"\n\n    cleaned = raw_input.strip()\n    if not cleaned:\n        return None, \"Input cannot be only whitespace\"\n\n    # Validate length\n    if len(cleaned) &gt; 100:\n        return None, \"Input too long (max 100 characters)\"\n\n    # Check for forbidden characters\n    forbidden_chars = ['&lt;', '&gt;', '&amp;', '\"', \"'\"]\n    if any(char in cleaned for char in forbidden_chars):\n        return None, \"Input contains forbidden characters\"\n\n    # Additional validation based on content\n    if cleaned.lower() in ['admin', 'root', 'system']:\n        return None, \"Reserved word not allowed\"\n\n    return cleaned, \"Valid input\"\n\n# Usage examples\nprint(\"=== CONDITION PATTERNS EXAMPLES ===\\n\")\n\n# Age categorization\nages = [5, 15, 25, 70, -1]\nfor age in ages:\n    category = categorize_age(age)\n    print(f\"Age {age}: {category}\")\n\nprint()\n\n# Password validation\npasswords = [\"weak\", \"StrongPass123\", \"nodigits\", \"NOLOWERCASE123\"]\nfor pwd in passwords:\n    result = validate_password(pwd)\n    print(f\"'{pwd}': {result}\")\n\nprint()\n\n# Order state machine\norder_state = \"cart\"\nactions = [\"add_item\", \"checkout\", \"confirm\", \"ship\", \"deliver\"]\nfor action in actions:\n    new_state = process_order(order_state, action)\n    print(f\"State '{order_state}' + action '{action}' \u2192 '{new_state}'\")\n    order_state = new_state\n</code></pre> <p>This comprehensive guide covers all essential conditional concepts with detailed explanations, practical examples, performance considerations, and best practices for effective condition usage in Python!</p>"},{"location":"intro-to-python/debugging/","title":"Error Handling and Debugging in Python","text":""},{"location":"intro-to-python/debugging/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this document you will be able to:</p> <ul> <li>Explain how Python reports errors (exceptions and tracebacks).</li> <li>Use <code>try</code> / <code>except</code> / <code>else</code> / <code>finally</code> blocks effectively.</li> <li>Raise and define custom exceptions appropriately.</li> <li>Use standard debugging tools (<code>pdb</code>, <code>breakpoint</code>, <code>traceback</code>) and logging for diagnosing problems.</li> <li>Apply best practices for error handling in libraries and applications (avoiding broad excepts, fail-fast, clear messages).</li> <li>Use assertions, warnings, and unit tests to catch and prevent bugs early.</li> <li>Read and interpret tracebacks and use them to quickly locate the source of a problem.</li> </ul>"},{"location":"intro-to-python/debugging/#what-is-an-exception","title":"What is an exception?","text":"<p>An exception is a runtime event that interrupts normal flow of a program. When Python encounters an error, it raises an exception object that contains information about what went wrong. If not handled, the interpreter prints a traceback and terminates the program.</p> <p>Example traceback (shortened):</p> <pre><code>Traceback (most recent call last):\n  File \"example.py\", line 10, in &lt;module&gt;\n    main()\n  File \"example.py\", line 6, in main\n    print(1 / 0)\nZeroDivisionError: division by zero\n</code></pre> <p>Tracebacks show the call stack: the chain of function calls that led to the exception, and the last line indicates the exception type and message.</p>"},{"location":"intro-to-python/debugging/#basic-exception-handling-try-except","title":"Basic exception handling: <code>try</code> / <code>except</code>","text":"<p>Use <code>try</code> to wrap code that may fail and <code>except</code> to handle specific exceptions.</p> <pre><code>try:\n    value = int(input_str)\nexcept ValueError:\n    print('Invalid integer:', input_str)\nelse:\n    print('Got integer', value)\n</code></pre> <ul> <li><code>except ExceptionType:</code> catches only that type.</li> <li><code>except (TypeError, ValueError):</code> can catch multiple types.</li> <li><code>except Exception as e:</code> binds the exception object to <code>e</code>.</li> </ul> <p>Do not use bare <code>except:</code> unless you have a very good reason (it catches <code>KeyboardInterrupt</code> and <code>SystemExit</code> and hides bugs).</p>"},{"location":"intro-to-python/debugging/#finally-and-else","title":"<code>finally</code> and <code>else</code>","text":"<ul> <li><code>finally</code> always runs, whether an exception occurred or not \u2014 useful for cleanup (closing files, network connections).</li> <li><code>else</code> runs only if the <code>try</code> block did not raise an exception \u2014 handy for code that should run when all went well.</li> </ul> <pre><code>try:\n    f = open(path)\n    data = f.read()\nexcept OSError as err:\n    handle_error(err)\nelse:\n    process(data)\nfinally:\n    try:\n        f.close()\n    except Exception:\n        pass\n</code></pre> <p>Using <code>with open(path) as f:</code> is preferred because it handles cleanup automatically.</p>"},{"location":"intro-to-python/debugging/#raising-exceptions-and-custom-exceptions","title":"Raising exceptions and custom exceptions","text":"<p>Raise exceptions when a function cannot perform its contract.</p> <pre><code>def divide(a, b):\n    if b == 0:\n        raise ValueError('b must be non-zero')\n    return a / b\n</code></pre> <p>Define custom exceptions by subclassing <code>Exception</code> (or a more specific base):</p> <pre><code>class ConfigurationError(Exception):\n    \"\"\"Raised when configuration is invalid or missing.\"\"\"\n    pass\n\nraise ConfigurationError('missing API key')\n</code></pre> <p>Best practices for custom exceptions:</p> <ul> <li>Use a clear, descriptive name ending with <code>Error</code>.</li> <li>Keep exception hierarchy shallow and meaningful.</li> <li>Attach helpful information (message, attributes) to the exception when needed.</li> </ul>"},{"location":"intro-to-python/debugging/#exception-chaining-and-from","title":"Exception chaining and <code>from</code>","text":"<p>When catching and re-raising a new exception, preserve context using <code>raise NewError(...) from original_exc</code>.</p> <pre><code>try:\n    val = int(s)\nexcept ValueError as e:\n    raise ConfigurationError('bad integer in config') from e\n</code></pre> <p>This keeps tracebacks linked and is useful for debugging layered code.</p>"},{"location":"intro-to-python/debugging/#catching-many-exceptions-good-patterns","title":"Catching many exceptions \u2014 good patterns","text":"<ul> <li>Catch the specific exceptions you expect.</li> <li>Use broad <code>except Exception:</code> only at top-level entry points to log and fail gracefully (never swallow silently).</li> <li>Use <code>logging.exception()</code> inside an <code>except</code> block to log stack traces.</li> </ul> <p>Example top-level handler:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    run()\nexcept Exception:\n    logger.exception('Unhandled error \u2014 exiting')\n    raise  # optionally re-raise after logging\n</code></pre>"},{"location":"intro-to-python/debugging/#using-warnings-for-non-fatal-issues","title":"Using <code>warnings</code> for non-fatal issues","text":"<p>Use the <code>warnings</code> module for deprecations or recoverable issues; they are softer than exceptions and can be filtered or turned into errors in tests.</p> <pre><code>import warnings\n\nif old_flag_used:\n    warnings.warn('old_flag is deprecated; use new_flag', DeprecationWarning)\n</code></pre> <p>In tests, enable <code>warnings.filterwarnings('error')</code> to catch accidental usage of deprecated behavior.</p>"},{"location":"intro-to-python/debugging/#assertions-vs-exceptions","title":"Assertions vs exceptions","text":"<p><code>assert</code> is a debugging aid \u2014 it throws <code>AssertionError</code> if the condition is false. Do not use <code>assert</code> for argument validation in production because Python can be run with optimizations (<code>-O</code>) which remove assertions.</p> <pre><code>assert n &gt; 0, 'n must be positive'\n</code></pre> <p>Use explicit exceptions for validating external inputs or public API usage.</p>"},{"location":"intro-to-python/debugging/#logging-best-practices","title":"Logging best practices","text":"<ul> <li>Prefer <code>logging</code> over <code>print</code> for production code.</li> <li>Configure logging at application entry point; libraries should use <code>logging.getLogger(__name__)</code> and not configure handlers themselves.</li> <li>Use appropriate log levels: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>.</li> </ul> <pre><code>import logging\nlogger = logging.getLogger(__name__)\nlogger.debug('value = %r', value)\nlogger.error('Failed to process %s', item, exc_info=True)\n</code></pre> <p>Use <code>exc_info=True</code> or <code>logger.exception()</code> in exception handlers to include tracebacks in logs.</p>"},{"location":"intro-to-python/debugging/#debugging-tools-and-techniques","title":"Debugging tools and techniques","text":""},{"location":"intro-to-python/debugging/#pdb-and-breakpoint","title":"<code>pdb</code> and <code>breakpoint()</code>","text":"<ul> <li>Insert <code>import pdb; pdb.set_trace()</code> or simply <code>breakpoint()</code> (Python 3.7+). This opens an interactive debugger at that line.</li> <li>Basic pdb commands: <code>n</code> (next), <code>s</code> (step into), <code>c</code> (continue), <code>l</code> (list), <code>p</code> (print), <code>q</code> (quit).</li> </ul> <p>Example:</p> <pre><code>def compute(x):\n    breakpoint()\n    return x * 2\n</code></pre> <p>Consider using <code>ipdb</code> for an enhanced interactive experience (IPython-powered debugger).</p>"},{"location":"intro-to-python/debugging/#traceback-and-traceback-module","title":"Traceback and <code>traceback</code> module","text":"<p>Use <code>traceback.format_exc()</code> to capture the current traceback as a string (useful for logging).</p> <pre><code>import traceback\ntry:\n    risky()\nexcept Exception:\n    tb = traceback.format_exc()\n    logger.error('Error: %s', tb)\n</code></pre>"},{"location":"intro-to-python/debugging/#debugging-in-ides","title":"Debugging in IDEs","text":"<p>Modern IDEs (VSCode, PyCharm) offer breakpoints, variable inspection, and step-through debugging \u2014 use them for faster diagnosis.</p>"},{"location":"intro-to-python/debugging/#print-debugging-when-small","title":"Print debugging (when small)","text":"<p>Occasionally a few <code>print()</code> calls are the fastest way to inspect values for quick scripts \u2014 prefer <code>logging.debug()</code> for anything longer lived.</p>"},{"location":"intro-to-python/debugging/#reproducing-bugs-with-minimal-test-cases","title":"Reproducing bugs with minimal test cases","text":"<p>When you hit a bug, reduce the code to the smallest snippet that reproduces the issue. This often reveals the root cause.</p>"},{"location":"intro-to-python/debugging/#inspecting-frames-and-post-mortem-debugging","title":"Inspecting frames and post-mortem debugging","text":"<ul> <li><code>pdb.post_mortem()</code> lets you inspect a crashed process after an exception.</li> </ul> <pre><code>import pdb, sys\ntry:\n    main()\nexcept Exception:\n    pdb.post_mortem()\n</code></pre> <ul> <li>Use <code>faulthandler</code> module to get tracebacks for native crashes (segfaults) or use <code>python -X faulthandler</code>.</li> </ul>"},{"location":"intro-to-python/debugging/#unit-testing-to-prevent-regressions","title":"Unit testing to prevent regressions","text":"<ul> <li>Write tests for expected and error cases (using <code>pytest</code> or <code>unittest</code>).</li> <li>Use <code>pytest.raises</code> to assert that code raises expected exceptions.</li> </ul> <pre><code>import pytest\n\ndef test_divide_by_zero():\n    with pytest.raises(ValueError):\n        divide(1, 0)\n</code></pre> <ul> <li>Turn warnings into errors in tests to catch deprecated behavior: <code>pytest -W error</code> or <code>warnings.filterwarnings('error')</code>.</li> </ul>"},{"location":"intro-to-python/debugging/#defensive-programming-and-api-design","title":"Defensive programming and API design","text":"<ul> <li>Validate inputs at API boundaries and raise clear exceptions with actionable messages.</li> <li>Document which exceptions a function can raise.</li> <li>Fail fast: detect incorrect state early and raise informative errors.</li> <li>For libraries, prefer raising standard builtins where appropriate (e.g., <code>ValueError</code>, <code>TypeError</code>) and provide custom exceptions only when callers may want to catch your library-specific problems.</li> </ul>"},{"location":"intro-to-python/debugging/#common-error-types-and-how-to-handle-them","title":"Common error types and how to handle them","text":"<ul> <li><code>TypeError</code> \u2014 wrong type passed. Check types, use duck-typing carefully, and document expectations.</li> <li><code>ValueError</code> \u2014 correct type but invalid value. Validate ranges and formats.</li> <li><code>KeyError</code> / <code>IndexError</code> \u2014 missing keys or out-of-bounds indices. Use <code>.get()</code> for dicts when sensible.</li> <li><code>IOError</code> / <code>OSError</code> \u2014 file or OS-level issues. Handle with retries or clear user-facing messages.</li> <li><code>ImportError</code> / <code>ModuleNotFoundError</code> \u2014 missing optional dependencies; handle gracefully if optional.</li> </ul>"},{"location":"intro-to-python/debugging/#tips-and-best-practices-summary","title":"Tips and best practices (summary)","text":"<ul> <li>Catch specific exceptions; avoid bare <code>except:</code>.</li> <li>Log exceptions with context and stack traces.</li> <li>Use <code>with</code> and context managers for resource cleanup instead of manual <code>try/finally</code> where possible.</li> <li>Prefer clear error messages and small exception hierarchies.</li> <li>Add tests for error cases and treat warnings as errors in CI.</li> <li>Use assertions only for internal invariants, not input validation.</li> <li>Reproduce bugs with small examples and fix there; add regression tests.</li> </ul>"},{"location":"intro-to-python/debugging/#exercises","title":"Exercises","text":"<ul> <li>Write a function that reads a CSV and raises <code>ConfigurationError</code> if a required column is missing. Write tests asserting the exception.</li> <li>Add logging to a small script and demonstrate logging an exception stack trace using <code>logger.exception()</code>.</li> <li>Create a small program that uses <code>breakpoint()</code> to inspect variables, and step through it with <code>pdb</code> commands.</li> <li>Convert a <code>try/except</code> that swallows exceptions into one that handles only expected exceptions and logs unexpected ones.</li> <li>Write a test that treats <code>DeprecationWarning</code> as an error and fails when deprecated functionality is used.</li> </ul>"},{"location":"intro-to-python/dictionary/","title":"Dictionary - Basic Guide","text":""},{"location":"intro-to-python/dictionary/#what-is-a-dictionary","title":"What is a Dictionary?","text":"<p>A dictionary is a collection of key-value pairs where each key is unique and maps to a specific value. Dictionaries are ordered (as of Python 3.7+), mutable, and use curly braces <code>{}</code> with key-value pairs separated by colons.</p>"},{"location":"intro-to-python/dictionary/#creating-dictionaries","title":"Creating Dictionaries","text":"<pre><code># Empty dictionary\nempty_dict = {}\nalso_empty = dict()\n\n# Dictionary with elements\nstudent = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nnumbers = {1: \"one\", 2: \"two\", 3: \"three\"}\nmixed = {\"string_key\": 100, 42: \"number_key\", True: \"boolean_key\"}\n\n# Creating dictionary from lists of tuples\npairs = [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\nletter_dict = dict(pairs)       # {\"a\": 1, \"b\": 2, \"c\": 3}\n\n# Using keyword arguments (keys must be valid variable names)\nperson = dict(name=\"Bob\", age=25, city=\"New York\")\n</code></pre> <p>Dictionary keys must be immutable (strings, numbers, tuples) and unique. If you use the same key twice, the second value overwrites the first. Values can be any data type and can be duplicated.</p>"},{"location":"intro-to-python/dictionary/#accessing-dictionary-elements","title":"Accessing Dictionary Elements","text":""},{"location":"intro-to-python/dictionary/#basic-access-methods","title":"Basic Access Methods","text":"<p>Using square brackets []: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nprint(student[\"name\"])          # \"Alice\" - direct key access\nprint(student[\"age\"])           # 20\n# print(student[\"height\"])      # KeyError - key doesn't exist\n</code></pre>  Square bracket notation gives you direct access to values using their keys. If the key doesn't exist, Python raises a KeyError.</p> <p>Using get() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nprint(student.get(\"name\"))      # \"Alice\" - same as student[\"name\"]\nprint(student.get(\"height\"))    # None - key doesn't exist, returns None\nprint(student.get(\"height\", \"Not specified\"))  # \"Not specified\" - custom default\n</code></pre>  The <code>get()</code> method is safer than square brackets because it returns <code>None</code> (or a default value) instead of raising an error when a key doesn't exist.</p>"},{"location":"intro-to-python/dictionary/#modifying-dictionaries","title":"Modifying Dictionaries","text":""},{"location":"intro-to-python/dictionary/#adding-and-updating-elements","title":"Adding and Updating Elements","text":"<p>Direct assignment: <pre><code>student = {\"name\": \"Alice\", \"age\": 20}\nstudent[\"grade\"] = \"A\"          # Add new key-value pair\nstudent[\"age\"] = 21             # Update existing value\nprint(student)                  # {\"name\": \"Alice\", \"age\": 21, \"grade\": \"A\"}\n</code></pre>  You can add new keys or update existing ones using square bracket assignment. If the key exists, its value is updated; if not, a new key-value pair is created.</p> <p>update() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20}\nstudent.update({\"grade\": \"A\", \"major\": \"Computer Science\"})  # Add multiple from dict\nstudent.update([(\"gpa\", 3.8), (\"year\", 2)])                # Add from list of tuples\nstudent.update(credits=120, status=\"active\")                # Add using keyword arguments\n</code></pre>  The <code>update()</code> method can add multiple key-value pairs at once. It accepts dictionaries, lists of tuples, or keyword arguments. Existing keys get updated, new keys get added.</p> <p>setdefault() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20}\ngrade = student.setdefault(\"grade\", \"B\")    # Returns \"B\" and adds \"grade\": \"B\"\nage = student.setdefault(\"age\", 25)         # Returns 20, doesn't change existing value\nprint(student)                              # {\"name\": \"Alice\", \"age\": 20, \"grade\": \"B\"}\n</code></pre> <code>setdefault()</code> adds a key with a default value only if the key doesn't already exist. It returns the existing value if the key is present, or the new default value if it's not.</p>"},{"location":"intro-to-python/dictionary/#removing-elements","title":"Removing Elements","text":"<p>del statement: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\", \"major\": \"CS\"}\ndel student[\"grade\"]            # Remove specific key-value pair\n# del student[\"height\"]         # KeyError - key doesn't exist\nprint(student)                  # {\"name\": \"Alice\", \"age\": 20, \"major\": \"CS\"}\n</code></pre>  The <code>del</code> statement permanently removes a key-value pair from the dictionary. If the key doesn't exist, it raises a KeyError.</p> <p>pop() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nremoved_grade = student.pop(\"grade\")        # Returns \"A\" and removes the key\nmissing = student.pop(\"height\", \"Unknown\")  # Returns \"Unknown\" (default), no error\n# student.pop(\"height\")                     # KeyError - no default provided\n</code></pre>  The <code>pop()</code> method removes a key and returns its value. You can provide a default value to return if the key doesn't exist, preventing KeyError.</p> <p>popitem() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nlast_item = student.popitem()   # Returns (\"grade\", \"A\") - removes last inserted item\nprint(student)                  # {\"name\": \"Alice\", \"age\": 20}\n\nempty_dict = {}\n# empty_dict.popitem()          # KeyError - can't pop from empty dictionary\n</code></pre>  The <code>popitem()</code> method removes and returns the last inserted key-value pair as a tuple. In older Python versions (&lt;3.7), it removed an arbitrary item. Raises KeyError on empty dictionary.</p> <p>clear() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nstudent.clear()                 # Remove all key-value pairs\nprint(student)                  # {} - empty dictionary\n</code></pre>  The <code>clear()</code> method removes all elements from the dictionary, leaving it empty but not deleting the dictionary variable itself.</p>"},{"location":"intro-to-python/dictionary/#dictionary-methods-for-information","title":"Dictionary Methods for Information","text":""},{"location":"intro-to-python/dictionary/#getting-keys-values-and-items","title":"Getting Keys, Values, and Items","text":"<p>keys() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nall_keys = student.keys()       # dict_keys(['name', 'age', 'grade'])\nkey_list = list(student.keys()) # ['name', 'age', 'grade'] - convert to list\n</code></pre>  The <code>keys()</code> method returns a view of all dictionary keys. It's not a list, but you can convert it to a list or iterate over it. The view updates automatically if the dictionary changes.</p> <p>values() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nall_values = student.values()   # dict_values(['Alice', 20, 'A'])\nvalue_list = list(student.values())  # ['Alice', 20, 'A'] - convert to list\n</code></pre>  The <code>values()</code> method returns a view of all dictionary values. Like keys(), it returns a view object that reflects changes to the original dictionary.</p> <p>items() method: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nall_items = student.items()     # dict_items([('name', 'Alice'), ('age', 20), ('grade', 'A')])\nitem_list = list(student.items())    # [('name', 'Alice'), ('age', 20), ('grade', 'A')]\n</code></pre>  The <code>items()</code> method returns a view of all key-value pairs as tuples. This is particularly useful when you need both keys and values together.</p>"},{"location":"intro-to-python/dictionary/#checking-dictionary-contents","title":"Checking Dictionary Contents","text":"<p>Membership testing with 'in': <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nprint(\"name\" in student)        # True - checks if key exists\nprint(\"Alice\" in student)       # False - checks keys, not values\nprint(\"height\" in student)      # False - key doesn't exist\n\n# Check if value exists (slower operation)\nprint(\"Alice\" in student.values())     # True - checks values\n</code></pre>  The <code>in</code> operator checks if a key exists in the dictionary (not values). To check for values, use <code>in</code> with the <code>values()</code> method, but this is slower than key checking.</p> <p>Length: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\nprint(len(student))             # 3 - number of key-value pairs\n</code></pre>  The <code>len()</code> function returns the number of key-value pairs in the dictionary.</p>"},{"location":"intro-to-python/dictionary/#dictionary-operations-and-methods","title":"Dictionary Operations and Methods","text":""},{"location":"intro-to-python/dictionary/#copying-dictionaries","title":"Copying Dictionaries","text":"<p>copy() method (shallow copy): <pre><code>original = {\"name\": \"Alice\", \"scores\": [85, 92, 78]}\nshallow_copy = original.copy()\n\nshallow_copy[\"name\"] = \"Bob\"            # Changes only the copy\nshallow_copy[\"scores\"].append(95)       # Changes both (shared list object)\n\nprint(original)     # {\"name\": \"Alice\", \"scores\": [85, 92, 78, 95]}\nprint(shallow_copy) # {\"name\": \"Bob\", \"scores\": [85, 92, 78, 95]}\n</code></pre>  The <code>copy()</code> method creates a shallow copy. Changes to immutable values (strings, numbers) only affect the copy, but changes to mutable objects (lists, dictionaries) affect both copies because they share the same object reference.</p> <p>Using dict() constructor: <pre><code>original = {\"a\": 1, \"b\": 2, \"c\": 3}\ncopy_dict = dict(original)      # Creates shallow copy\nanother_copy = {**original}     # Dictionary unpacking - also shallow copy\n</code></pre>  Both <code>dict()</code> constructor and dictionary unpacking <code>{**dict}</code> create shallow copies of the original dictionary.</p>"},{"location":"intro-to-python/dictionary/#dictionary-comprehensions","title":"Dictionary Comprehensions","text":"<p>Basic dictionary comprehension: <pre><code># Create dictionary from range\nsquares = {x: x**2 for x in range(1, 6)}   # {1: 1, 2: 4, 3: 9, 4: 16, 5: 25}\n\n# Transform existing dictionary\nstudent = {\"name\": \"alice\", \"city\": \"new york\", \"major\": \"cs\"}\nuppercase = {key: value.upper() for key, value in student.items()}\n# {\"name\": \"ALICE\", \"city\": \"NEW YORK\", \"major\": \"CS\"}\n</code></pre>  Dictionary comprehensions create new dictionaries using a concise syntax. The format is <code>{key_expression: value_expression for item in iterable}</code>.</p> <p>Dictionary comprehension with conditions: <pre><code>numbers = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5}\neven_only = {key: value for key, value in numbers.items() if value % 2 == 0}\n# {\"b\": 2, \"d\": 4}\n\n# Filter by key\nlong_keys = {key: value for key, value in numbers.items() if len(key) &gt; 1}\n</code></pre>  You can add conditions to filter which items are included in the new dictionary. The condition comes after the <code>for</code> clause.</p>"},{"location":"intro-to-python/dictionary/#working-with-nested-dictionaries","title":"Working with Nested Dictionaries","text":""},{"location":"intro-to-python/dictionary/#accessing-nested-data","title":"Accessing Nested Data","text":"<p><pre><code>students = {\n    \"alice\": {\"age\": 20, \"grades\": {\"math\": 85, \"science\": 92}},\n    \"bob\": {\"age\": 22, \"grades\": {\"math\": 78, \"science\": 88}}\n}\n\n# Accessing nested values\nalice_age = students[\"alice\"][\"age\"]                    # 20\nalice_math = students[\"alice\"][\"grades\"][\"math\"]        # 85\n\n# Safe access with get()\ncharlie_age = students.get(\"charlie\", {}).get(\"age\", \"Unknown\")  # \"Unknown\"\n</code></pre>  Access nested dictionary values by chaining square brackets or <code>get()</code> methods. Using <code>get()</code> with empty dict as default prevents KeyError when intermediate keys don't exist.</p>"},{"location":"intro-to-python/dictionary/#updating-nested-dictionaries","title":"Updating Nested Dictionaries","text":"<p><pre><code>students = {\n    \"alice\": {\"age\": 20, \"grades\": {\"math\": 85, \"science\": 92}}\n}\n\n# Add new nested data\nstudents[\"alice\"][\"major\"] = \"Computer Science\"\nstudents[\"alice\"][\"grades\"][\"english\"] = 90\n\n# Add new student\nstudents[\"bob\"] = {\"age\": 22, \"grades\": {\"math\": 78}}\n</code></pre>  You can add or modify nested dictionary values using multiple levels of square bracket notation.</p>"},{"location":"intro-to-python/dictionary/#dictionary-performance-and-use-cases","title":"Dictionary Performance and Use Cases","text":""},{"location":"intro-to-python/dictionary/#performance-characteristics","title":"Performance Characteristics","text":"<p>Fast Operations: - Key lookup: <code>dict[key]</code> and <code>key in dict</code> are very fast (O(1) average case) - Adding/updating: <code>dict[key] = value</code> is very fast - Deleting: <code>del dict[key]</code> is very fast</p> <p>Slower Operations: - Value lookup: <code>value in dict.values()</code> is slower (O(n)) - Finding key by value: No direct method, requires iteration</p>"},{"location":"intro-to-python/dictionary/#memory-considerations","title":"Memory Considerations","text":"<p><pre><code># Dictionaries use more memory than lists for simple data\nstudent_list = [\"Alice\", 20, \"A\"]       # Less memory\nstudent_dict = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}  # More memory but more readable\n</code></pre>  Dictionaries use more memory than lists because they store keys along with values and maintain a hash table structure. However, they provide much faster key-based access.</p>"},{"location":"intro-to-python/dictionary/#common-use-cases-and-patterns","title":"Common Use Cases and Patterns","text":""},{"location":"intro-to-python/dictionary/#counting-and-grouping","title":"Counting and Grouping","text":"<p>Counting occurrences: <pre><code>text = \"hello world\"\nchar_count = {}\nfor char in text:\n    char_count[char] = char_count.get(char, 0) + 1\n# {'h': 1, 'e': 1, 'l': 3, 'o': 2, ' ': 1, 'w': 1, 'r': 1, 'd': 1}\n\n# Using setdefault\nchar_count2 = {}\nfor char in text:\n    char_count2.setdefault(char, 0)\n    char_count2[char] += 1\n</code></pre></p> <p>Grouping data: <pre><code>students = [\n    {\"name\": \"Alice\", \"grade\": \"A\"},\n    {\"name\": \"Bob\", \"grade\": \"B\"},\n    {\"name\": \"Charlie\", \"grade\": \"A\"}\n]\n\nby_grade = {}\nfor student in students:\n    grade = student[\"grade\"]\n    by_grade.setdefault(grade, []).append(student[\"name\"])\n# {\"A\": [\"Alice\", \"Charlie\"], \"B\": [\"Bob\"]}\n</code></pre></p>"},{"location":"intro-to-python/dictionary/#configuration-and-settings","title":"Configuration and Settings","text":"<pre><code># Application configuration\nconfig = {\n    \"database\": {\n        \"host\": \"localhost\",\n        \"port\": 5432,\n        \"name\": \"myapp\"\n    },\n    \"debug\": True,\n    \"max_connections\": 100\n}\n\n# Access configuration values\ndb_host = config[\"database\"][\"host\"]\ndebug_mode = config.get(\"debug\", False)  # Default to False if not specified\n</code></pre>"},{"location":"intro-to-python/dictionary/#caching-and-memoization","title":"Caching and Memoization","text":"<pre><code># Simple cache for expensive calculations\ncalculation_cache = {}\n\ndef expensive_calculation(n):\n    if n in calculation_cache:\n        return calculation_cache[n]  # Return cached result\n\n    result = n ** 2 + n * 3  # Simulate expensive calculation\n    calculation_cache[n] = result  # Cache the result\n    return result\n</code></pre>"},{"location":"intro-to-python/dictionary/#data-transformation","title":"Data Transformation","text":"<pre><code># Transform list of tuples to dictionary\nraw_data = [(\"name\", \"Alice\"), (\"age\", 20), (\"grade\", \"A\")]\nstudent_dict = dict(raw_data)  # {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\n\n# Swap keys and values\noriginal = {\"a\": 1, \"b\": 2, \"c\": 3}\nswapped = {value: key for key, value in original.items()}  # {1: \"a\", 2: \"b\", 3: \"c\"}\n\n# Filter and transform\nnumbers = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5}\neven_squares = {key: value**2 for key, value in numbers.items() if value % 2 == 0}\n# {\"b\": 4, \"d\": 16}\n</code></pre>"},{"location":"intro-to-python/dictionary/#best-practices","title":"Best Practices","text":""},{"location":"intro-to-python/dictionary/#when-to-use-dictionaries","title":"When to Use Dictionaries","text":"<p>\u2705 Good use cases: - Key-value mappings: When you need to associate keys with values - Fast lookups: When you frequently need to find data by a unique identifier - Counting: When you need to count occurrences of items - Grouping: When you need to organize data by categories - Configuration: When you need structured settings or parameters - Caching: When you want to store results for quick retrieval</p> <p>\u274c Avoid dictionaries when: - You only need ordered data without key lookups (use lists) - You need mathematical operations on all elements (use lists/arrays) - Memory usage is critical and you don't need key-based access - All your keys are sequential integers starting from 0 (use lists)</p>"},{"location":"intro-to-python/dictionary/#key-guidelines","title":"Key Guidelines","text":"<ol> <li>Use descriptive keys: <code>student[\"first_name\"]</code> is better than <code>student[\"fn\"]</code></li> <li>Be consistent with key types: Don't mix strings and numbers as keys unless necessary</li> <li>Use <code>get()</code> for optional keys: Prevents KeyError and makes code more robust</li> <li>Consider defaultdict for complex grouping: For advanced use cases (not covered here)</li> <li>Use dictionary comprehensions: They're more readable than building dictionaries with loops</li> </ol>"},{"location":"intro-to-python/dictionary/#quick-reference-summary","title":"Quick Reference Summary","text":"Operation Syntax Description Create <code>{\"key\": \"value\"}</code> Create dictionary with initial data Access <code>dict[key]</code> or <code>dict.get(key)</code> Get value by key Add/Update <code>dict[key] = value</code> Set key to value Remove <code>del dict[key]</code> or <code>dict.pop(key)</code> Remove key-value pair Check Key <code>key in dict</code> Test if key exists Get All Keys <code>dict.keys()</code> View of all keys Get All Values <code>dict.values()</code> View of all values Get All Items <code>dict.items()</code> View of all key-value pairs Copy <code>dict.copy()</code> Create shallow copy Clear <code>dict.clear()</code> Remove all items Length <code>len(dict)</code> Number of key-value pairs <p>Example combining multiple operations: <pre><code># Create and populate dictionary\ninventory = {\"apples\": 50, \"bananas\": 30, \"oranges\": 25}\n\n# Update and add items\ninventory.update({\"grapes\": 40, \"apples\": 60})  # Update apples, add grapes\ninventory[\"mangoes\"] = 15  # Add mangoes\n\n# Check and remove items\nif \"bananas\" in inventory:\n    sold_bananas = inventory.pop(\"bananas\")  # Remove and get value\n    print(f\"Sold {sold_bananas} bananas\")\n\n# Display current inventory\nprint(f\"Current inventory has {len(inventory)} items:\")\nfor item, quantity in inventory.items():\n    print(f\"  {item}: {quantity}\")\n</code></pre></p> <p>This comprehensive guide covers all the essential dictionary operations and methods with detailed explanations, practical examples, and best practices for effective dictionary usage in Python!</p>"},{"location":"intro-to-python/functions/","title":"Python Functions Guide","text":""},{"location":"intro-to-python/functions/#what-is-a-function","title":"What is a Function?","text":"<p>A function is a reusable block of code that performs a specific task. Functions help organize code, avoid repetition, and make programs easier to read and maintain.</p>"},{"location":"intro-to-python/functions/#basic-function-syntax","title":"Basic Function Syntax","text":"<pre><code>def function_name(parameters):\n    \"\"\"Optional docstring\"\"\"\n    # Function body\n    return value  # Optional\n</code></pre> <p>This is the basic template for creating a function in Python. Think of <code>def</code> as saying \"I'm going to teach you a new command.\" The function name is what you'll use to call it later, and parameters are like slots where you can put information the function needs to do its job.</p>"},{"location":"intro-to-python/functions/#simple-function-example","title":"Simple Function Example","text":"<pre><code>def greet():\n    print(\"Hello, World!\")\n\n# Call the function\ngreet()  # Output: Hello, World!\n</code></pre> <p>This creates a function called <code>greet</code> that simply prints \"Hello, World!\" to the screen. Think of it like teaching your computer a new command. Once you define it, you can use <code>greet()</code> anywhere in your program to display that message.</p>"},{"location":"intro-to-python/functions/#functions-with-parameters","title":"Functions with Parameters","text":"<pre><code>def greet_person(name):\n    print(f\"Hello, {name}!\")\n\ngreet_person(\"Alice\")  # Output: Hello, Alice!\n</code></pre> <p>Parameters are like blanks that you can fill in when using the function. Here, <code>name</code> is a parameter - it's like a placeholder. When you call <code>greet_person(\"Alice\")</code>, you're filling in that blank with \"Alice\". The function then uses whatever name you provide to create a personalized greeting.</p>"},{"location":"intro-to-python/functions/#functions-with-multiple-parameters","title":"Functions with Multiple Parameters","text":"<pre><code>def add_numbers(a, b):\n    result = a + b\n    return result\n\nsum_result = add_numbers(5, 3)\nprint(sum_result)  # Output: 8\n</code></pre> <p>This function takes two numbers as input (like ingredients in a recipe) and adds them together. The <code>return</code> statement sends the answer back to whoever called the function. It's like asking someone to calculate something for you - they do the math and give you back the result, which you can then store in a variable or use elsewhere.</p>"},{"location":"intro-to-python/functions/#default-parameters","title":"Default Parameters","text":"<pre><code>def greet_with_title(name, title=\"Mr.\"):\n    print(f\"Hello, {title} {name}!\")\n\ngreet_with_title(\"Smith\")           # Output: Hello, Mr. Smith!\ngreet_with_title(\"Johnson\", \"Dr.\")  # Output: Hello, Dr. Johnson!\n</code></pre> <p>Default parameters are like having a \"usual order\" at a restaurant. If you don't specify a title, the function automatically uses \"Mr.\" But if you want something different (like \"Dr.\"), you can specify it. This makes functions more flexible - they work even if you don't provide every piece of information.</p>"},{"location":"intro-to-python/functions/#return-values","title":"Return Values","text":"<p>Functions can return values using the <code>return</code> statement:</p> <pre><code>def multiply(x, y):\n    return x * y\n\ndef get_user_info():\n    return \"John\", 25, \"Engineer\"  # Returns multiple values as tuple\n\nresult = multiply(4, 7)  # result = 28\nname, age, job = get_user_info()  # Unpacking tuple\n</code></pre> <p>Think of <code>return</code> as the function's way of giving you an answer. The <code>multiply</code> function calculates 4 \u00d7 7 and hands back 28. The <code>get_user_info</code> function is like filling out a form and handing back multiple pieces of information at once. You can then store these returned values in variables to use later in your program.</p>"},{"location":"intro-to-python/functions/#function-with-no-return","title":"Function with No Return","text":"<p>If a function doesn't have a <code>return</code> statement, it returns <code>None</code>:</p> <pre><code>def print_info(name):\n    print(f\"Name: {name}\")\n    # No return statement means it returns None\n\nresult = print_info(\"Alice\")\nprint(result)  # Output: None\n</code></pre> <p>Some functions are like appliances that just do something (like a printer that prints) rather than giving you something back (like a calculator that gives you an answer). This function just displays information on the screen. When Python doesn't see a <code>return</code> statement, it automatically returns <code>None</code>, which means \"nothing\" or \"empty.\"</p>"},{"location":"intro-to-python/functions/#keyword-arguments","title":"Keyword Arguments","text":"<pre><code>def create_profile(name, age, city=\"Unknown\"):\n    print(f\"Name: {name}, Age: {age}, City: {city}\")\n\n# Using keyword arguments\ncreate_profile(name=\"Bob\", age=30, city=\"New York\")\ncreate_profile(age=25, name=\"Alice\")  # Order doesn't matter with keywords\n</code></pre> <p>Keyword arguments are like filling out a form where you can label each field. Instead of having to remember the exact order of information, you can specify which piece of information goes where by using labels (like <code>name=</code> and <code>age=</code>). This makes your code clearer and prevents mistakes from putting things in the wrong order.</p>"},{"location":"intro-to-python/functions/#variable-length-arguments","title":"Variable-Length Arguments","text":""},{"location":"intro-to-python/functions/#args-for-multiple-positional-arguments","title":"*args (for multiple positional arguments)","text":"<pre><code>def sum_all(*numbers):\n    total = 0\n    for num in numbers:\n        total += num\n    return total\n\nprint(sum_all(1, 2, 3, 4, 5))  # Output: 15\n</code></pre> <p>The <code>*args</code> is like having a function that can accept any number of items, like a shopping cart that can hold 1 item or 100 items. You don't know ahead of time how many numbers someone will want to add up, so <code>*args</code> lets the function accept however many numbers you give it and add them all together.</p>"},{"location":"intro-to-python/functions/#kwargs-for-multiple-keyword-arguments","title":"**kwargs (for multiple keyword arguments)","text":"<pre><code>def print_details(**details):\n    for key, value in details.items():\n        print(f\"{key}: {value}\")\n\nprint_details(name=\"Alice\", age=30, city=\"Boston\")\n# Output:\n# name: Alice\n# age: 30\n# city: Boston\n</code></pre> <p>The <code>**kwargs</code> is like a function that can accept any number of labeled pieces of information. It's like a flexible form that can have any fields you want to add. You might give it a name and age, or you might give it name, age, city, and job - the function adapts to whatever labeled information you provide.</p>"},{"location":"intro-to-python/functions/#docstrings","title":"Docstrings","text":"<p>Document your functions with docstrings:</p> <pre><code>def calculate_area(length, width):\n    \"\"\"\n    Calculate the area of a rectangle.\n\n    Args:\n        length (float): The length of the rectangle\n        width (float): The width of the rectangle\n\n    Returns:\n        float: The area of the rectangle\n    \"\"\"\n    return length * width\n</code></pre> <p>A docstring is like leaving instructions or notes about what your function does. It's like putting a label on a tool that explains what it's for and how to use it. This helps other programmers (or yourself later) understand what the function does without having to figure it out from the code.</p>"},{"location":"intro-to-python/functions/#scope-and-local-variables","title":"Scope and Local Variables","text":"<p>Variables defined inside a function are local to that function:</p> <pre><code>def my_function():\n    local_var = \"I'm local\"\n    print(local_var)\n\nmy_function()  # Output: I'm local\n# print(local_var)  # This would cause an error - local_var doesn't exist outside the function\n</code></pre> <p>Think of a function like a room in a house. Variables created inside that room (function) can only be used in that room. Once you leave the room, you can't access those variables anymore. This prevents functions from accidentally interfering with each other - each function has its own private workspace.</p>"},{"location":"intro-to-python/functions/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive names: <code>calculate_tax()</code> is better than <code>calc()</code></li> <li>Keep functions small: Each function should do one thing well</li> <li>Use docstrings: Document what your function does</li> <li>Return values instead of printing: Makes functions more reusable</li> <li>Use type hints (Python 3.5+):</li> </ol> <pre><code>def add_numbers(a: int, b: int) -&gt; int:\n    return a + b\n</code></pre> <p>Type hints are like putting labels on your function's inputs and outputs. The <code>a: int</code> means \"a should be a whole number\" and <code>-&gt; int</code> means \"this function will give back a whole number.\" It's like putting ingredients lists on recipes - it helps everyone understand what to expect.</p>"},{"location":"intro-to-python/functions/#common-function-patterns","title":"Common Function Patterns","text":""},{"location":"intro-to-python/functions/#validation-function","title":"Validation Function","text":"<pre><code>def is_valid_email(email: str) -&gt; bool:\n    return \"@\" in email and \".\" in email\n</code></pre> <p>This function checks if an email address looks valid by making sure it has both an \"@\" symbol and a period. It returns <code>True</code> if the email looks good, <code>False</code> if it doesn't. It's like having a bouncer who checks if people meet certain requirements before letting them in.</p>"},{"location":"intro-to-python/functions/#processing-function","title":"Processing Function","text":"<pre><code>def process_data(data: list) -&gt; list:\n    return [item.upper() for item in data if len(item) &gt; 2]\n</code></pre> <p>This function takes a list of text items, filters out any that are too short (2 characters or less), and converts the remaining items to uppercase. It's like having an assembly line worker who sorts items and modifies them according to specific rules before passing them along.</p>"},{"location":"intro-to-python/functions/#helper-function","title":"Helper Function","text":"<pre><code>def format_currency(amount: float) -&gt; str:\n    return f\"${amount:.2f}\"\n</code></pre> <p>This helper function takes any number and formats it to look like money (with a dollar sign and exactly 2 decimal places). So if you give it <code>15.7</code>, it returns <code>\"$15.70\"</code>. Helper functions are like having a personal assistant who handles small, repetitive tasks so you don't have to do them manually every time.</p>"},{"location":"intro-to-python/functions/#summary","title":"Summary","text":"<p>Functions are essential building blocks in Python programming. They help you: - Organize code into reusable chunks - Avoid code repetition - Make code easier to test and debug - Create more readable and maintainable programs</p> <p>Start with simple functions and gradually work your way up to more complex ones as you become comfortable with the basic concepts.</p>"},{"location":"intro-to-python/installation/","title":"Installing Python","text":"<p>Whether you're a beginner stepping into programming or a data enthusiast diving into automation, Python is a great language to start with. In this post, we\u2019ll explore various ways to install Python, both locally on your computer and through online platforms, so you can choose the one that works best for you. </p>"},{"location":"intro-to-python/installation/#installing-python-locally","title":"Installing Python Locally","text":"<p>Let's explore steps to install Python on various Operating Systems. Let's start by downloading the latest package by either hovering on Downloads and downloading package or by visiting https://www.python.org/downloads/</p> <p></p>"},{"location":"intro-to-python/installation/#installing-python-on-windows","title":"Installing python on Windows","text":"<p>Start by downloading latest .exe installer from https://www.python.org/downloads/windows/ Once downloaded, double click on it to open installer </p> <p></p> <p>After checking both boxes, click on Customize Installation and checkmark everything</p> <p></p> <p>click on Next , then checkmark as per following screenshots</p> <p></p> <p>and then click on Install. After installation is done, you can open Command Prompt and confirm if installation is done by typing</p> <pre><code>python --version\n</code></pre> <p>and if you see following result, it means your installation is done ! </p> <p></p>"},{"location":"intro-to-python/installation/#installing-python-on-ubuntu","title":"Installing python on Ubuntu","text":"<p>Open terminal and enter following command</p> <pre><code>sudo apt install python3\n</code></pre> <p>enter your password.</p> <p></p> <p>after installing python3, we also need to install pip which manages the packages in python. To install pip, execute following command</p> <pre><code>sudo apt install python3-pip\n</code></pre> <p>You can check if the installations are done correctly by typing </p> <p><pre><code>python3 --version #to check python installation\npip3 --version # to check pip installation\n</code></pre> </p>"},{"location":"intro-to-python/installation/#installing-python-on-macos","title":"Installing python on MacOS","text":"<p>Installing Python on MacOS X is similar to Windows, you can download the installer and following the commands </p> <p></p> <p>once the installation is done, check on terminal</p> <p></p>"},{"location":"intro-to-python/installation/#hosted-python-environments-no-installation-required","title":"Hosted Python Environments (No Installation Required!)","text":"<p>If you don\u2019t want to install anything yet, you can run Python in the cloud. Ideal for learning or quick testing.</p>"},{"location":"intro-to-python/installation/#google-colab","title":"Google Colab","text":"<ul> <li>URL: colab.research.google.com</li> <li>Free, cloud-based Jupyter notebooks with access to GPU</li> <li>Great for data science and ML</li> </ul>"},{"location":"intro-to-python/installation/#replit","title":"Replit","text":"<ul> <li>URL: replit.com</li> <li>Supports Python and many other languages</li> <li>Includes a file manager, debugger, and terminal</li> </ul>"},{"location":"intro-to-python/installation/#jupyter-notebook-via-binder","title":"Jupyter Notebook (via Binder)","text":"<ul> <li>URL: mybinder.org</li> <li>Turn any GitHub repo into an executable notebook</li> </ul>"},{"location":"intro-to-python/intro-to-packages/","title":"Python Packages","text":"<p>One of the reasons why Python is so loved and respected language is its vast ecosystem of packages and libraries. These packages are developed by the community and are available on PyPI (Python Package Index). These packages can be easily installed using <code>pip</code>, which is the package manager for Python. </p> <p>By making entry barrier low, Python has enabled developers to focus on solving problems rather than reinventing the wheel.</p> <p>E.g. If you are a researcher and you found out an easier way to loop through a list with million elements, you can create a package and share it with the community. This way, other developers can use your package and benefit from your work. This might seem like a small contribution, but it can have a huge impact since this can be used by applications such as web servers, data analysis tools, machine learning libraries, etc. and without you knowing it, your package might be used by thousands of developers around the world..</p> <p>This is the power of open source and community driven development. </p> <p>If you want to check the list of packages available globally, you can check the PyPI website</p> <p></p>"},{"location":"intro-to-python/intro-to-packages/#installing-packages","title":"Installing Packages","text":"<p>We are living in a time where we have packages for almost everything. From web development to data analysis, from machine learning to game development, there is a package for everything. if you are a data scientist, you might be using packages like <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code>, etc. If you are a web developer, you might be using packages like <code>Django</code>, <code>Flask</code>, etc. If you are a game developer, you might be using packages like <code>Pygame</code>, etc. </p> <p>To install a package, you can use the <code>pip</code> command followed by the package name. Make sure that you have your virtual env running before you install any package, otherwise it will be install globally, which might create conflicts. If you want to install the <code>requests</code> package, you can run the following command in your terminal:</p> <pre><code>pip install requests\n</code></pre> <p>by running this command it will install all necessary packages needed to run the <code>requests</code> package. You can also specify the version of the package that you want to install. For example, if you want to install version <code>2.25.1</code> of the <code>requests</code> package, you can run the following command:</p> <pre><code>pip install requests==2.25.1\n</code></pre> <p></p> <p>You can also install multiple packages in one go by specifying the package names separated by space. For example, if you want to install <code>requests</code>, <code>pandas</code>, and <code>numpy</code> packages, you can run the following command:</p> <pre><code>pip install requests pandas numpy\n</code></pre>"},{"location":"intro-to-python/intro-to-packages/#installing-from-requirementstxt","title":"Installing from requirements.txt","text":"<p>While working on a project, you might be using multiple packages. To make it easier to install all the packages needed for a project, you can create a <code>requirements.txt</code> file. This file contains a list of packages along with their versions that are required for your project.</p> <p>Here is an example of a <code>requirements.txt</code> file:</p> <pre><code>requests==2.25.1\npandas==1.2.3\nnumpy==1.19.5\n</code></pre> <p>Create a file named <code>requirements.txt</code> in your project directory and add the above content to it. then, to install all the packages listed in the <code>requirements.txt</code> file, you can run the following command:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>This command will read the <code>requirements.txt</code> file and install all the packages listed in it along with their specified versions. This is a very useful way to manage dependencies for your project and ensure that everyone working on the project has the same packages installed.</p> <p></p>"},{"location":"intro-to-python/intro-to-packages/#uninstalling-packages","title":"Uninstalling Packages","text":"<p>To uninstall a package, you can use the <code>pip uninstall</code> command followed by the package name. For example, if you want to uninstall the <code>requests</code> package, you can run the following command:</p> <pre><code>pip uninstall requests\n</code></pre> <p>This will shown a prompt asking for confirmation to uninstall the package. Type <code>y</code> and press <code>Enter</code> to confirm the uninstallation.</p> <p></p>"},{"location":"intro-to-python/intro-to-packages/#listing-installed-packages","title":"Listing Installed Packages","text":"<p>To list all the packages installed in your virtual environment, you can use the <code>pip list</code> command. This will show a list of all the packages along with their versions that are currently installed in your virtual environment.</p> <pre><code>pip list\n</code></pre> <p></p>"},{"location":"intro-to-python/list/","title":"Lists","text":""},{"location":"intro-to-python/list/#what-is-a-list","title":"What is a List?","text":"<p>A list is an ordered collection of elements that can be changed (mutable). Lists allow duplicate elements, maintain insertion order, and can store different data types. Lists use square brackets <code>[]</code> and elements are separated by commas.</p>"},{"location":"intro-to-python/list/#creating-lists","title":"Creating Lists","text":"<pre><code># Empty list\nempty_list = []\nalso_empty = list()\n\n# List with elements\nnumbers = [1, 2, 3, 4, 5]\nfruits = [\"apple\", \"banana\", \"orange\"]\nmixed = [1, \"hello\", 3.14, True, [1, 2, 3]]  # Different data types including nested list\n\n# Creating list from other iterables\nstring_list = list(\"hello\")         # ['h', 'e', 'l', 'l', 'o']\nrange_list = list(range(5))         # [0, 1, 2, 3, 4]\ntuple_list = list((1, 2, 3))        # [1, 2, 3] - convert tuple to list\n\n# List with repeated elements\nzeros = [0] * 5                     # [0, 0, 0, 0, 0]\nrepeated = [\"item\"] * 3             # [\"item\", \"item\", \"item\"]\n</code></pre> <p>Lists are versatile containers that can hold any type of data, including other lists. The <code>*</code> operator creates a list with repeated elements, and the <code>list()</code> function can convert other iterable objects into lists.</p>"},{"location":"intro-to-python/list/#accessing-list-elements","title":"Accessing List Elements","text":""},{"location":"intro-to-python/list/#indexing","title":"Indexing","text":"<p>Basic indexing: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"grape\", \"mango\"]\nprint(fruits[0])        # \"apple\" - first element (index starts at 0)\nprint(fruits[1])        # \"banana\" - second element\nprint(fruits[4])        # \"mango\" - fifth element\n# print(fruits[5])      # IndexError - index out of range\n</code></pre> List indexing starts at 0 for the first element. Trying to access an index that doesn't exist raises an IndexError.</p> <p>Negative indexing: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"grape\", \"mango\"]\nprint(fruits[-1])       # \"mango\" - last element\nprint(fruits[-2])       # \"grape\" - second to last element\nprint(fruits[-5])       # \"apple\" - first element (same as fruits[0])\n# print(fruits[-6])     # IndexError - negative index too large\n</code></pre> Negative indices count from the end of the list. <code>-1</code> is the last element, <code>-2</code> is second to last, and so on.</p>"},{"location":"intro-to-python/list/#slicing","title":"Slicing","text":"<p>Basic slicing: <pre><code>numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(numbers[2:5])     # [2, 3, 4] - elements from index 2 to 4 (5 not included)\nprint(numbers[:3])      # [0, 1, 2] - first three elements\nprint(numbers[3:])      # [3, 4, 5, 6, 7, 8, 9] - from index 3 to end\nprint(numbers[:])       # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] - entire list (copy)\n</code></pre> Slicing creates a new list with selected elements. The syntax is <code>[start:stop]</code> where <code>stop</code> is not included. Omitting <code>start</code> means from beginning, omitting <code>stop</code> means to end.</p> <p>Advanced slicing with step: <pre><code>numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(numbers[::2])     # [0, 2, 4, 6, 8] - every second element\nprint(numbers[1::2])    # [1, 3, 5, 7, 9] - every second element starting from index 1\nprint(numbers[::-1])    # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] - reverse the list\nprint(numbers[2:8:2])   # [2, 4, 6] - from index 2 to 7, every second element\n</code></pre> The full slicing syntax is <code>[start:stop:step]</code>. A step of 2 takes every second element, and a negative step reverses the direction.</p>"},{"location":"intro-to-python/list/#modifying-lists","title":"Modifying Lists","text":""},{"location":"intro-to-python/list/#adding-elements","title":"Adding Elements","text":"<p>append() method: <pre><code>fruits = [\"apple\", \"banana\"]\nfruits.append(\"orange\")         # Add single element to the end\nprint(fruits)                   # [\"apple\", \"banana\", \"orange\"]\n\nfruits.append([\"grape\", \"mango\"])  # Adds the entire list as one element\nprint(fruits)                   # [\"apple\", \"banana\", \"orange\", [\"grape\", \"mango\"]]\n</code></pre> The <code>append()</code> method adds exactly one element to the end of the list. If you append a list, the entire list becomes a single element (nested list).</p> <p>extend() method: <pre><code>fruits = [\"apple\", \"banana\"]\nfruits.extend([\"orange\", \"grape\"])     # Add multiple elements from iterable\nprint(fruits)                          # [\"apple\", \"banana\", \"orange\", \"grape\"]\n\nfruits.extend(\"hi\")                    # Add each character as separate element\nprint(fruits)                          # [\"apple\", \"banana\", \"orange\", \"grape\", \"h\", \"i\"]\n</code></pre> The <code>extend()</code> method adds all elements from an iterable to the end of the list. Each element is added individually, unlike <code>append()</code>.</p> <p>insert() method: <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nfruits.insert(1, \"grape\")      # Insert \"grape\" at index 1\nprint(fruits)                   # [\"apple\", \"grape\", \"banana\", \"orange\"]\n\nfruits.insert(0, \"mango\")      # Insert at beginning\nprint(fruits)                   # [\"mango\", \"apple\", \"grape\", \"banana\", \"orange\"]\n\nfruits.insert(100, \"kiwi\")     # Insert beyond list length (adds to end)\nprint(fruits)                   # [\"mango\", \"apple\", \"grape\", \"banana\", \"orange\", \"kiwi\"]\n</code></pre> The <code>insert()</code> method adds an element at a specific position. All elements at and after that position shift to the right. If the index is larger than the list length, it adds to the end.</p> <p>Using + operator: <pre><code>list1 = [1, 2, 3]\nlist2 = [4, 5, 6]\ncombined = list1 + list2        # [1, 2, 3, 4, 5, 6] - creates new list\nlist1 += [7, 8]                 # Modify list1 in place: [1, 2, 3, 7, 8]\n</code></pre> The <code>+</code> operator creates a new list by combining existing lists. The <code>+=</code> operator modifies the original list in place (equivalent to <code>extend()</code>).</p>"},{"location":"intro-to-python/list/#removing-elements","title":"Removing Elements","text":"<p>remove() method: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"banana\", \"grape\"]\nfruits.remove(\"banana\")         # Removes first occurrence of \"banana\"\nprint(fruits)                   # [\"apple\", \"orange\", \"banana\", \"grape\"]\n# fruits.remove(\"mango\")        # ValueError - element not in list\n</code></pre> The <code>remove()</code> method removes the first occurrence of the specified value. If the value doesn't exist, it raises a ValueError.</p> <p>pop() method: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"grape\"]\nlast_fruit = fruits.pop()       # Remove and return last element: \"grape\"\nsecond_fruit = fruits.pop(1)    # Remove and return element at index 1: \"banana\"\nprint(fruits)                   # [\"apple\", \"orange\"]\n# fruits.pop(10)                # IndexError - index out of range\n</code></pre> The <code>pop()</code> method removes and returns an element. Without arguments, it removes the last element. With an index argument, it removes the element at that position.</p> <p>del statement: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"grape\", \"mango\"]\ndel fruits[1]                   # Remove element at index 1\nprint(fruits)                   # [\"apple\", \"orange\", \"grape\", \"mango\"]\n\ndel fruits[1:3]                 # Remove slice (elements at index 1 and 2)\nprint(fruits)                   # [\"apple\", \"mango\"]\n\ndel fruits[:]                   # Remove all elements (same as clear())\nprint(fruits)                   # []\n</code></pre> The <code>del</code> statement can remove elements by index, slices, or entire variables. It's more flexible than <code>pop()</code> because it can remove multiple elements at once.</p> <p>clear() method: <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nfruits.clear()                  # Remove all elements\nprint(fruits)                   # []\n</code></pre> The <code>clear()</code> method removes all elements from the list, leaving an empty list.</p>"},{"location":"intro-to-python/list/#modifying-elements","title":"Modifying Elements","text":"<p>Direct assignment: <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nfruits[1] = \"grape\"             # Replace element at index 1\nprint(fruits)                   # [\"apple\", \"grape\", \"orange\"]\n\nfruits[0:2] = [\"mango\", \"kiwi\", \"peach\"]  # Replace slice with multiple elements\nprint(fruits)                   # [\"mango\", \"kiwi\", \"peach\", \"orange\"]\n</code></pre> You can modify list elements by assigning new values to specific indices or slices. Slice assignment can change the list length.</p>"},{"location":"intro-to-python/list/#list-methods-for-information-and-organization","title":"List Methods for Information and Organization","text":""},{"location":"intro-to-python/list/#finding-elements","title":"Finding Elements","text":"<p>index() method: <pre><code>fruits = [\"apple\", \"banana\", \"orange\", \"banana\", \"grape\"]\nbanana_index = fruits.index(\"banana\")       # Returns 1 (first occurrence)\n# mango_index = fruits.index(\"mango\")       # ValueError - not in list\n\n# Search within a range\nlater_banana = fruits.index(\"banana\", 2)    # Returns 3 (first occurrence at/after index 2)\nrange_search = fruits.index(\"banana\", 1, 4) # Search between index 1 and 3\n</code></pre> The <code>index()</code> method returns the position of the first occurrence of a value. You can specify start and end positions for the search. Raises ValueError if not found.</p> <p>count() method: <pre><code>numbers = [1, 2, 3, 2, 4, 2, 5, 2]\ncount_2 = numbers.count(2)      # Returns 4 (appears 4 times)\ncount_7 = numbers.count(7)      # Returns 0 (doesn't appear)\n\nfruits = [\"apple\", \"banana\", \"apple\"]\ncount_apple = fruits.count(\"apple\")  # Returns 2\n</code></pre> The <code>count()</code> method returns how many times a specific value appears in the list. Returns 0 if the value is not found.</p>"},{"location":"intro-to-python/list/#membership-testing","title":"Membership Testing","text":"<p><pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nprint(\"banana\" in fruits)       # True - element exists\nprint(\"grape\" in fruits)        # False - element doesn't exist\nprint(\"apple\" not in fruits)    # False - opposite of \"in\"\n\n# Check for sublists (doesn't work as expected)\nnumbers = [1, 2, 3, 4, 5]\nprint([2, 3] in numbers)        # False - checks for exact sublist as element\nprint(2 in numbers and 3 in numbers)  # True - check individual elements\n</code></pre> The <code>in</code> operator checks if a value exists in the list. For sublists, you need to check each element individually as <code>in</code> looks for exact matches.</p>"},{"location":"intro-to-python/list/#list-length-and-properties","title":"List Length and Properties","text":"<p><pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nprint(len(fruits))              # 3 - number of elements\n\nmixed = [1, \"hello\", [1, 2, 3], {\"key\": \"value\"}]\nprint(len(mixed))               # 4 - counts nested structures as single elements\n\nempty = []\nprint(len(empty))               # 0 - empty list\n</code></pre> The <code>len()</code> function returns the number of elements in the list. Nested structures (lists, dictionaries) count as single elements.</p>"},{"location":"intro-to-python/list/#organizing-lists","title":"Organizing Lists","text":""},{"location":"intro-to-python/list/#sorting","title":"Sorting","text":"<p>sort() method (modifies original list): <pre><code>numbers = [3, 1, 4, 1, 5, 9, 2, 6]\nnumbers.sort()                  # Sort in ascending order\nprint(numbers)                  # [1, 1, 2, 3, 4, 5, 6, 9]\n\nnumbers.sort(reverse=True)      # Sort in descending order\nprint(numbers)                  # [9, 6, 5, 4, 3, 2, 1, 1]\n\nfruits = [\"banana\", \"apple\", \"orange\", \"grape\"]\nfruits.sort()                   # Alphabetical sorting\nprint(fruits)                   # [\"apple\", \"banana\", \"grape\", \"orange\"]\n</code></pre> The <code>sort()</code> method modifies the original list. It sorts in ascending order by default, use <code>reverse=True</code> for descending. Strings are sorted alphabetically.</p> <p>sorted() function (creates new list): <pre><code>numbers = [3, 1, 4, 1, 5, 9, 2, 6]\nsorted_numbers = sorted(numbers)         # Create new sorted list\nprint(numbers)                           # [3, 1, 4, 1, 5, 9, 2, 6] - original unchanged\nprint(sorted_numbers)                    # [1, 1, 2, 3, 4, 5, 6, 9] - new sorted list\n\nreverse_sorted = sorted(numbers, reverse=True)  # [9, 6, 5, 4, 3, 2, 1, 1]\n</code></pre> The <code>sorted()</code> function creates a new sorted list without modifying the original. Use this when you need to keep the original order intact.</p> <p>Custom sorting with key parameter: <pre><code>words = [\"apple\", \"pie\", \"cherry\", \"a\"]\nwords.sort(key=len)             # Sort by string length\nprint(words)                    # [\"a\", \"pie\", \"apple\", \"cherry\"]\n\nstudents = [\"Alice\", \"bob\", \"Charlie\", \"diana\"]\nstudents.sort(key=str.lower)    # Case-insensitive sorting\nprint(students)                 # [\"Alice\", \"bob\", \"Charlie\", \"diana\"]\n</code></pre> The <code>key</code> parameter accepts a function that determines how to compare elements. <code>len</code> sorts by length, <code>str.lower</code> ignores case differences.</p>"},{"location":"intro-to-python/list/#reversing","title":"Reversing","text":"<p>reverse() method: <pre><code>numbers = [1, 2, 3, 4, 5]\nnumbers.reverse()               # Reverse the list in place\nprint(numbers)                  # [5, 4, 3, 2, 1]\n</code></pre> The <code>reverse()</code> method reverses the order of elements in the original list.</p> <p>Using slicing to reverse: <pre><code>numbers = [1, 2, 3, 4, 5]\nreversed_copy = numbers[::-1]   # Create new reversed list\nprint(numbers)                  # [1, 2, 3, 4, 5] - original unchanged\nprint(reversed_copy)            # [5, 4, 3, 2, 1] - new reversed list\n</code></pre> Slicing with <code>[::-1]</code> creates a new reversed list without modifying the original.</p>"},{"location":"intro-to-python/list/#copying-lists","title":"Copying Lists","text":""},{"location":"intro-to-python/list/#shallow-copy-methods","title":"Shallow Copy Methods","text":"<p>copy() method: <pre><code>original = [1, 2, [3, 4], 5]\nshallow_copy = original.copy()\n\nshallow_copy[0] = 99            # Changes only the copy\nshallow_copy[2].append(5)       # Changes both (shared nested list)\n\nprint(original)                 # [1, 2, [3, 4, 5], 5]\nprint(shallow_copy)             # [99, 2, [3, 4, 5], 5]\n</code></pre> The <code>copy()</code> method creates a shallow copy. Changes to immutable elements only affect the copy, but changes to nested mutable objects affect both lists.</p> <p>Using slicing to copy: <pre><code>original = [1, 2, 3, 4, 5]\ncopy_by_slice = original[:]     # Create copy using full slice\ncopy_by_list = list(original)   # Create copy using list() constructor\n</code></pre> Both <code>[:]</code> slicing and <code>list()</code> constructor create shallow copies of the original list.</p>"},{"location":"intro-to-python/list/#list-comprehensions","title":"List Comprehensions","text":""},{"location":"intro-to-python/list/#basic-list-comprehensions","title":"Basic List Comprehensions","text":"<p>Creating new lists: <pre><code># Squares of numbers\nsquares = [x**2 for x in range(1, 6)]       # [1, 4, 9, 16, 25]\n\n# Transform existing list\nwords = [\"hello\", \"world\", \"python\"]\nuppercase = [word.upper() for word in words]  # [\"HELLO\", \"WORLD\", \"PYTHON\"]\nlengths = [len(word) for word in words]      # [5, 5, 6]\n</code></pre> List comprehensions create new lists using the syntax <code>[expression for item in iterable]</code>. They're more concise than traditional loops for creating lists.</p> <p>List comprehensions with conditions: <pre><code>numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nevens = [x for x in numbers if x % 2 == 0]   # [2, 4, 6, 8, 10]\neven_squares = [x**2 for x in numbers if x % 2 == 0]  # [4, 16, 36, 64, 100]\n\n# Conditional expression (ternary operator)\nsigns = [\"positive\" if x &gt; 0 else \"negative\" for x in [-2, -1, 0, 1, 2]]\n# [\"negative\", \"negative\", \"negative\", \"positive\", \"positive\"]\n</code></pre> You can add conditions to filter elements (<code>if condition</code> at the end) or use conditional expressions to transform values (<code>value_if_true if condition else value_if_false</code>).</p> <p>Nested list comprehensions: <pre><code># Flatten nested list\nnested = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened = [item for sublist in nested for item in sublist]\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# Create multiplication table\nmult_table = [[i * j for j in range(1, 4)] for i in range(1, 4)]\n# [[1, 2, 3], [2, 4, 6], [3, 6, 9]]\n</code></pre> You can nest comprehensions for more complex operations. The order of <code>for</code> clauses matches the order of nested loops.</p>"},{"location":"intro-to-python/list/#working-with-nested-lists","title":"Working with Nested Lists","text":""},{"location":"intro-to-python/list/#accessing-nested-elements","title":"Accessing Nested Elements","text":"<p><pre><code>matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nprint(matrix[0])        # [1, 2, 3] - first row\nprint(matrix[0][1])     # 2 - first row, second column\nprint(matrix[2][0])     # 7 - third row, first column\n\n# Modify nested elements\nmatrix[1][1] = 99       # Change middle element\nprint(matrix)           # [[1, 2, 3], [4, 99, 6], [7, 8, 9]]\n</code></pre> Access nested list elements by chaining indices. The first index selects the inner list, the second index selects the element within that list.</p>"},{"location":"intro-to-python/list/#operations-on-nested-lists","title":"Operations on Nested Lists","text":"<p><pre><code># Sum all elements in nested lists\nnested_numbers = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\ntotal = sum(sum(sublist) for sublist in nested_numbers)  # 45\n\n# Find maximum in each sublist\nmax_in_each = [max(sublist) for sublist in nested_numbers]  # [3, 5, 9]\n\n# Get all elements from nested lists\nall_elements = [item for sublist in nested_numbers for item in sublist]\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n</code></pre> You can perform operations on nested lists using comprehensions and built-in functions like <code>sum()</code> and <code>max()</code>.</p>"},{"location":"intro-to-python/list/#list-performance-and-memory","title":"List Performance and Memory","text":""},{"location":"intro-to-python/list/#performance-characteristics","title":"Performance Characteristics","text":"<p>Fast Operations (O(1) - constant time): - Access by index: <code>list[i]</code> - Append to end: <code>list.append(item)</code> - Get length: <code>len(list)</code> - Pop from end: <code>list.pop()</code></p> <p>Slow Operations (O(n) - linear time): - Search for item: <code>item in list</code> - Insert at beginning: <code>list.insert(0, item)</code> - Remove by value: <code>list.remove(item)</code> - Pop from beginning: <code>list.pop(0)</code></p> <p><pre><code># Fast: append to end\nmy_list = []\nfor i in range(1000):\n    my_list.append(i)  # Fast operation\n\n# Slow: insert at beginning\nmy_list = []\nfor i in range(1000):\n    my_list.insert(0, i)  # Slow operation - shifts all elements\n</code></pre> Operations at the end of lists are fast, while operations at the beginning or middle require shifting elements and are slower for large lists.</p>"},{"location":"intro-to-python/list/#memory-considerations","title":"Memory Considerations","text":"<p><pre><code># Lists pre-allocate memory for efficiency\nimport sys\nmy_list = []\nfor i in range(10):\n    my_list.append(i)\n    print(f\"Length: {len(my_list)}, Memory: {sys.getsizeof(my_list)} bytes\")\n</code></pre> Python lists pre-allocate extra memory space to make append operations faster. The memory size grows in chunks, not with every single element.</p>"},{"location":"intro-to-python/list/#common-patterns-and-use-cases","title":"Common Patterns and Use Cases","text":""},{"location":"intro-to-python/list/#data-processing","title":"Data Processing","text":"<p>Filtering data: <pre><code>numbers = [1, -2, 3, -4, 5, -6, 7, -8, 9, -10]\npositives = [x for x in numbers if x &gt; 0]        # [1, 3, 5, 7, 9]\nnegative_squares = [x**2 for x in numbers if x &lt; 0]  # [4, 16, 36, 64, 100]\n</code></pre></p> <p>Transforming data: <pre><code>temperatures_celsius = [0, 20, 30, 100]\ntemperatures_fahrenheit = [c * 9/5 + 32 for c in temperatures_celsius]\n# [32.0, 68.0, 86.0, 212.0]\n\nnames = [\"alice\", \"bob\", \"charlie\"]\nformatted_names = [name.title() for name in names]  # [\"Alice\", \"Bob\", \"Charlie\"]\n</code></pre></p>"},{"location":"intro-to-python/list/#working-with-multiple-lists","title":"Working with Multiple Lists","text":"<p>Zip for parallel iteration: <pre><code>names = [\"Alice\", \"Bob\", \"Charlie\"]\nages = [25, 30, 35]\ncombined = list(zip(names, ages))       # [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n\n# Create dictionary from two lists\nname_age_dict = dict(zip(names, ages))  # {\"Alice\": 25, \"Bob\": 30, \"Charlie\": 35}\n</code></pre> The <code>zip()</code> function pairs elements from multiple lists, creating tuples of corresponding elements.</p> <p>Unpacking lists: <pre><code>coordinates = [10, 20]\nx, y = coordinates          # x = 10, y = 20\n\ndata = [1, 2, 3, 4, 5]\nfirst, *middle, last = data # first = 1, middle = [2, 3, 4], last = 5\n</code></pre> You can unpack list elements into separate variables. The <code>*</code> operator collects multiple elements into a new list.</p>"},{"location":"intro-to-python/list/#accumulating-results","title":"Accumulating Results","text":"<pre><code># Calculate cumulative sum\nnumbers = [1, 2, 3, 4, 5]\ncumulative = []\ntotal = 0\nfor num in numbers:\n    total += num\n    cumulative.append(total)    # [1, 3, 6, 10, 15]\n\n# Build list of unique elements (preserving order)\noriginal = [1, 2, 2, 3, 1, 4, 3, 5]\nunique = []\nfor item in original:\n    if item not in unique:\n        unique.append(item)     # [1, 2, 3, 4, 5]\n</code></pre>"},{"location":"intro-to-python/list/#best-practices","title":"Best Practices","text":""},{"location":"intro-to-python/list/#when-to-use-lists","title":"When to Use Lists","text":"<p>\u2705 Good use cases: - Ordered data: When the sequence of elements matters - Indexed access: When you need to access elements by position - Dynamic size: When the number of elements changes frequently - Homogeneous data: When storing similar types of data - Stack operations: When you need to add/remove from the end - Data collection: When gathering data that will be processed later</p> <p>\u274c Avoid lists when: - You need unique elements only (use sets) - You frequently search for specific values (use dictionaries) - You need key-value relationships (use dictionaries) - The data doesn't change (consider tuples) - You need mathematical operations on all elements (use numpy arrays for large data)</p>"},{"location":"intro-to-python/list/#performance-tips","title":"Performance Tips","text":"<ol> <li>Append instead of insert: Use <code>append()</code> for adding elements when order doesn't matter</li> <li>Extend instead of multiple appends: Use <code>extend()</code> to add multiple elements at once</li> <li>List comprehensions: Often faster than equivalent loops for creating lists</li> <li>Slice assignment: Efficient for replacing multiple elements</li> <li>Use appropriate data structures: Consider sets for membership testing, dictionaries for lookups</li> </ol>"},{"location":"intro-to-python/list/#memory-tips","title":"Memory Tips","text":"<ol> <li>Pre-allocate when possible: If you know the final size, consider creating the full list first</li> <li>Delete references: Use <code>del</code> to remove references to large lists when done</li> <li>Use generators: For large datasets that you process once, consider generators instead of lists</li> <li>Slice carefully: Remember that slices create new lists and use memory</li> </ol>"},{"location":"intro-to-python/list/#quick-reference-summary","title":"Quick Reference Summary","text":"Operation Syntax Description Create <code>[1, 2, 3]</code> or <code>list()</code> Create list with initial data Access <code>list[index]</code> Get element by position Slice <code>list[start:stop:step]</code> Get multiple elements Add to end <code>list.append(item)</code> Add single element Add multiple <code>list.extend(items)</code> Add all elements from iterable Insert <code>list.insert(index, item)</code> Add element at position Remove by value <code>list.remove(value)</code> Remove first occurrence Remove by index <code>list.pop(index)</code> Remove and return element Find position <code>list.index(value)</code> Get index of first occurrence Count occurrences <code>list.count(value)</code> Count how many times value appears Sort <code>list.sort()</code> Sort list in place Reverse <code>list.reverse()</code> Reverse list in place Copy <code>list.copy()</code> or <code>list[:]</code> Create shallow copy Clear <code>list.clear()</code> Remove all elements Length <code>len(list)</code> Number of elements Check membership <code>item in list</code> Test if item exists <p>Example combining multiple operations: <pre><code># Create and populate list\nscores = [85, 92, 78, 96, 88]\n\n# Add new scores\nscores.append(94)                    # Add single score\nscores.extend([91, 87])              # Add multiple scores\n\n# Remove lowest score\nlowest = min(scores)\nscores.remove(lowest)                # Remove first occurrence of lowest\n\n# Sort and analyze\nscores.sort(reverse=True)            # Sort highest to lowest\nprint(f\"Top 3 scores: {scores[:3]}\")\n\n# Create grade categories\nhigh_scores = [score for score in scores if score &gt;= 90]\naverage_scores = [score for score in scores if 80 &lt;= score &lt; 90]\n\nprint(f\"High scores ({len(high_scores)}): {high_scores}\")\nprint(f\"Average scores ({len(average_scores)}): {average_scores}\")\nprint(f\"Overall average: {sum(scores) / len(scores):.1f}\")\n</code></pre></p> <p>This comprehensive guide covers all essential list operations with detailed explanations, practical examples, performance considerations, and best practices for effective list usage in Python!</p>"},{"location":"intro-to-python/loops/","title":"Loops in Python","text":""},{"location":"intro-to-python/loops/#what-are-loops","title":"What are Loops?","text":"<p>Loops are programming constructs that allow you to repeat a block of code multiple times. Python has two main types of loops: <code>for</code> loops (for iterating over sequences) and <code>while</code> loops (for repeating while a condition is true). Loops help avoid code repetition and make programs more efficient.</p>"},{"location":"intro-to-python/loops/#for-loops","title":"For Loops","text":"<p>A <code>for</code> loop iterates over a sequence (list, tuple, string, etc.) or other iterable objects, executing a block of code for each element.</p>"},{"location":"intro-to-python/loops/#basic-for-loop-syntax","title":"Basic For Loop Syntax","text":"<pre><code># Basic structure\nfor variable in sequence:\n    # code to execute for each item\n    pass\n</code></pre>"},{"location":"intro-to-python/loops/#iterating-over-different-data-types","title":"Iterating Over Different Data Types","text":"<p>Iterating over lists: <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nfor fruit in fruits:\n    print(fruit)\n# Output:\n# apple\n# banana\n# orange\n\nnumbers = [1, 2, 3, 4, 5]\nfor number in numbers:\n    result = number * 2\n    print(f\"{number} * 2 = {result}\")\n</code></pre> The loop variable (<code>fruit</code>, <code>number</code>) takes the value of each element in the list, one at a time, from left to right.</p> <p>Iterating over strings: <pre><code>word = \"Python\"\nfor letter in word:\n    print(letter)\n# Output: P, y, t, h, o, n (each on new line)\n\n# Count vowels in a string\ntext = \"Hello World\"\nvowel_count = 0\nfor char in text:\n    if char.lower() in \"aeiou\":\n        vowel_count += 1\nprint(f\"Number of vowels: {vowel_count}\")  # Output: 3\n</code></pre> Strings are iterable, so you can loop through each character. The loop processes each character individually.</p> <p>Iterating over tuples: <pre><code>coordinates = (10, 20, 30)\nfor coordinate in coordinates:\n    print(f\"Coordinate: {coordinate}\")\n\n# Multiple tuples\npoints = [(1, 2), (3, 4), (5, 6)]\nfor point in points:\n    print(f\"Point: {point}\")\n    print(f\"X: {point[0]}, Y: {point[1]}\")\n</code></pre> Tuples work the same way as lists in for loops. Each element becomes the loop variable's value.</p> <p>Iterating over dictionaries: <pre><code>student = {\"name\": \"Alice\", \"age\": 20, \"grade\": \"A\"}\n\n# Iterate over keys (default behavior)\nfor key in student:\n    print(f\"{key}: {student[key]}\")\n\n# Explicitly iterate over keys\nfor key in student.keys():\n    print(f\"Key: {key}\")\n\n# Iterate over values\nfor value in student.values():\n    print(f\"Value: {value}\")\n\n# Iterate over key-value pairs\nfor key, value in student.items():\n    print(f\"{key} = {value}\")\n</code></pre> By default, iterating over a dictionary loops through its keys. Use <code>.keys()</code>, <code>.values()</code>, or <code>.items()</code> for specific iteration patterns.</p>"},{"location":"intro-to-python/loops/#using-range-function","title":"Using range() Function","text":"<p>Basic range usage: <pre><code># range(stop) - numbers from 0 to stop-1\nfor i in range(5):\n    print(i)\n# Output: 0, 1, 2, 3, 4\n\n# range(start, stop) - numbers from start to stop-1\nfor i in range(2, 7):\n    print(i)\n# Output: 2, 3, 4, 5, 6\n\n# range(start, stop, step) - with custom step\nfor i in range(0, 10, 2):\n    print(i)\n# Output: 0, 2, 4, 6, 8\n</code></pre> <code>range()</code> generates a sequence of numbers. It's memory-efficient because it generates numbers on-demand rather than creating a list.</p> <p>Practical range examples: <pre><code># Count down\nfor i in range(10, 0, -1):\n    print(f\"Countdown: {i}\")\nprint(\"Blast off!\")\n\n# Create multiplication table\nnumber = 5\nfor i in range(1, 11):\n    print(f\"{number} x {i} = {number * i}\")\n\n# Generate even numbers\neven_numbers = []\nfor i in range(0, 21, 2):\n    even_numbers.append(i)\nprint(even_numbers)  # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n</code></pre> Negative step values count backwards. You can use range with any arithmetic progression.</p>"},{"location":"intro-to-python/loops/#enumerate-function","title":"Enumerate() Function","text":"<p>Getting index and value: <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nfor index, fruit in enumerate(fruits):\n    print(f\"{index}: {fruit}\")\n# Output:\n# 0: apple\n# 1: banana\n# 2: orange\n\n# Start enumeration from different number\nfor index, fruit in enumerate(fruits, start=1):\n    print(f\"#{index}: {fruit}\")\n# Output:\n# #1: apple\n# #2: banana\n# #3: orange\n</code></pre> <code>enumerate()</code> returns pairs of (index, value) for each element. The <code>start</code> parameter lets you begin counting from a different number.</p> <p>Practical enumerate examples: <pre><code># Find position of specific items\nnames = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"]\nfor index, name in enumerate(names):\n    if name == \"Charlie\":\n        print(f\"Charlie is at position {index}\")\n\n# Create numbered list\ntasks = [\"Buy groceries\", \"Walk the dog\", \"Study Python\"]\nfor number, task in enumerate(tasks, start=1):\n    print(f\"{number}. {task}\")\n</code></pre> <code>enumerate()</code> is useful when you need both the position and value of elements.</p>"},{"location":"intro-to-python/loops/#zip-function","title":"Zip() Function","text":"<p>Combining multiple sequences: <pre><code>names = [\"Alice\", \"Bob\", \"Charlie\"]\nages = [25, 30, 35]\ncities = [\"New York\", \"London\", \"Tokyo\"]\n\nfor name, age, city in zip(names, ages, cities):\n    print(f\"{name} is {age} years old and lives in {city}\")\n# Output:\n# Alice is 25 years old and lives in New York\n# Bob is 30 years old and lives in London\n# Charlie is 35 years old and lives in Tokyo\n</code></pre> <code>zip()</code> combines multiple iterables element by element. It stops when the shortest iterable is exhausted.</p> <p>Handling different lengths: <pre><code>list1 = [1, 2, 3, 4, 5]\nlist2 = [\"a\", \"b\", \"c\"]\n\nfor number, letter in zip(list1, list2):\n    print(f\"{number}: {letter}\")\n# Output: 1: a, 2: b, 3: c (stops at shortest list)\n\n# Create dictionary from two lists\nkeys = [\"name\", \"age\", \"city\"]\nvalues = [\"Alice\", 25, \"New York\"]\nperson_dict = {}\nfor key, value in zip(keys, values):\n    person_dict[key] = value\nprint(person_dict)  # {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"}\n</code></pre> <code>zip()</code> stops at the shortest sequence. It's commonly used to create dictionaries or process parallel data.</p>"},{"location":"intro-to-python/loops/#while-loops","title":"While Loops","text":"<p>A <code>while</code> loop repeats a block of code as long as a specified condition is true. It's useful when you don't know exactly how many iterations you need.</p>"},{"location":"intro-to-python/loops/#basic-while-loop-syntax","title":"Basic While Loop Syntax","text":"<pre><code># Basic structure\nwhile condition:\n    # code to execute while condition is True\n    pass\n</code></pre>"},{"location":"intro-to-python/loops/#simple-while-loop-examples","title":"Simple While Loop Examples","text":"<p>Basic counting: <pre><code>count = 0\nwhile count &lt; 5:\n    print(f\"Count: {count}\")\n    count += 1  # Important: increment to avoid infinite loop\n# Output: Count: 0, Count: 1, Count: 2, Count: 3, Count: 4\n\n# Count down\ncount = 5\nwhile count &gt; 0:\n    print(f\"Countdown: {count}\")\n    count -= 1\nprint(\"Done!\")\n</code></pre> The condition is checked before each iteration. Always ensure the condition can become false to avoid infinite loops.</p> <p>User input validation: <pre><code># Keep asking until valid input\nage = -1\nwhile age &lt; 0 or age &gt; 150:\n    age = int(input(\"Enter your age (0-150): \"))\n    if age &lt; 0 or age &gt; 150:\n        print(\"Invalid age. Please try again.\")\nprint(f\"Your age is {age}\")\n\n# Password verification\npassword = \"\"\nwhile password != \"secret123\":\n    password = input(\"Enter password: \")\n    if password != \"secret123\":\n        print(\"Incorrect password. Try again.\")\nprint(\"Access granted!\")\n</code></pre> While loops are excellent for input validation because they continue until the user provides acceptable input.</p>"},{"location":"intro-to-python/loops/#while-loop-with-calculations","title":"While Loop with Calculations","text":"<p>Sum until condition: <pre><code># Sum numbers until total exceeds 100\ntotal = 0\nnumber = 1\nwhile total &lt;= 100:\n    total += number\n    print(f\"Added {number}, total is now {total}\")\n    number += 1\nprint(f\"Final total: {total}\")\n\n# Find first power of 2 greater than 1000\npower = 1\nexponent = 0\nwhile power &lt;= 1000:\n    power *= 2\n    exponent += 1\nprint(f\"2^{exponent} = {power} (first power of 2 &gt; 1000)\")\n</code></pre> While loops are useful for calculations where you continue until reaching a target value.</p>"},{"location":"intro-to-python/loops/#while-true-with-break","title":"While True with Break","text":"<p>Infinite loop with controlled exit: <pre><code>while True:\n    user_input = input(\"Enter 'quit' to exit: \")\n    if user_input.lower() == 'quit':\n        print(\"Goodbye!\")\n        break\n    print(f\"You entered: {user_input}\")\n\n# Menu system\nwhile True:\n    print(\"\\nMenu:\")\n    print(\"1. Say Hello\")\n    print(\"2. Show Time\")\n    print(\"3. Quit\")\n\n    choice = input(\"Choose an option (1-3): \")\n\n    if choice == \"1\":\n        print(\"Hello there!\")\n    elif choice == \"2\":\n        import datetime\n        print(f\"Current time: {datetime.datetime.now()}\")\n    elif choice == \"3\":\n        print(\"Exiting...\")\n        break\n    else:\n        print(\"Invalid choice. Please try again.\")\n</code></pre> <code>while True</code> creates an infinite loop, but <code>break</code> provides controlled exit points. This pattern is common for menu systems.</p>"},{"location":"intro-to-python/loops/#loop-control-statements","title":"Loop Control Statements","text":""},{"location":"intro-to-python/loops/#break-statement","title":"Break Statement","text":"<p>Exit loop early: <pre><code># Find first even number\nnumbers = [1, 3, 7, 8, 9, 10]\nfor number in numbers:\n    if number % 2 == 0:\n        print(f\"First even number: {number}\")\n        break\n    print(f\"Checking {number} - odd\")\n\n# Search in nested structure\nstudents = [\n    {\"name\": \"Alice\", \"grade\": \"A\"},\n    {\"name\": \"Bob\", \"grade\": \"B\"},\n    {\"name\": \"Charlie\", \"grade\": \"A\"}\n]\n\nfor student in students:\n    if student[\"grade\"] == \"A\":\n        print(f\"Found A-grade student: {student['name']}\")\n        break\n</code></pre> <code>break</code> immediately exits the loop, skipping any remaining iterations. Only the innermost loop is exited in nested loops.</p> <p>Break in while loops: <pre><code># Guessing game\nsecret_number = 7\nattempts = 0\nmax_attempts = 3\n\nwhile attempts &lt; max_attempts:\n    guess = int(input(\"Guess the number (1-10): \"))\n    attempts += 1\n\n    if guess == secret_number:\n        print(f\"Correct! You found it in {attempts} attempts.\")\n        break\n    elif guess &lt; secret_number:\n        print(\"Too low!\")\n    else:\n        print(\"Too high!\")\nelse:\n    print(f\"Sorry! The number was {secret_number}\")\n</code></pre> In while loops, <code>break</code> stops the repetition immediately. The <code>else</code> clause runs if the loop completes without breaking.</p>"},{"location":"intro-to-python/loops/#continue-statement","title":"Continue Statement","text":"<p>Skip current iteration: <pre><code># Print only positive numbers\nnumbers = [-2, -1, 0, 1, 2, 3, 4, 5]\nfor number in numbers:\n    if number &lt;= 0:\n        continue  # Skip to next iteration\n    print(f\"Positive number: {number}\")\n# Output: Positive number: 1, 2, 3, 4, 5\n\n# Process only valid data\ndata = [\"abc\", \"\", \"def\", None, \"ghi\", \"   \"]\nfor item in data:\n    if not item or not item.strip():  # Skip empty or whitespace-only items\n        continue\n    print(f\"Processing: {item}\")\n</code></pre> <code>continue</code> skips the rest of the current iteration and moves to the next one. It's useful for filtering data during processing.</p> <p>Continue in while loops: <pre><code># Count only even numbers\ncount = 0\nnumber = 0\nwhile number &lt; 10:\n    number += 1\n    if number % 2 != 0:  # Skip odd numbers\n        continue\n    count += 1\n    print(f\"Even number: {number}\")\nprint(f\"Found {count} even numbers\")\n</code></pre> In while loops, <code>continue</code> jumps back to the condition check, potentially creating infinite loops if not handled carefully.</p>"},{"location":"intro-to-python/loops/#else-clause-in-loops","title":"Else Clause in Loops","text":"<p>Else with for loops: <pre><code># Search for item\nitems = [\"apple\", \"banana\", \"orange\"]\nsearch_item = \"grape\"\n\nfor item in items:\n    if item == search_item:\n        print(f\"Found {search_item}!\")\n        break\nelse:\n    print(f\"{search_item} not found in the list\")\n\n# Check if all numbers are positive\nnumbers = [1, 2, 3, 4, 5]\nfor number in numbers:\n    if number &lt;= 0:\n        print(\"Found non-positive number\")\n        break\nelse:\n    print(\"All numbers are positive\")\n</code></pre> The <code>else</code> clause runs only if the loop completes naturally (without <code>break</code>). It's useful for \"search and not found\" scenarios.</p> <p>Else with while loops: <pre><code># Find factor\nnumber = 17\ndivisor = 2\nwhile divisor &lt; number:\n    if number % divisor == 0:\n        print(f\"{number} is divisible by {divisor}\")\n        break\n    divisor += 1\nelse:\n    print(f\"{number} is a prime number\")\n</code></pre> With while loops, <code>else</code> runs if the condition becomes false naturally, not through <code>break</code>.</p>"},{"location":"intro-to-python/loops/#nested-loops","title":"Nested Loops","text":""},{"location":"intro-to-python/loops/#basic-nested-loops","title":"Basic Nested Loops","text":"<p>Loop within loop: <pre><code># Multiplication table\nfor i in range(1, 6):  # Outer loop\n    for j in range(1, 6):  # Inner loop\n        product = i * j\n        print(f\"{i} x {j} = {product}\")\n    print()  # Empty line after each table\n\n# Create 2D pattern\nrows = 4\nfor i in range(rows):\n    for j in range(i + 1):\n        print(\"*\", end=\"\")\n    print()  # New line after each row\n# Output:\n# *\n# **\n# ***\n# ****\n</code></pre> The inner loop runs completely for each iteration of the outer loop. Total iterations = outer iterations \u00d7 inner iterations.</p>"},{"location":"intro-to-python/loops/#working-with-2d-data","title":"Working with 2D Data","text":"<p>Process matrix: <pre><code>matrix = [\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n]\n\n# Print matrix with formatting\nfor row in matrix:\n    for element in row:\n        print(f\"{element:3}\", end=\"\")  # Format with width 3\n    print()  # New line after each row\n\n# Find maximum element\nmax_value = 0\nmax_position = (0, 0)\nfor i in range(len(matrix)):\n    for j in range(len(matrix[i])):\n        if matrix[i][j] &gt; max_value:\n            max_value = matrix[i][j]\n            max_position = (i, j)\nprint(f\"Maximum value {max_value} at position {max_position}\")\n</code></pre> Nested loops are essential for processing 2D data structures like matrices, tables, or grids.</p>"},{"location":"intro-to-python/loops/#breaking-from-nested-loops","title":"Breaking from Nested Loops","text":"<p>Control nested loop flow: <pre><code># Find first occurrence in 2D structure\ndata = [\n    [\"apple\", \"banana\"],\n    [\"orange\", \"grape\"],\n    [\"kiwi\", \"mango\"]\n]\n\nsearch_item = \"grape\"\nfound = False\n\nfor i, row in enumerate(data):\n    for j, item in enumerate(row):\n        if item == search_item:\n            print(f\"Found '{search_item}' at row {i}, column {j}\")\n            found = True\n            break  # Exit inner loop\n    if found:\n        break  # Exit outer loop\n\n# Alternative: using function with return\ndef find_item(data, search_item):\n    for i, row in enumerate(data):\n        for j, item in enumerate(row):\n            if item == search_item:\n                return (i, j)\n    return None\n\nposition = find_item(data, \"grape\")\nif position:\n    print(f\"Found at {position}\")\nelse:\n    print(\"Not found\")\n</code></pre> <code>break</code> only exits the innermost loop. To exit multiple levels, use a flag variable or put the loops in a function and use <code>return</code>.</p>"},{"location":"intro-to-python/loops/#loop-performance-and-best-practices","title":"Loop Performance and Best Practices","text":""},{"location":"intro-to-python/loops/#performance-considerations","title":"Performance Considerations","text":"<p>Efficient iteration: <pre><code># Slow: repeated list access\nitems = [\"a\", \"b\", \"c\", \"d\", \"e\"] * 1000\nfor i in range(len(items)):\n    print(items[i])  # Slower: index lookup each time\n\n# Fast: direct iteration\nfor item in items:\n    print(item)  # Faster: direct access\n\n# Avoid creating unnecessary lists\n# Slow: creates entire list in memory\nfor i in list(range(1000000)):\n    pass\n\n# Fast: generates numbers on demand\nfor i in range(1000000):\n    pass\n</code></pre> Direct iteration over collections is faster than index-based access. Use generators (like <code>range()</code>) instead of creating large lists in memory.</p> <p>Loop optimization tips: <pre><code># Move constant calculations outside loops\nnumbers = [1, 2, 3, 4, 5]\nmultiplier = 10\n\n# Inefficient: repeated calculation\nfor number in numbers:\n    result = number * (5 + 5)  # 5 + 5 calculated each time\n\n# Efficient: calculate once\nconstant = 5 + 5\nfor number in numbers:\n    result = number * constant\n\n# Use list comprehensions for simple operations\n# Instead of:\nsquares = []\nfor x in range(10):\n    squares.append(x ** 2)\n\n# Use:\nsquares = [x ** 2 for x in range(10)]\n</code></pre> Avoid repeated calculations inside loops and use list comprehensions for simple transformations.</p>"},{"location":"intro-to-python/loops/#memory-considerations","title":"Memory Considerations","text":"<p><pre><code># Memory-efficient iteration\ndef process_large_file():\n    # Instead of loading entire file\n    # lines = open(\"large_file.txt\").readlines()  # Memory intensive\n\n    # Process line by line\n    with open(\"large_file.txt\") as file:\n        for line in file:  # Memory efficient\n            process_line(line.strip())\n\ndef process_line(line):\n    # Process individual line\n    pass\n\n# Use generators for large datasets\ndef fibonacci_generator(n):\n    a, b = 0, 1\n    count = 0\n    while count &lt; n:\n        yield a\n        a, b = b, a + b\n        count += 1\n\n# Memory efficient: generates one number at a time\nfor fib_number in fibonacci_generator(100):\n    print(fib_number)\n</code></pre> For large datasets, use generators or process data in chunks to avoid memory issues.</p>"},{"location":"intro-to-python/loops/#common-loop-patterns","title":"Common Loop Patterns","text":""},{"location":"intro-to-python/loops/#accumulator-patterns","title":"Accumulator Patterns","text":"<p>Sum and count: <pre><code>numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Sum all numbers\ntotal = 0\nfor number in numbers:\n    total += number\nprint(f\"Sum: {total}\")\n\n# Count even numbers\neven_count = 0\nfor number in numbers:\n    if number % 2 == 0:\n        even_count += 1\nprint(f\"Even count: {even_count}\")\n\n# Find maximum\nmaximum = numbers[0]  # Initialize with first element\nfor number in numbers[1:]:  # Start from second element\n    if number &gt; maximum:\n        maximum = number\nprint(f\"Maximum: {maximum}\")\n</code></pre> Accumulator patterns build up a result over multiple iterations. Initialize the accumulator before the loop.</p>"},{"location":"intro-to-python/loops/#string-building","title":"String Building","text":"<p><pre><code># Build string from list\nwords = [\"Python\", \"is\", \"awesome\"]\nsentence = \"\"\nfor word in words:\n    sentence += word + \" \"\nsentence = sentence.strip()  # Remove trailing space\nprint(sentence)  # \"Python is awesome\"\n\n# More efficient for large strings: use join\nsentence = \" \".join(words)\nprint(sentence)\n\n# Build formatted output\nstudents = [(\"Alice\", 85), (\"Bob\", 92), (\"Charlie\", 78)]\nreport = \"\"\nfor name, score in students:\n    report += f\"{name}: {score}%\\n\"\nprint(report)\n</code></pre> String concatenation in loops can be inefficient for large strings. Use <code>join()</code> for better performance.</p>"},{"location":"intro-to-python/loops/#filtering-and-transformation","title":"Filtering and Transformation","text":"<p><pre><code># Filter data\nages = [15, 22, 17, 35, 12, 28, 19]\nadults = []\nfor age in ages:\n    if age &gt;= 18:\n        adults.append(age)\nprint(f\"Adults: {adults}\")\n\n# Transform data\ncelsius_temps = [0, 20, 30, 100]\nfahrenheit_temps = []\nfor celsius in celsius_temps:\n    fahrenheit = celsius * 9/5 + 32\n    fahrenheit_temps.append(fahrenheit)\nprint(f\"Fahrenheit: {fahrenheit_temps}\")\n\n# Combine filter and transform\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\neven_squares = []\nfor number in numbers:\n    if number % 2 == 0:  # Filter: only even numbers\n        even_squares.append(number ** 2)  # Transform: square them\nprint(f\"Even squares: {even_squares}\")\n</code></pre> Loops are commonly used to filter data (keep only certain elements) and transform data (modify elements).</p>"},{"location":"intro-to-python/loops/#error-handling-in-loops","title":"Error Handling in Loops","text":""},{"location":"intro-to-python/loops/#common-loop-errors","title":"Common Loop Errors","text":"<p>Index errors: <pre><code>numbers = [1, 2, 3, 4, 5]\n\n# Dangerous: index might go out of bounds\nfor i in range(len(numbers) + 1):  # Goes one too far!\n    try:\n        print(numbers[i])\n    except IndexError:\n        print(f\"Index {i} is out of bounds\")\n\n# Safe: direct iteration\nfor number in numbers:\n    print(number)\n</code></pre> Index-based loops can cause IndexError. Direct iteration is safer and more readable.</p> <p>Infinite loops: <pre><code># Dangerous: infinite loop\ncount = 0\nwhile count &lt; 10:\n    print(count)\n    # Forgot to increment count! This will run forever\n    # count += 1  # Uncomment to fix\n\n# Safe: always ensure condition can become false\ncount = 0\nwhile count &lt; 10:\n    print(count)\n    count += 1  # Essential for termination\n</code></pre> Always ensure while loop conditions can become false. Include increment/decrement statements where needed.</p>"},{"location":"intro-to-python/loops/#error-handling-inside-loops","title":"Error Handling Inside Loops","text":"<p><pre><code># Handle errors gracefully\ndata = [\"1\", \"2\", \"abc\", \"4\", \"def\", \"6\"]\nvalid_numbers = []\n\nfor item in data:\n    try:\n        number = int(item)\n        valid_numbers.append(number)\n    except ValueError:\n        print(f\"Skipping invalid number: {item}\")\n\nprint(f\"Valid numbers: {valid_numbers}\")\n\n# Continue processing despite errors\nfile_names = [\"file1.txt\", \"missing.txt\", \"file3.txt\"]\nfor file_name in file_names:\n    try:\n        with open(file_name, 'r') as file:\n            content = file.read()\n            print(f\"Processed {file_name}\")\n    except FileNotFoundError:\n        print(f\"File not found: {file_name}\")\n        continue  # Continue with next file\n</code></pre> Use try-except blocks inside loops to handle errors gracefully without stopping the entire loop.</p>"},{"location":"intro-to-python/loops/#best-practices-and-guidelines","title":"Best Practices and Guidelines","text":""},{"location":"intro-to-python/loops/#when-to-use-each-loop-type","title":"When to Use Each Loop Type","text":"<p>Use for loops when: - You know the exact number of iterations - You're iterating over a collection (list, tuple, string, etc.) - You need the index and value (<code>enumerate()</code>) - You're processing multiple sequences together (<code>zip()</code>)</p> <p>Use while loops when: - The number of iterations is unknown - You're waiting for a condition to be met - You're implementing game loops or interactive programs - You're processing user input until a specific condition</p>"},{"location":"intro-to-python/loops/#loop-best-practices","title":"Loop Best Practices","text":"<ol> <li> <p>Choose the right loop type: <pre><code># Good: for loop for known sequence\nfor i in range(10):\n    print(i)\n\n# Avoid: while loop for known iterations\ni = 0\nwhile i &lt; 10:\n    print(i)\n    i += 1\n</code></pre></p> </li> <li> <p>Use descriptive variable names: <pre><code># Good: descriptive names\nfor student in students:\n    print(student.name)\n\nfor row in matrix:\n    for column in row:\n        process_cell(column)\n\n# Avoid: unclear names\nfor x in students:\n    print(x.name)\n\nfor i in matrix:\n    for j in i:\n        process_cell(j)\n</code></pre></p> </li> <li> <p>Keep loops simple: <pre><code># Good: simple, focused loop\nfor number in numbers:\n    if number &gt; 0:\n        positive_numbers.append(number)\n\n# Avoid: complex nested conditions\nfor number in numbers:\n    if number &gt; 0:\n        if number % 2 == 0:\n            if number &lt; 100:\n                # Complex nested logic\n                pass\n</code></pre></p> </li> <li> <p>Use loop control statements appropriately: <pre><code># Good: clear exit condition\nfor item in items:\n    if item == target:\n        found = True\n        break\n\n# Avoid: unnecessary flags\nfound = False\nfor item in items:\n    if item == target and not found:\n        found = True\n</code></pre></p> </li> </ol>"},{"location":"intro-to-python/loops/#quick-reference-summary","title":"Quick Reference Summary","text":"Loop Type Syntax Use Case For loop <code>for item in sequence:</code> Iterate over collections For with range <code>for i in range(n):</code> Repeat n times For with enumerate <code>for i, item in enumerate(seq):</code> Need index and value For with zip <code>for a, b in zip(seq1, seq2):</code> Parallel iteration While loop <code>while condition:</code> Repeat while condition true Break <code>break</code> Exit loop immediately Continue <code>continue</code> Skip to next iteration Else <code>for/while: ... else:</code> Execute if no break occurred <p>Example combining multiple concepts: <pre><code># Comprehensive example: Student grade processor\nstudents = [\n    {\"name\": \"Alice\", \"scores\": [85, 92, 78, 96]},\n    {\"name\": \"Bob\", \"scores\": [88, 76, 90, 85]},\n    {\"name\": \"Charlie\", \"scores\": [92, 88, 94, 90]}\n]\n\nprint(\"=== STUDENT GRADE REPORT ===\\n\")\n\nfor student_num, student in enumerate(students, 1):\n    print(f\"Student #{student_num}: {student['name']}\")\n\n    # Calculate average\n    total = 0\n    valid_scores = 0\n\n    for score_num, score in enumerate(student['scores'], 1):\n        if score &lt; 0 or score &gt; 100:  # Skip invalid scores\n            print(f\"  \u26a0\ufe0f  Invalid score #{score_num}: {score}\")\n            continue\n\n        total += score\n        valid_scores += 1\n        print(f\"  Test {score_num}: {score}%\")\n\n    if valid_scores == 0:\n        print(\"  \u274c No valid scores found\")\n        continue\n\n    average = total / valid_scores\n\n    # Determine letter grade\n    if average &gt;= 90:\n        letter_grade = \"A\"\n        emoji = \"\ud83c\udf1f\"\n    elif average &gt;= 80:\n        letter_grade = \"B\"\n        emoji = \"\ud83d\udc4d\"\n    elif average &gt;= 70:\n        letter_grade = \"C\"\n        emoji = \"\ud83d\udc4c\"\n    elif average &gt;= 60:\n        letter_grade = \"D\"\n        emoji = \"\u26a0\ufe0f\"\n    else:\n        letter_grade = \"F\"\n        emoji = \"\u274c\"\n\n    print(f\"  \ud83d\udcca Average: {average:.1f}% (Grade: {letter_grade}) {emoji}\")\n    print()\n\nprint(\"Report complete!\")\n</code></pre></p> <p>This comprehensive guide covers all essential loop concepts with detailed explanations, practical examples, performance considerations, and best practices for effective loop usage in Python!</p>"},{"location":"intro-to-python/modules/","title":"Python Modules - Basic Guide","text":""},{"location":"intro-to-python/modules/#what-are-modules","title":"What are Modules?","text":"<p>A module in Python is simply a file containing Python code. It can define functions, classes, and variables, and can also include runnable code. Modules help you organize your code into separate files and reuse code across different programs.</p> <p>Think of modules as toolboxes - each toolbox (module) contains specific tools (functions) that you can use in your projects.</p>"},{"location":"intro-to-python/modules/#why-use-modules","title":"Why Use Modules?","text":"<ul> <li>Organization: Keep related code together</li> <li>Reusability: Use the same code in multiple programs</li> <li>Maintainability: Easier to update and fix code</li> <li>Avoid repetition: Write once, use many times</li> </ul>"},{"location":"intro-to-python/modules/#creating-your-own-module","title":"Creating Your Own Module","text":"<p>Creating a module is as simple as saving Python code in a <code>.py</code> file.</p>"},{"location":"intro-to-python/modules/#example-creating-a-math_helperspy-module","title":"Example: Creating a math_helpers.py module","text":"<pre><code># math_helpers.py\ndef add_numbers(a, b):\n    return a + b\n\ndef multiply_numbers(a, b):\n    return a * b\n\ndef calculate_area_circle(radius):\n    pi = 3.14159\n    return pi * radius * radius\n\n# You can also include variables\ngreeting = \"Hello from math helpers!\"\n</code></pre>"},{"location":"intro-to-python/modules/#using-modules","title":"Using Modules","text":"<p>There are several ways to import and use modules:</p>"},{"location":"intro-to-python/modules/#import-the-entire-module","title":"Import the entire module","text":"<pre><code>import math_helpers\n\nresult = math_helpers.add_numbers(5, 3)\narea = math_helpers.calculate_area_circle(10)\nprint(math_helpers.greeting)\n</code></pre>"},{"location":"intro-to-python/modules/#import-specific-functions","title":"Import specific functions","text":"<pre><code>from math_helpers import add_numbers, multiply_numbers\n\nresult = add_numbers(5, 3)  # No need for module name\nproduct = multiply_numbers(4, 7)\n</code></pre>"},{"location":"intro-to-python/modules/#3-import-with-an-alias-nickname","title":"3. Import with an alias (nickname)","text":"<pre><code>import math_helpers as mh\n\nresult = mh.add_numbers(5, 3)\n</code></pre>"},{"location":"intro-to-python/modules/#4-import-everything-not-recommended","title":"4. Import everything (not recommended)","text":"<pre><code>from math_helpers import *\n\nresult = add_numbers(5, 3)  # Can use all functions directly\n</code></pre>"},{"location":"intro-to-python/modules/#built-in-modules","title":"Built-in Modules","text":"<p>Python comes with many pre-built modules. Here are some common ones:</p>"},{"location":"intro-to-python/modules/#math-module","title":"math module","text":"<pre><code>import math\n\nprint(math.pi)          # 3.141592653589793\nprint(math.sqrt(16))    # 4.0\nprint(math.ceil(4.3))   # 5\n</code></pre>"},{"location":"intro-to-python/modules/#random-module","title":"random module","text":"<pre><code>import random\n\nprint(random.randint(1, 10))        # Random number between 1-10\nprint(random.choice(['a', 'b', 'c'])) # Random choice from list\n</code></pre>"},{"location":"intro-to-python/modules/#datetime-module","title":"datetime module","text":"<pre><code>import datetime\n\nnow = datetime.datetime.now()\nprint(now)  # Current date and time\n</code></pre>"},{"location":"intro-to-python/modules/#module-search-path","title":"Module Search Path","text":"<p>Python looks for modules in this order: 1. Current directory 2. Python's built-in modules 3. Directories in sys.path</p>"},{"location":"intro-to-python/modules/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive names: <code>calculator.py</code> is better than <code>calc.py</code></li> <li>Keep modules focused: One module should do one thing well</li> <li>Use proper imports: Import only what you need</li> <li>Document your modules: Add comments and docstrings</li> </ol>"},{"location":"intro-to-python/modules/#example-with-documentation","title":"Example with documentation:","text":"<pre><code># calculator.py\n\"\"\"\nA simple calculator module with basic operations.\n\"\"\"\n\ndef add(a, b):\n    \"\"\"Add two numbers and return the result.\"\"\"\n    return a + b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a and return the result.\"\"\"\n    return a - b\n</code></pre>"},{"location":"intro-to-python/modules/#quick-example-project","title":"Quick Example Project","text":"<p>Let's create a simple project with modules:</p> <p>File: greetings.py <pre><code>def say_hello(name):\n    \"\"\"This function creates a friendly hello message\n    It takes someone's name and returns 'Hello, [name]!'\"\"\"\n    return f\"Hello, {name}!\"\n\ndef say_goodbye(name):\n    \"\"\"This function creates a goodbye message\n    It takes someone's name and returns 'Goodbye, [name]!'\"\"\"\n    return f\"Goodbye, {name}!\"\n</code></pre></p> <p>File: main.py <pre><code>from greetings import say_hello, say_goodbye\n\nuser_name = \"Alice\"  # We store the name \"Alice\" in a variable\nprint(say_hello(user_name))    # This will create and print \"Hello, Alice!\"\nprint(say_goodbye(user_name))  # This will create and print \"Goodbye, Alice!\"\n</code></pre></p> <p>When you run <code>main.py</code>, it will output: <pre><code>Hello, Alice!\nGoodbye, Alice!\n</code></pre></p>"},{"location":"intro-to-python/modules/#summary","title":"Summary","text":"<ul> <li>Modules are Python files that contain reusable code</li> <li>Create modules by saving code in <code>.py</code> files</li> <li>Import modules using <code>import</code> statement</li> <li>Use built-in modules for common tasks</li> <li>Organize your code with modules for better structure</li> </ul> <p>Start simple and gradually build more complex modules as you learn!</p>"},{"location":"intro-to-python/oop/","title":"Object-Oriented Programming (OOP) in Python","text":"<p>Object-Oriented Programming (OOP) is one of the most powerful paradigms in Python. It allows you to model real-world entities as objects, which combine data (attributes) and behavior (methods).</p>"},{"location":"intro-to-python/oop/#what-is-oop","title":"What is OOP?","text":"<p>OOP is a programming approach where the focus is on objects rather than functions or logic. Objects are created using classes, which serve as blueprints.  </p> <p>For example: - A class defines what attributes and behaviors an object will have. - An object is an instance of that class with actual data.</p>"},{"location":"intro-to-python/oop/#key-building-blocks-of-oop","title":"Key Building Blocks of OOP","text":"<ul> <li>Class \u2192 Blueprint or template for creating objects.  </li> <li>Object \u2192 An instance of a class containing specific data.  </li> <li>Attributes \u2192 Variables that store data related to an object.  </li> <li>Methods \u2192 Functions that define the behavior of an object.  </li> <li>Constructor (<code>__init__</code>) \u2192 A special method used to initialize new objects.</li> </ul>"},{"location":"intro-to-python/oop/#example-creating-a-class-and-object","title":"Example: Creating a Class and Object","text":"<pre><code>class Car:\n    def __init__(self, brand, color):\n        self.brand = brand\n        self.color = color\n\n    def drive(self):\n        print(f\"The {self.color} {self.brand} is driving!\")\n\n# Creating objects\ncar1 = Car(\"Toyota\", \"Red\")\ncar2 = Car(\"Tesla\", \"Black\")\n\ncar1.drive()\ncar2.drive()\n</code></pre> <p>Each object (<code>car1</code>, <code>car2</code>) has its own state (brand and color) but shares the same behavior (<code>drive()</code>).</p>"},{"location":"intro-to-python/oop/#principles-of-oop","title":"Principles of OOP","text":""},{"location":"intro-to-python/oop/#encapsulation","title":"Encapsulation","text":"<p>Encapsulation means keeping the internal details of an object hidden and only exposing what\u2019s necessary. It helps prevent direct modification of internal data.</p> <pre><code>class BankAccount:\n    def __init__(self, balance):\n        self.__balance = balance   # private variable\n\n    def deposit(self, amount):\n        self.__balance += amount\n\n    def get_balance(self):\n        return self.__balance\n</code></pre> <p>Here, <code>__balance</code> cannot be accessed directly from outside the class.</p>"},{"location":"intro-to-python/oop/#inheritance","title":"Inheritance","text":"<p>Inheritance allows a class to use properties and methods of another class. It encourages code reusability.</p> <pre><code>class Animal:\n    def speak(self):\n        print(\"Animal speaks\")\n\nclass Dog(Animal):\n    def speak(self):\n        print(\"Woof!\")\n\ndog = Dog()\ndog.speak()\n</code></pre>"},{"location":"intro-to-python/oop/#polymorphism","title":"Polymorphism","text":"<p>Polymorphism means using a common interface for different types of objects. It allows methods with the same name to behave differently depending on the class.</p> <p><pre><code>class Cat:\n    def speak(self):\n        print(\"Meow!\")\n\nanimals = [Dog(), Cat()]\nfor animal in animals:\n    animal.speak()\n</code></pre> Each class implements its own version of <code>speak()</code>.</p>"},{"location":"intro-to-python/oop/#abstraction","title":"Abstraction","text":"<p>Abstraction hides the internal implementation and shows only essential features. In Python, it can be achieved using abstract base classes.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Shape(ABC):\n    @abstractmethod\n    def area(self):\n        pass\n\nclass Circle(Shape):\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return 3.14 * self.radius ** 2\n</code></pre>"},{"location":"intro-to-python/oop/#special-methods-dunder-methods","title":"Special Methods (Dunder Methods)","text":"<p>Python classes can define special (double underscore) methods that integrate with Python\u2019s built-in operations.</p> <p>Common examples: - <code>__init__</code> \u2192 Constructor - <code>__str__</code> \u2192 String representation - <code>__len__</code> \u2192 Length of an object - <code>__add__</code> \u2192 Add two objects  </p> <pre><code>class Book:\n    def __init__(self, title, pages):\n        self.title = title\n        self.pages = pages\n\n    def __str__(self):\n        return f\"Book: {self.title}\"\n\n    def __len__(self):\n        return self.pages\n\nbook = Book(\"Python Guide\", 350)\nprint(book)\nprint(len(book))\n</code></pre>"},{"location":"intro-to-python/oop/#oop-in-practice","title":"OOP in Practice","text":"<ul> <li>Real-world analogy:</li> <li>Class: Blueprint of a house  </li> <li>Object: Actual house built from the blueprint  </li> <li>Attributes: Color, size, number of rooms  </li> <li> <p>Methods: Open door, close window  </p> </li> <li> <p>Applications of OOP:</p> </li> <li>GUI frameworks (Tkinter, PyQt)</li> <li>Game development (player, enemy objects)</li> <li>Web development (Django models)</li> <li>Data analysis (Pandas DataFrames are objects)</li> </ul>"},{"location":"intro-to-python/oop/#conclusion","title":"Conclusion","text":"<p>Object-Oriented Programming helps you organize your code into manageable, modular pieces. By applying concepts like encapsulation, inheritance, polymorphism, and abstraction, you can write cleaner, reusable, and scalable Python programs.</p>"},{"location":"intro-to-python/sets-tuple/","title":"Sets and Tuples","text":""},{"location":"intro-to-python/sets-tuple/#sets","title":"Sets","text":"<p>A set is a collection of unique elements. Sets automatically remove duplicates and are unordered, meaning elements don't have a fixed position.</p>"},{"location":"intro-to-python/sets-tuple/#creating-sets","title":"Creating Sets","text":"<pre><code># Empty set - must use set() function, not {} (which creates empty dict)\nmy_set = set()\n\n# Set with elements - use curly braces with comma-separated values\nfruits = {\"apple\", \"banana\", \"orange\"}\nnumbers = {1, 2, 3, 4, 5}\n\n# Creating set from a list - automatically removes duplicates\nmy_set = set([1, 2, 2, 3, 3, 4])  # Result: {1, 2, 3, 4}\n</code></pre> <p>Sets only store unique values. If you try to create a set with duplicate elements, Python automatically keeps only one copy of each element.</p>"},{"location":"intro-to-python/sets-tuple/#basic-set-methods","title":"Basic Set Methods","text":""},{"location":"intro-to-python/sets-tuple/#adding-elements","title":"Adding Elements","text":"<p>add() method: <pre><code>fruits = {\"apple\", \"banana\"}\nfruits.add(\"orange\")        # Adds single element to the set\nprint(fruits)               # {\"apple\", \"banana\", \"orange\"}\n</code></pre>  The <code>add()</code> method adds exactly one element to the set. If the element already exists, nothing happens (no error, no duplicate).</p> <p>update() method: <pre><code>fruits = {\"apple\", \"banana\"}\nfruits.update([\"grape\", \"mango\"])    # Add multiple elements from a list\nfruits.update({\"kiwi\", \"peach\"})     # Add multiple elements from another set\nfruits.update(\"hello\")               # Adds each character: 'h', 'e', 'l', 'o'\n</code></pre>  The <code>update()</code> method can add multiple elements at once. It accepts any iterable (list, set, string, etc.). When you pass a string, each character becomes a separate element.</p>"},{"location":"intro-to-python/sets-tuple/#removing-elements","title":"Removing Elements","text":"<p>remove() method: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\nfruits.remove(\"banana\")     # Removes \"banana\" from the set\n# fruits.remove(\"grape\")    # This would cause KeyError since \"grape\" doesn't exist\n</code></pre>  The <code>remove()</code> method deletes the specified element from the set. If the element doesn't exist, Python raises a KeyError.</p> <p>discard() method: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\nfruits.discard(\"banana\")    # Removes \"banana\" from the set\nfruits.discard(\"grape\")     # No error even though \"grape\" doesn't exist\n</code></pre>  The <code>discard()</code> method is safer than <code>remove()</code> because it won't raise an error if the element doesn't exist. It simply does nothing.</p> <p>pop() method: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\nremoved_fruit = fruits.pop()    # Removes and returns a random element\nprint(removed_fruit)            # Could be any of the fruits\nprint(fruits)                   # Now missing one element\n</code></pre>  The <code>pop()</code> method removes and returns an arbitrary element from the set. Since sets are unordered, you can't predict which element will be removed. If the set is empty, it raises a KeyError.</p> <p>clear() method: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\nfruits.clear()              # Removes all elements\nprint(fruits)               # set() - empty set\n</code></pre>  The <code>clear()</code> method removes every element from the set, leaving it completely empty.</p>"},{"location":"intro-to-python/sets-tuple/#set-operations","title":"Set Operations","text":"<p>Union - combining sets: <pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Using union() method\nunion_set = set1.union(set2)        # Creates new set: {1, 2, 3, 4, 5, 6}\nunion_set = set1 | set2             # Same result using | operator\n</code></pre>  Union combines all unique elements from both sets. Elements that appear in both sets are only included once in the result.</p> <p>Intersection - finding common elements: <pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\ncommon = set1.intersection(set2)    # Creates new set: {3, 4}\ncommon = set1 &amp; set2                # Same result using &amp; operator\n</code></pre>  Intersection returns only the elements that exist in both sets. If there are no common elements, you get an empty set.</p> <p>Difference - elements in first set but not second: <pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\ndiff = set1.difference(set2)        # Creates new set: {1, 2}\ndiff = set1 - set2                  # Same result using - operator\n</code></pre>  Difference returns elements that are in the first set but not in the second set. The order matters: <code>set1 - set2</code> gives different results than <code>set2 - set1</code>.</p>"},{"location":"intro-to-python/sets-tuple/#checking-elements-and-properties","title":"Checking Elements and Properties","text":"<p>Membership testing: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\n\nprint(\"apple\" in fruits)     # True - \"apple\" exists in the set\nprint(\"grape\" in fruits)     # False - \"grape\" doesn't exist\nprint(\"apple\" not in fruits) # False - opposite of \"in\"\n</code></pre>  The <code>in</code> operator checks if an element exists in the set. It returns <code>True</code> if found, <code>False</code> if not found. This operation is very fast with sets.</p> <p>Length and set relationships: <pre><code>fruits = {\"apple\", \"banana\", \"orange\"}\nsmall_set = {\"apple\", \"banana\"}\nbig_set = {\"apple\", \"banana\", \"orange\", \"grape\", \"mango\"}\n\nprint(len(fruits))                      # 3 - number of elements\nprint(small_set.issubset(fruits))       # True - all elements of small_set are in fruits\nprint(fruits.issuperset(small_set))     # True - fruits contains all elements of small_set\nprint(fruits.isdisjoint({1, 2, 3}))     # True - no common elements\n</code></pre></p> <ul> <li><code>len()</code> returns the number of elements in the set</li> <li><code>issubset()</code> checks if all elements of the current set exist in another set</li> <li><code>issuperset()</code> checks if the current set contains all elements of another set</li> <li><code>isdisjoint()</code> returns <code>True</code> if the sets have no common elements</li> </ul>"},{"location":"intro-to-python/sets-tuple/#tuples","title":"Tuples","text":"<p>A tuple is an ordered collection of elements that cannot be changed after creation (immutable). Unlike sets, tuples allow duplicate elements and maintain the order of elements.</p>"},{"location":"intro-to-python/sets-tuple/#creating-tuples","title":"Creating Tuples","text":"<pre><code># Empty tuple - use empty parentheses\nempty_tuple = ()\n\n# Tuple with multiple elements\ncoordinates = (3, 5)\ncolors = (\"red\", \"green\", \"blue\")\nmixed = (1, \"hello\", 3.14, True)\n\n# Single element tuple - MUST include comma!\nsingle = (42,)      # Without comma, (42) is just a number in parentheses\nalso_single = 42,   # Comma makes it a tuple even without parentheses\n</code></pre> <p>Tuples use parentheses <code>()</code> but the comma is what actually makes it a tuple. For a single-element tuple, the comma is essential because <code>(42)</code> is just a number in parentheses, but <code>(42,)</code> is a tuple with one element.</p>"},{"location":"intro-to-python/sets-tuple/#basic-tuple-methods","title":"Basic Tuple Methods","text":""},{"location":"intro-to-python/sets-tuple/#accessing-elements","title":"Accessing Elements","text":"<p>Indexing: <pre><code>colors = (\"red\", \"green\", \"blue\", \"yellow\")\nprint(colors[0])        # \"red\" - first element (index starts at 0)\nprint(colors[1])        # \"green\" - second element  \nprint(colors[-1])       # \"yellow\" - last element (negative indexing)\nprint(colors[-2])       # \"blue\" - second to last element\n</code></pre>  Tuple indexing works like lists. Positive indices start from 0 at the beginning, negative indices start from -1 at the end.</p> <p>Slicing: <pre><code>colors = (\"red\", \"green\", \"blue\", \"yellow\", \"purple\")\nprint(colors[1:3])      # (\"green\", \"blue\") - elements from index 1 to 2\nprint(colors[:2])       # (\"red\", \"green\") - first two elements\nprint(colors[2:])       # (\"blue\", \"yellow\", \"purple\") - from index 2 to end\nprint(colors[::2])      # (\"red\", \"blue\", \"purple\") - every second element\n</code></pre>  Slicing creates a new tuple with selected elements. The syntax is <code>[start:stop:step]</code> where <code>stop</code> is not included in the result.</p>"},{"location":"intro-to-python/sets-tuple/#built-in-tuple-methods","title":"Built-in Tuple Methods","text":"<p>count() method: <pre><code>numbers = (1, 2, 3, 2, 4, 2, 5)\ncount_of_2 = numbers.count(2)      # Returns 3 (appears 3 times)\ncount_of_7 = numbers.count(7)      # Returns 0 (doesn't appear)\n</code></pre>  The <code>count()</code> method returns how many times a specific element appears in the tuple. If the element doesn't exist, it returns 0.</p> <p>index() method: <pre><code>numbers = (1, 2, 3, 2, 4, 2, 5)\nfirst_2_index = numbers.index(2)      # Returns 1 (first occurrence at index 1)\n# numbers.index(7)                    # Would raise ValueError since 7 doesn't exist\n\n# Find index starting from a specific position\nlater_2_index = numbers.index(2, 2)   # Returns 3 (first occurrence at/after index 2)\n</code></pre>  The <code>index()</code> method returns the position of the first occurrence of an element. If the element doesn't exist, it raises a ValueError. You can optionally specify where to start searching.</p>"},{"location":"intro-to-python/sets-tuple/#tuple-operations","title":"Tuple Operations","text":"<p>Concatenation: <pre><code>tuple1 = (1, 2, 3)\ntuple2 = (4, 5, 6)\ntuple3 = (\"a\", \"b\")\n\ncombined = tuple1 + tuple2      # (1, 2, 3, 4, 5, 6) - creates new tuple\nlong_tuple = tuple1 + tuple2 + tuple3  # (1, 2, 3, 4, 5, 6, 'a', 'b')\n</code></pre>  The <code>+</code> operator creates a new tuple by combining elements from multiple tuples in order. The original tuples remain unchanged.</p> <p>Repetition: <pre><code>base_tuple = (1, 2, 3)\nrepeated = base_tuple * 3       # (1, 2, 3, 1, 2, 3, 1, 2, 3)\nempty_repeat = base_tuple * 0   # () - empty tuple\n</code></pre>  The <code>*</code> operator creates a new tuple by repeating the original tuple a specified number of times.</p> <p>Membership testing: <pre><code>coordinates = (10, 20, 30)\nprint(20 in coordinates)        # True - 20 exists in the tuple\nprint(40 in coordinates)        # False - 40 doesn't exist\nprint(20 not in coordinates)    # False - opposite of \"in\"\n</code></pre>  The <code>in</code> operator works the same way as with sets, checking if an element exists in the tuple.</p> <p>Length: <pre><code>data = (1, \"hello\", 3.14, True, [1, 2, 3])\nprint(len(data))              # 5 - counts number of elements\n</code></pre>  The <code>len()</code> function returns the number of elements in the tuple, regardless of their types.</p>"},{"location":"intro-to-python/sets-tuple/#unpacking-tuples","title":"Unpacking Tuples","text":"<p>Basic unpacking: <pre><code>point = (10, 20)\nx, y = point                    # x gets 10, y gets 20\n\nperson = (\"Alice\", 25, \"Engineer\")\nname, age, job = person         # Each variable gets corresponding element\n</code></pre>  Unpacking assigns each element of the tuple to separate variables. The number of variables must match the number of elements in the tuple.</p> <p>Advanced unpacking with * operator: <pre><code>data = (1, 2, 3, 4, 5)\nfirst, *middle, last = data     # first=1, middle=[2, 3, 4], last=5\nfirst, *rest = data             # first=1, rest=[2, 3, 4, 5]\n*beginning, last = data         # beginning=[1, 2, 3, 4], last=5\n</code></pre>  The <code>*</code> operator collects multiple elements into a list. This allows flexible unpacking when you don't know exactly how many elements you'll have.</p>"},{"location":"intro-to-python/sets-tuple/#key-differences","title":"Key Differences","text":"Feature Set Tuple Ordered No - elements have no fixed position Yes - elements keep their position Duplicates No - automatically removes duplicates Yes - can store identical elements Mutable Yes - can add/remove elements No - cannot change after creation Indexing No - cannot access by position Yes - can access elements by index Use Case Unique collections, math operations Coordinates, fixed data, multiple return values Performance Fast membership testing Fast access by index"},{"location":"intro-to-python/sets-tuple/#common-use-cases","title":"Common Use Cases","text":""},{"location":"intro-to-python/sets-tuple/#sets_1","title":"Sets","text":"<p>Removing duplicates: When you have data with repeated values and only want unique items. <pre><code>grades = [85, 92, 78, 92, 88, 85, 95]\nunique_grades = set(grades)     # {78, 85, 88, 92, 95}\n</code></pre></p> <p>Mathematical operations: When you need to find common elements, differences, or combine collections. <pre><code>students_math = {\"Alice\", \"Bob\", \"Charlie\", \"Diana\"}\nstudents_science = {\"Bob\", \"Diana\", \"Eve\", \"Frank\"}\nboth_subjects = students_math.intersection(students_science)  # {\"Bob\", \"Diana\"}\n</code></pre></p> <p>Fast membership testing: When you frequently need to check if an element exists. <pre><code>valid_codes = {\"A1\", \"B2\", \"C3\", \"D4\"}\nuser_input = \"B2\"\nif user_input in valid_codes:  # Very fast operation\n    print(\"Valid code!\")\n</code></pre></p>"},{"location":"intro-to-python/sets-tuple/#tuples_1","title":"Tuples","text":"<p>Coordinates and paired data: When elements belong together and shouldn't change. <pre><code>location = (40.7128, -74.0060)  # Latitude, longitude for New York\nrgb_color = (255, 128, 0)       # Red, green, blue values\n</code></pre></p> <p>Multiple return values: When a function needs to return several related values. <pre><code>def get_name_age():\n    return (\"John\", 25)         # Return multiple values as tuple\n\nname, age = get_name_age()      # Unpack the returned tuple\n</code></pre></p> <p>Dictionary keys: Since tuples are immutable, they can be used as dictionary keys. <pre><code>coordinates_to_city = {\n    (40.7128, -74.0060): \"New York\",\n    (34.0522, -118.2437): \"Los Angeles\"\n}\n</code></pre></p> <p>Configuration data: When you have settings that shouldn't accidentally change. <pre><code>database_config = (\"localhost\", 5432, \"mydb\", \"user123\")\nhost, port, database, username = database_config\n</code></pre></p>"},{"location":"intro-to-python/setup-env/","title":"Setup Python Environment","text":"<p>Once you have installed python, you can start working with it. Generally when we work with python, we install <code>External Packages</code> which are not part of standard library. These packages are developed by community and are available on PyPI (Python Package Index).  But installing these packages globally can lead to version conflicts. For example, you might have two projects, one which requires <code>pandas v1.5.0</code> and another which requires <code>pandas v2.0.0</code>. Installing both versions globally is not possible and can lead to conflicts. To avoid this, we use <code>Virtual Environments</code> which are isolated environments for each project. This way, we can have different versions of packages for different projects without any conflicts. </p>"},{"location":"intro-to-python/setup-env/#venv-virtual-environment","title":"<code>venv</code> Virtual Environment","text":""},{"location":"intro-to-python/setup-env/#creating-virtual-environment","title":"Creating Virtual Environment","text":"<p>There are several ways to create virtual environments in python. The most common way is to use <code>venv</code> module which is part of standard library. To create a virtual environment, open terminal and navigate to your project directory and run following command</p> <pre><code># if you have python installed as python3\npython -m venv myenv\n\n# else you can use python3\npython3 -m venv myenv\n</code></pre> <p>The above command will create a virtual environment named <code>myenv</code> in your project directory. You can name it anything you want. </p>"},{"location":"intro-to-python/setup-env/#activating-virtual-environment","title":"Activating Virtual Environment","text":"<p>After creating the virtual environment, you need to activate it. To activate the virtual environment, run following command</p> <pre><code># on Windows\nmyenv\\Scripts\\activate\n# on MacOS and Linux\nsource myenv/bin/activate\n</code></pre> <p>After activating the virtual environment, you will see the name of the virtual environment in your terminal prompt. This indicates that you are now working inside the virtual environment.</p> <p></p>"},{"location":"intro-to-python/setup-env/#deactivating-virtual-environment","title":"Deactivating Virtual Environment","text":"<p>To deactivate the virtual environment, simply run</p> <pre><code>deactivate\n</code></pre> <p>you can confirm this by checking the terminal prompt, it should not have the name of the virtual environment anymore.</p> <p></p>"},{"location":"intro-to-python/setup-env/#conda-virtual-environment","title":"<code>Conda</code> Virtual Environment","text":"<p>Anaconda is also a popular virtual environment management solution, it also has an open source version which can be used without any licensing cost. This is typically easy to manage and share compared to <code>venv</code>.</p> <p>Checkout Installation documentation to add conda to your system and your path.</p>"},{"location":"intro-to-python/setup-env/#creating-conda-virtual-environment","title":"Creating Conda Virtual Environment","text":"<p>To create environment at minimum you just have to pass env name, along with that you can also mention python package  or version that you want to install initially. </p> <p><pre><code># Create conda env with name `mycondaenv` and python version 3.12\nconda create -n mycondaenv python==3.12\n</code></pre> This will install all necessary packages to run python=3.12</p>"},{"location":"intro-to-python/setup-env/#activate-virtual-environment","title":"Activate Virtual Environment","text":"<p>Conda stored all packages and envs in its own directory, so you can activate the env from anywhere in your system. To activate the virtual environment, run following command</p> <p><pre><code>conda activate mycondaenv\n</code></pre> After activating the virtual environment, you will see the name of the virtual environment in your terminal prompt. This indicates that you are now working inside the virtual environment.</p>"},{"location":"intro-to-python/setup-env/#deactivate-virtual-environment","title":"Deactivate Virtual Environment","text":"<p>To deactivate conda environment, you can run the following command</p> <pre><code>conda deactivate\n</code></pre> <p>This will deactivate whatever conda environment is running currently.</p>"},{"location":"intro-to-python/variables/","title":"Variables","text":"<p>Variables in simple language are the names assigned to value, so that instead of the value you can just refer to this variable name throughout your code. e.g. If we want to refer to my age in code, instead of writing the value 30, I can just assign this value to a variable</p> <pre><code>my_age = 30\n</code></pre> <p>and now, I can use this variable my_age in my code instead of the value 30. You might ask, why do we do this? Imagine you are writing a code where you are going to use this value at 10 different places, If you don't define the variable and directly use the value, then if you want to change the value from 30 to 31, you'll have to make changes at all 10 places, which make the probability of making error more. But if we use the variable in our python file, then we can just reassign new value to my_age and then this new value will be used everywhere. </p> <p>Here is an example of this</p> <pre><code># Python code for various checks on age with variable\n\nmy_age = 30\n\nif my_age &lt; 25: \n    print('you can not drink')\nif my_age &lt; 18: \n    print('you can not vote')\nif my_age &lt; 16: \n    print('you can not drive')\nif my_age &lt; 14: \n    print('you can not work')\nif my_age &lt; 10: \n    print('you can not stay awake after 10 PM')\n</code></pre> <p>now in above case, if I want to check for any age, I can simply change the value of age and run the code. But if I directly use the value instead of variable, I might make mistake</p> <pre><code># Python code for various checks on age without variable\nif 30 &lt; 25: \n    print('you can not drink')\nif 10 &lt; 18:  #  Accidentally wrote 10 instead of 30  \n    print('you can not vote')\nif 30 &lt; 16: \n    print('you can not drive')\nif 30 &lt; 14: \n    print('you can not work')\nif 30 &lt; 10: \n    print('you can not stay awake after 10 PM')\n</code></pre>"},{"location":"intro-to-python/variables/#defining-variables","title":"Defining variables","text":"<p>In theory, variables can be anything from sensible words like fruit_name , title , is_available to big sentences with either camel xasing vehicleNumer , mathScore or snake casing valid_driver_license_numer , total_test_score . It might contain numbers like is_18 , more_than_30 , or it can start with <code>_</code> such as _5_fruits_names , _3subjectAvg. It can be completely random as dsdfudfgsfs , fdFDSFS_232 , etc. </p> <p>Here are few rules that we need to follow</p> <ul> <li>Variable name can not start with number</li> <li>Variable name can not have special characters </li> </ul>"},{"location":"intro-to-python/variables/#reserve-keywords","title":"Reserve keywords","text":"<p>While variables can be anything, python does not allow few words as variable as they are used internally by python. e.g. <code>True</code>, <code>def</code> , <code>class</code> ,etc. Here is a list of keywords that we can not use. </p>"},{"location":"vector-analysis/accessing_vector_data_online/","title":"Accessing Vector Data from Online Sources \u2014 Full Working Example","text":""},{"location":"vector-analysis/accessing_vector_data_online/#1-setup","title":"1\ufe0f\u20e3 Setup","text":"<pre><code>import geopandas as gpd\nimport osmnx as ox\nimport requests\nfrom io import BytesIO\nimport zipfile\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#2-download-vector-data-via-http","title":"2\ufe0f\u20e3 Download Vector Data via HTTP","text":"<pre><code># Download a zipped shapefile from a URL\nurl = \"https://github.com/gregoiredavid/france-geojson/raw/master/departements.zip\"\nr = requests.get(url)\nwith zipfile.ZipFile(BytesIO(r.content)) as z:\n    z.extractall(\"data_zip/\")\n\n# Load the shapefile\ngdf_zip = gpd.read_file(\"data_zip/departements.shp\")\nprint(gdf_zip.head())\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#3-reading-from-openstreetmap-using-osmnx","title":"3\ufe0f\u20e3 Reading from OpenStreetMap using OSMnx","text":"<pre><code># Download the road network for Pune, India\nG = ox.graph_from_place(\"Pune, India\", network_type=\"drive\")\n\n# Convert the graph to GeoDataFrames\nedges = ox.graph_to_gdfs(G, nodes=False)\nnodes = ox.graph_to_gdfs(G, edges=False)\n\nprint(edges.head())\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#4-using-overpass-api-for-custom-queries","title":"4\ufe0f\u20e3 Using Overpass API for Custom Queries","text":"<pre><code># Define a bounding box: (south, west, north, east)\nbbox = (18.45, 73.80, 18.55, 73.95)\n\n# Query all parks inside bounding box\ntags = {\"leisure\": \"park\"}\ngdf_parks = ox.geometries_from_bbox(*bbox, tags=tags)\n\nprint(gdf_parks.head())\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#5-web-hosted-geojson-example","title":"5\ufe0f\u20e3 Web-hosted GeoJSON Example","text":"<pre><code># Directly read GeoJSON from a URL\nurl_geojson = \"https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements.geojson\"\ngdf_geojson = gpd.read_file(url_geojson)\nprint(gdf_geojson.head())\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#6-combine-all-sources-full-workflow","title":"6\ufe0f\u20e3 Combine All Sources: Full Workflow","text":"<pre><code>fig, ax = plt.subplots(figsize=(12,8))\n\n# Plot HTTP shapefile (France departments) as background\ngdf_zip.to_crs(epsg=3857).plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.5)\n\n# Plot Pune road network\nedges.to_crs(epsg=3857).plot(ax=ax, color='blue', linewidth=1, alpha=0.7)\n\n# Plot parks from Overpass API\ngdf_parks.to_crs(epsg=3857).plot(ax=ax, color='green', markersize=20)\n\nplt.title(\"Combining Vector Data: HTTP + OSMnx + Overpass\")\nplt.show()\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#7-best-practices","title":"7\ufe0f\u20e3 Best Practices","text":"<ul> <li>Check CRS with <code>gdf.crs</code> and convert if needed.</li> <li>Filter large datasets using bounding boxes or tags.</li> <li>Inspect using <code>.head()</code>, <code>.info()</code>, and <code>.plot()</code>.</li> <li>Save cleaned or downloaded data locally:</li> </ul> <pre><code>gdf_parks.to_file(\"parks_pune.geojson\", driver=\"GeoJSON\")\n</code></pre>"},{"location":"vector-analysis/accessing_vector_data_online/#summary","title":"\u2705 Summary","text":"<ul> <li>HTTP downloads allow accessing generic shapefiles and GeoJSONs.</li> <li>OSMnx provides street networks and building footprints.</li> <li>Overpass API is for flexible, tag-based custom queries.</li> <li>Combining multiple sources is easy with GeoPandas and consistent CRS.</li> </ul>"},{"location":"vector-analysis/advanced_spatial_operations/","title":"Advanced Spatial Operations with GeoPandas","text":""},{"location":"vector-analysis/advanced_spatial_operations/#1-setup","title":"1\ufe0f\u20e3 Setup","text":"<pre><code>import geopandas as gpd\nfrom shapely.geometry import Point\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#2-load-natural-earth-data","title":"2\ufe0f\u20e3 Load Natural Earth Data","text":"<pre><code># Countries (polygons)\ncountries = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Populated places (points)\npop_places = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n\n# Roads (lines) - from Natural Earth\nroads = gpd.read_file(\"https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_roads.zip\")\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#3-inspect-visualize","title":"3\ufe0f\u20e3 Inspect &amp; Visualize","text":"<pre><code>fig, ax = plt.subplots(figsize=(12,8))\ncountries.plot(ax=ax, color='lightgray', edgecolor='black')\nroads.plot(ax=ax, color='blue')\npop_places.plot(ax=ax, color='red', markersize=20)\nplt.show()\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#4-crs-transformation","title":"4\ufe0f\u20e3 CRS Transformation","text":"<pre><code># Project to metric CRS for distance-based operations\ncountries = countries.to_crs(epsg=3857)\npop_places = pop_places.to_crs(epsg=3857)\nroads = roads.to_crs(epsg=3857)\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#5-buffering","title":"5\ufe0f\u20e3 Buffering","text":"<pre><code># 50km buffer around cities\npop_places['buffer_50km'] = pop_places.geometry.buffer(50000)\n\n# Plot\nfig, ax = plt.subplots(figsize=(12,8))\ncountries.plot(ax=ax, color='lightgray')\npop_places['buffer_50km'].plot(ax=ax, facecolor='none', edgecolor='green')\npop_places.plot(ax=ax, color='red', markersize=20)\nplt.show()\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#6-spatial-joins","title":"6\ufe0f\u20e3 Spatial Joins","text":"<pre><code># Find which country each city belongs to\ncity_country = gpd.sjoin(pop_places, countries, how='left', predicate='within')\n\n# Find roads within a buffer of 50km of cities\nroads_near_cities = gpd.sjoin(roads, pop_places[['buffer_50km']], how='inner', predicate='intersects')\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#7-nearest-feature-example","title":"7\ufe0f\u20e3 Nearest Feature Example","text":"<pre><code># Find nearest country for each city (if outside any country)\npop_places['nearest_country'] = pop_places.geometry.apply(lambda x: countries.distance(x).idxmin())\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#8-overlay-operations","title":"8\ufe0f\u20e3 Overlay Operations","text":"<pre><code># Intersection: parts of countries covered by city buffers\nintersect_gdf = gpd.overlay(countries, pop_places[['buffer_50km']], how='intersection')\n\n# Difference: country area not covered by buffers\ndiff_gdf = gpd.overlay(countries, pop_places[['buffer_50km']], how='difference')\n\n# Symmetric difference\nsym_diff_gdf = gpd.overlay(countries, pop_places[['buffer_50km']], how='symmetric_difference')\n\n# Union: combine all geometries into one\nunion_gdf = gpd.overlay(countries, pop_places[['buffer_50km']], how='union')\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#9-clipping","title":"9\ufe0f\u20e3 Clipping","text":"<pre><code># Clip roads to country boundaries\nroads_clipped = gpd.clip(roads, countries)\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#dissolve-aggregation","title":"\ud83d\udd1f Dissolve &amp; Aggregation","text":"<pre><code># Dissolve countries by continent\ncontinent_gdf = countries.dissolve(by='continent', aggfunc='sum')\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#11-centroids-bounding-boxes","title":"1\ufe0f\u20e31\ufe0f\u20e3 Centroids &amp; Bounding Boxes","text":"<pre><code>countries['centroid'] = countries.centroid\ncountries['bbox'] = countries.envelope\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#12-distance-calculations","title":"1\ufe0f\u20e32\ufe0f\u20e3 Distance Calculations","text":"<pre><code># Distance from each city to the nearest road\npop_places['dist_to_road'] = pop_places.geometry.apply(lambda x: roads.distance(x).min())\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#13-advanced-examples","title":"1\ufe0f\u20e33\ufe0f\u20e3 Advanced Examples","text":"<ul> <li>Find cities within 50km of any road:  </li> </ul> <pre><code>cities_near_roads = gpd.sjoin(pop_places, roads.buffer(50000).rename('geometry').to_frame(), how='inner', predicate='intersects')\n</code></pre> <ul> <li>Count number of cities per country:  </li> </ul> <pre><code>city_count = city_country.groupby('name_right').size().reset_index(name='city_count')\n</code></pre> <ul> <li>Plot country centroids with city counts:</li> </ul> <pre><code>fig, ax = plt.subplots(figsize=(12,8))\ncountries.plot(ax=ax, color='lightgray')\nfor idx, row in countries.iterrows():\n    plt.text(row['centroid'].x, row['centroid'].y, str(city_count.loc[city_count['name_right']==row['name'], 'city_count'].values[0] if not city_count.loc[city_count['name_right']==row['name']].empty else 0), fontsize=8)\n</code></pre>"},{"location":"vector-analysis/advanced_spatial_operations/#all-key-spatial-operations-covered","title":"\u2705 All Key Spatial Operations Covered","text":"<ul> <li>Inspect &amp; plot  </li> <li>CRS transformation  </li> <li>Buffer &amp; proximity  </li> <li>Spatial join &amp; nearest  </li> <li>Overlay: intersection, difference, union, symmetric difference  </li> <li>Clip &amp; mask  </li> <li>Dissolve &amp; aggregation  </li> <li>Centroid &amp; bounding box  </li> <li>Distance calculation  </li> </ul>"},{"location":"vector-analysis/attribute_query/","title":"Attribute Operations in GeoPandas","text":"<p>GeoPandas allows users to manipulate spatial and non-spatial data efficiently \u2014 just like pandas, but with the power of geometry operations. In this chapter, we\u2019ll explore how to work with attributes, filter data, and combine spatial datasets.</p>"},{"location":"vector-analysis/attribute_query/#filtering-and-querying-features","title":"Filtering and Querying Features","text":"<p>Filtering is essential to extract specific features based on attribute values or conditions.</p>"},{"location":"vector-analysis/attribute_query/#example-filter-by-attribute-value","title":"Example: Filter by attribute value","text":"<pre><code>import geopandas as gpd\n\ngdf = gpd.read_file(\"data/countries.gpkg\")\n\n# Filter countries with population greater than 10 million\nlarge_countries = gdf[gdf[\"population\"] &gt; 10_000_000]\n</code></pre>"},{"location":"vector-analysis/attribute_query/#using-query-for-readable-conditions","title":"Using <code>query()</code> for readable conditions","text":"<pre><code>asian_countries = gdf.query(\"continent == 'Asia' and population &gt; 5000000\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#filter-by-multiple-conditions","title":"Filter by multiple conditions","text":"<pre><code>filtered = gdf[(gdf[\"area\"] &gt; 100000) &amp; (gdf[\"gdp_per_capita\"] &gt; 10000)]\n</code></pre>"},{"location":"vector-analysis/attribute_query/#creating-and-updating-columns","title":"Creating and Updating Columns","text":"<p>GeoPandas allows easy creation and modification of attribute columns.</p>"},{"location":"vector-analysis/attribute_query/#example-create-new-column","title":"Example: Create new column","text":"<pre><code>gdf[\"population_density\"] = gdf[\"population\"] / gdf[\"area\"]\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-update-column-values","title":"Example: Update column values","text":"<pre><code>gdf.loc[gdf[\"continent\"] == \"Asia\", \"region\"] = \"Eastern Hemisphere\"\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-conditional-column-creation","title":"Example: Conditional column creation","text":"<pre><code>gdf[\"category\"] = gdf[\"population\"].apply(lambda x: \"High\" if x &gt; 10_000_000 else \"Low\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-rename-or-drop-columns","title":"Example: Rename or drop columns","text":"<pre><code>gdf = gdf.rename(columns={\"gdp\": \"GDP\"})\ngdf = gdf.drop(columns=[\"old_column\"])\n</code></pre>"},{"location":"vector-analysis/attribute_query/#merging-tabular-and-spatial-data","title":"Merging Tabular and Spatial Data","text":"<p>You can combine spatial datasets or attach non-spatial attributes using <code>merge()</code> or <code>join()</code>.</p>"},{"location":"vector-analysis/attribute_query/#example-merge-geodataframe-with-tabular-data","title":"Example: Merge GeoDataFrame with tabular data","text":"<pre><code>import pandas as pd\n\nstats = pd.read_csv(\"data/country_stats.csv\")\n\nmerged = gdf.merge(stats, on=\"country_code\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#spatial-join-combine-based-on-geometry-relationship","title":"Spatial join (combine based on geometry relationship)","text":"<pre><code>points = gpd.read_file(\"data/cities.geojson\")\npolygons = gpd.read_file(\"data/states.geojson\")\n\n# Join points to polygons to identify which state each city belongs to\njoined = gpd.sjoin(points, polygons, how=\"left\", predicate=\"within\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#merge-multiple-layers","title":"Merge multiple layers","text":"<pre><code>gdf_combined = gdf1.merge(gdf2, on=\"region_id\", how=\"inner\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#groupby-aggregation-and-statistical-summaries","title":"GroupBy, Aggregation, and Statistical Summaries","text":"<p>Like pandas, GeoPandas supports powerful group and aggregation operations.</p>"},{"location":"vector-analysis/attribute_query/#example-group-by-region-and-sum-population","title":"Example: Group by region and sum population","text":"<pre><code>region_stats = gdf.groupby(\"region\")[\"population\"].sum().reset_index()\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-multiple-aggregations","title":"Example: Multiple aggregations","text":"<pre><code>summary = gdf.groupby(\"continent\").agg({\n    \"population\": [\"sum\", \"mean\"],\n    \"area\": [\"mean\"]\n}).reset_index()\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-join-results-back-to-spatial-data","title":"Example: Join results back to spatial data","text":"<pre><code>gdf_summary = gdf.merge(region_stats, on=\"region\")\n</code></pre>"},{"location":"vector-analysis/attribute_query/#example-group-by-geometry-type","title":"Example: Group by geometry type","text":"<pre><code>geom_summary = gdf.groupby(gdf.geom_type).size()\nprint(geom_summary)\n</code></pre>"},{"location":"vector-analysis/attribute_query/#practical-tips","title":"Practical Tips","text":"<ul> <li>Always verify the join key when merging \u2014 mismatched values can lead to missing data.</li> <li>Use <code>.copy()</code> before modifying columns to avoid warnings.</li> <li>For large datasets, filter first before performing expensive spatial joins.</li> <li>For performance, prefer vectorized operations (<code>apply()</code> or arithmetic) over row-by-row loops.</li> </ul>"},{"location":"vector-analysis/attribute_query/#summary","title":"Summary","text":"<p>This chapter covered how to manage, query, and manipulate attributes in GeoPandas, including filtering data, creating and updating columns, merging tables, and performing aggregations. Mastering these operations is key to effective spatial data analysis.</p>"},{"location":"vector-analysis/creating_gis_data/","title":"Creating GIS Data in Python from Scratch","text":"<p>This chapter focuses on creating and manipulating GIS data entirely in Python, with an emphasis on Shapely, the core library for geometric operations. By the end of this chapter, you\u2019ll be able to create, transform, analyze, and export geometry data using Shapely and GeoPandas.</p>"},{"location":"vector-analysis/creating_gis_data/#1-introduction-to-shapely","title":"1. Introduction to Shapely","text":"<p>Shapely is a Python library for creating and manipulating planar geometric objects. It is the foundation for spatial data operations in Python and integrates seamlessly with GeoPandas.</p> <p>Shapely allows you to create and analyze geometries like: - Points (for locations) - LineStrings (for linear features like roads or rivers) - Polygons (for areas like lakes, parks, or buildings)</p>"},{"location":"vector-analysis/creating_gis_data/#2-creating-geometries","title":"2. Creating Geometries","text":""},{"location":"vector-analysis/creating_gis_data/#importing-shapely-geometry-classes","title":"Importing Shapely Geometry Classes","text":"<pre><code>from shapely.geometry import Point, LineString, Polygon\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#creating-a-point","title":"Creating a Point","text":"<p><pre><code>p = Point(77.5946, 12.9716)  # Bengaluru\nprint(p.x, p.y)\n</code></pre> You can also create 3D points: <pre><code>p3d = Point(77.5946, 12.9716, 920)\nprint(p3d.z)\n</code></pre></p>"},{"location":"vector-analysis/creating_gis_data/#creating-a-linestring","title":"Creating a LineString","text":"<pre><code>line = LineString([(77.5, 12.9), (77.6, 13.0), (77.7, 13.2)])\nprint(line.length)\nprint(line.coords[:])\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#creating-a-polygon","title":"Creating a Polygon","text":"<pre><code>poly = Polygon([(77.5, 12.9), (77.7, 13.1), (77.9, 13.0), (77.5, 12.9)])\nprint(poly.area)\nprint(poly.bounds)  # (minx, miny, maxx, maxy)\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#3-common-shapely-attributes-and-methods","title":"3. Common Shapely Attributes and Methods","text":""},{"location":"vector-analysis/creating_gis_data/#point-methods","title":"Point Methods","text":"Method Description <code>.x</code>, <code>.y</code>, <code>.z</code> Access coordinate values <code>.buffer(distance)</code> Creates a circular buffer polygon around the point <code>.distance(other)</code> Calculates Euclidean distance to another geometry <code>.within(other)</code> Checks if point lies within another geometry <code>.intersects(other)</code> Checks if it touches or overlaps another geometry"},{"location":"vector-analysis/creating_gis_data/#example-point-buffer","title":"Example: Point Buffer","text":"<pre><code>p = Point(0, 0)\nbuffered = p.buffer(10)\nprint(buffered.area)  # Area of circle with radius 10\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#linestring-methods","title":"LineString Methods","text":"Method Description <code>.length</code> Total length of line <code>.coords</code> Returns list of coordinates <code>.interpolate(distance)</code> Returns a point at given distance along line <code>.simplify(tolerance)</code> Simplifies line by reducing vertices <pre><code>line = LineString([(0, 0), (1, 1), (2, 2)])\nprint(line.interpolate(1))  # Point at distance 1 along line\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#polygon-methods","title":"Polygon Methods","text":"Method Description <code>.area</code> Polygon area <code>.centroid</code> Returns the geometric center <code>.bounds</code> Bounding box (minx, miny, maxx, maxy) <code>.exterior</code> Outer boundary as LineString <code>.interiors</code> List of holes within polygon <code>.contains(other)</code> True if polygon fully contains another geometry <code>.touches(other)</code> True if boundaries touch <code>.difference(other)</code> Returns area difference <code>.union(other)</code> Merges two polygons"},{"location":"vector-analysis/creating_gis_data/#4-geometry-relationships-and-boolean-operations","title":"4. Geometry Relationships and Boolean Operations","text":"<p>Shapely supports powerful geometric predicates and operations.</p>"},{"location":"vector-analysis/creating_gis_data/#boolean-operations","title":"Boolean Operations","text":"Operation Example Description <code>intersects</code> <code>poly1.intersects(poly2)</code> Checks if they touch/overlap <code>contains</code> <code>poly1.contains(p)</code> True if poly1 fully contains p <code>within</code> <code>p.within(poly1)</code> True if p inside poly1 <code>equals</code> <code>geom1.equals(geom2)</code> Checks geometric equality"},{"location":"vector-analysis/creating_gis_data/#set-like-operations","title":"Set-like Operations","text":"Operation Example Description <code>union</code> <code>poly1.union(poly2)</code> Combines both areas <code>intersection</code> <code>poly1.intersection(poly2)</code> Common overlapping region <code>difference</code> <code>poly1.difference(poly2)</code> Removes overlapping part <code>symmetric_difference</code> <code>poly1.symmetric_difference(poly2)</code> Keeps non-overlapping parts <p>Example: <pre><code>from shapely.geometry import Polygon\n\npoly1 = Polygon([(0,0), (2,0), (2,2), (0,2)])\npoly2 = Polygon([(1,1), (3,1), (3,3), (1,3)])\n\nintersection = poly1.intersection(poly2)\nunion = poly1.union(poly2)\ndifference = poly1.difference(poly2)\n</code></pre></p>"},{"location":"vector-analysis/creating_gis_data/#5-geometric-manipulation","title":"5. Geometric Manipulation","text":""},{"location":"vector-analysis/creating_gis_data/#buffering","title":"Buffering","text":"<pre><code>p = Point(0, 0)\ncircle = p.buffer(5)\ncircle.boundary.length  # Circumference\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#simplification","title":"Simplification","text":"<pre><code>poly = Polygon([(0,0), (1,0.1), (2,0.2), (3,0), (3,1), (0,1)])\nsimple_poly = poly.simplify(0.2)\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#convex-hull","title":"Convex Hull","text":"<p>Creates the smallest convex polygon that encloses all points. <pre><code>from shapely.geometry import MultiPoint\n\npoints = MultiPoint([(0,0), (1,2), (2,1), (2,2)])\nhull = points.convex_hull\n</code></pre></p>"},{"location":"vector-analysis/creating_gis_data/#centroid","title":"Centroid","text":"<pre><code>poly = Polygon([(0,0), (4,0), (4,4), (0,4)])\nprint(poly.centroid)\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#bounds-and-envelope","title":"Bounds and Envelope","text":"<pre><code>print(poly.bounds)     # (minx, miny, maxx, maxy)\nprint(poly.envelope)   # Minimum bounding rectangle\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#6-combining-shapely-with-geopandas","title":"6. Combining Shapely with GeoPandas","text":"<p>After creating geometries, we can integrate them into GeoDataFrames for storage and export.</p> <pre><code>import geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\ncities = ['Delhi', 'Mumbai', 'Chennai']\ngeometry = [Point(77.1, 28.7), Point(72.8, 19.0), Point(80.2, 13.0)]\n\ngdf = gpd.GeoDataFrame({'city': cities}, geometry=geometry, crs='EPSG:4326')\ngdf.plot(markersize=80, color='crimson')\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#export-formats","title":"Export Formats","text":"<pre><code>gdf.to_file('cities.geojson', driver='GeoJSON')\ngdf.to_file('cities.gpkg', layer='cities', driver='GPKG')\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#7-practical-gis-examples-using-shapely","title":"7. Practical GIS Examples Using Shapely","text":""},{"location":"vector-analysis/creating_gis_data/#71-creating-buffer-zones-around-locations","title":"7.1 Creating Buffer Zones Around Locations","text":"<pre><code>schools = [Point(77.5, 12.9), Point(77.6, 13.0)]\nbuffers = [s.buffer(0.05) for s in schools]\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#72-checking-spatial-relationships","title":"7.2 Checking Spatial Relationships","text":"<pre><code>city_boundary = Polygon([(77.4,12.8),(77.8,12.8),(77.8,13.2),(77.4,13.2)])\nschool = Point(77.6, 12.9)\n\nprint(school.within(city_boundary))\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#73-clipping-a-line-by-a-polygon","title":"7.3 Clipping a Line by a Polygon","text":"<pre><code>line = LineString([(77.3, 12.9), (77.9, 13.1)])\nclipped = line.intersection(city_boundary)\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#74-calculating-area-and-length","title":"7.4 Calculating Area and Length","text":"<pre><code>print(city_boundary.area)\nprint(line.length)\n</code></pre>"},{"location":"vector-analysis/creating_gis_data/#8-summary-of-common-shapely-functions","title":"8. Summary of Common Shapely Functions","text":"Category Function Description Creation <code>Point</code>, <code>LineString</code>, <code>Polygon</code>, <code>MultiPoint</code>, <code>MultiPolygon</code> Create geometries Analysis <code>area</code>, <code>length</code>, <code>centroid</code>, <code>bounds</code>, <code>envelope</code> Measure properties Relationships <code>contains</code>, <code>within</code>, <code>intersects</code>, <code>touches</code>, <code>equals</code> Spatial relationships Operations <code>union</code>, <code>difference</code>, <code>intersection</code>, <code>buffer</code>, <code>simplify</code> Modify shapes Transformation <code>translate</code>, <code>rotate</code>, <code>scale</code> Move or reshape geometries"},{"location":"vector-analysis/creating_gis_data/#9-real-world-use-cases","title":"9. Real-World Use Cases","text":"<ul> <li>Urban Planning: Create 500m buffers around schools to check overlapping noise zones.  </li> <li>Environmental Studies: Calculate intersection area of flood zones and forest cover.  </li> <li>Transportation: Simplify road networks for visualization and performance.  </li> <li>Boundary Management: Merge administrative polygons to create regional boundaries.  </li> </ul>"},{"location":"vector-analysis/creating_gis_data/#10-practice-exercises","title":"10. Practice Exercises","text":"<ol> <li>Create 10 random points and compute a convex hull around them.  </li> <li>Create buffers around these points and calculate overlap area.  </li> <li>Clip a polygon with another and visualize using GeoPandas.  </li> <li>Create a custom function that calculates distance between multiple city pairs.  </li> </ol> <p>End of Chapter \u2014 \u201cCreating GIS Data in Python from Scratch\u201d</p>"},{"location":"vector-analysis/low_level_vector_access/","title":"Low-Level Vector File Access with Fiona","text":"<p>Fiona is a Python library that provides a Pythonic interface to GDAL/OGR, designed for reading and writing vector geospatial data formats such as Shapefile, GeoPackage, and GeoJSON. It is a low-level library, meaning it gives you fine-grained control over how files are created, read, and modified.</p>"},{"location":"vector-analysis/low_level_vector_access/#introduction","title":"Introduction","text":"<ul> <li>Fiona focuses on files and records rather than large in-memory data structures like GeoPandas.</li> <li>It is perfect for scenarios where you need to:</li> <li>Inspect metadata and schema</li> <li>Write or append to existing vector datasets</li> <li>Manage large files without loading them entirely into memory</li> </ul>"},{"location":"vector-analysis/low_level_vector_access/#schema-inspection-and-custom-field-types","title":"Schema Inspection and Custom Field Types","text":"<p>Every vector dataset (e.g., a Shapefile) has a schema \u2014 a definition of its geometry type and attributes.</p>"},{"location":"vector-analysis/low_level_vector_access/#reading-a-schema","title":"Reading a Schema","text":"<p><pre><code>import fiona\n\nwith fiona.open(\"data/roads.shp\", \"r\") as src:\n    print(src.schema)\n    print(src.crs)\n    print(src.driver)\n</code></pre> Output might look like: <pre><code>{'geometry': 'LineString',\n 'properties': {'road_name': 'str:80', 'length': 'float'}}\n</code></pre></p>"},{"location":"vector-analysis/low_level_vector_access/#custom-schemas","title":"Custom Schemas","text":"<p>When writing new data, you define your own schema:</p> <pre><code>schema = {\n    'geometry': 'Polygon',\n    'properties': {'id': 'int', 'name': 'str', 'area': 'float'}\n}\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#supported-data-types","title":"Supported Data Types","text":"<p>Common property types: - <code>'int'</code> or <code>'int:10'</code> - <code>'float'</code> or <code>'float:24.15'</code> - <code>'str'</code> or <code>'str:254'</code> - <code>'date'</code>, <code>'datetime'</code>, <code>'time'</code></p>"},{"location":"vector-analysis/low_level_vector_access/#writing-complex-geometry-with-fiona","title":"Writing Complex Geometry with Fiona","text":"<p>Fiona writes geometries using GeoJSON-style dictionaries.</p> <p>Example of writing multiple geometries:</p> <pre><code>import fiona\nfrom shapely.geometry import mapping, Point, Polygon\n\nschema = {\n    'geometry': 'Polygon',\n    'properties': {'name': 'str', 'area': 'float'}\n}\n\nwith fiona.open(\n    \"output/zones.shp\",\n    mode=\"w\",\n    driver=\"ESRI Shapefile\",\n    crs=\"EPSG:4326\",\n    schema=schema\n) as layer:\n    poly1 = Polygon([(0,0), (1,0), (1,1), (0,1)])\n    poly2 = Polygon([(2,2), (3,2), (3,3), (2,3)])\n\n    layer.write({\n        'geometry': mapping(poly1),\n        'properties': {'name': 'Zone A', 'area': poly1.area}\n    })\n    layer.write({\n        'geometry': mapping(poly2),\n        'properties': {'name': 'Zone B', 'area': poly2.area}\n    })\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#writing-multiple-layers-to-a-geopackage","title":"Writing Multiple Layers to a GeoPackage","text":"<pre><code>with fiona.open(\n    \"output/mylayers.gpkg\",\n    layer=\"buildings\",\n    driver=\"GPKG\",\n    mode=\"w\",\n    crs=\"EPSG:4326\",\n    schema={'geometry': 'Polygon', 'properties': {'id': 'int', 'height': 'float'}}\n) as layer:\n    # Write feature\n    pass\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#appending-to-an-existing-dataset","title":"Appending to an Existing Dataset","text":"<pre><code>with fiona.open(\"output/zones.shp\", \"a\") as dst:\n    new_poly = Polygon([(4,4), (5,4), (5,5), (4,5)])\n    dst.write({\n        'geometry': mapping(new_poly),\n        'properties': {'name': 'Zone C', 'area': new_poly.area}\n    })\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#gdalogr-cli-basics-for-preprocessing","title":"GDAL/OGR CLI Basics for Preprocessing","text":"<p>Before writing with Fiona, you may need to preprocess data using GDAL/OGR command-line utilities.</p>"},{"location":"vector-analysis/low_level_vector_access/#inspecting-vector-data","title":"Inspecting Vector Data","text":"<pre><code>ogrinfo data/roads.shp -so -al\n</code></pre> <p>Displays summary information, schema, and field types.</p>"},{"location":"vector-analysis/low_level_vector_access/#reprojecting-vector-data","title":"Reprojecting Vector Data","text":"<pre><code>ogr2ogr -t_srs EPSG:4326 output/roads_wgs84.shp data/roads.shp\n</code></pre> <p>Converts the coordinate system to WGS84.</p>"},{"location":"vector-analysis/low_level_vector_access/#filtering-features-by-attribute","title":"Filtering Features by Attribute","text":"<pre><code>ogr2ogr -where \"road_type='highway'\" output/highways.shp data/roads.shp\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#converting-between-formats","title":"Converting Between Formats","text":"<pre><code>ogr2ogr -f \"GeoJSON\" output/roads.json data/roads.shp\nogr2ogr -f \"GPKG\" output/roads.gpkg data/roads.shp\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#combining-fiona-with-shapely-for-geometry-processing","title":"Combining Fiona with Shapely for Geometry Processing","text":"<p>Fiona and Shapely integrate well for editing and manipulating geometries before saving back to disk.</p> <pre><code>import fiona\nfrom shapely.geometry import shape, mapping\n\nwith fiona.open(\"data/roads.shp\") as src:\n    schema = src.schema.copy()\n    with fiona.open(\"output/roads_buffered.shp\", \"w\", driver=src.driver, crs=src.crs, schema=schema) as dst:\n        for feature in src:\n            geom = shape(feature[\"geometry\"])\n            buffered = geom.buffer(0.01)\n            feature[\"geometry\"] = mapping(buffered)\n            dst.write(feature)\n</code></pre>"},{"location":"vector-analysis/low_level_vector_access/#best-practices","title":"Best Practices","text":"<ul> <li>Always close datasets (use <code>with fiona.open()</code> context managers).</li> <li>Define schemas explicitly to avoid type mismatches.</li> <li>Validate geometries with Shapely before writing.</li> <li>Use GDAL CLI tools for heavy preprocessing (e.g., reprojection, format conversion).</li> <li>Fiona is I/O-focused, not analytical \u2014 use GeoPandas for analysis.</li> </ul>"},{"location":"vector-analysis/low_level_vector_access/#summary","title":"Summary","text":"<p>Fiona gives precise control over geospatial vector file input/output, making it ideal for data engineers and GIS developers working with raw data pipelines. By combining Fiona, Shapely, and GDAL/OGR, you can efficiently handle everything from geometry creation to schema management and data transformation.</p>"},{"location":"vector-analysis/osmnx/","title":"Using OSMnx \u2014 Methods and Workflows","text":""},{"location":"vector-analysis/osmnx/#1-setup","title":"1\ufe0f\u20e3 Setup","text":"<p><pre><code>import osmnx as ox\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n</code></pre> - Ensure latest OSMnx version installed: <code>pip install osmnx --upgrade</code> - OSMnx uses OpenStreetMap data for street networks, building footprints, POIs, etc.</p>"},{"location":"vector-analysis/osmnx/#2-basic-network-download","title":"2\ufe0f\u20e3 Basic Network Download","text":"<p><pre><code>G = ox.graph_from_place(\"Pune, India\", network_type=\"drive\")\nG_walk = ox.graph_from_place(\"Pune, India\", network_type=\"walk\")\n</code></pre> - <code>network_type</code> options: <code>\"drive\"</code>, <code>\"walk\"</code>, <code>\"bike\"</code>, <code>\"all\"</code>, <code>\"all_private\"</code> - Graph is a NetworkX MultiDiGraph</p>"},{"location":"vector-analysis/osmnx/#3-convert-graph-to-geodataframes","title":"3\ufe0f\u20e3 Convert Graph to GeoDataFrames","text":"<p><pre><code>edges = ox.graph_to_gdfs(G, nodes=False)\nnodes = ox.graph_to_gdfs(G, edges=False)\n</code></pre> - <code>edges</code> contain street segments - <code>nodes</code> contain intersections</p>"},{"location":"vector-analysis/osmnx/#4-plotting-networks","title":"4\ufe0f\u20e3 Plotting Networks","text":"<p><pre><code>ox.plot_graph(G, node_size=10, edge_color='blue', bgcolor='white')\n</code></pre> - Simple graph plotting - Can also use Matplotlib for custom plots with <code>edges.plot()</code> and <code>nodes.plot()</code></p>"},{"location":"vector-analysis/osmnx/#5-geometries-from-place-or-polygon","title":"5\ufe0f\u20e3 Geometries from Place or Polygon","text":"<p><pre><code>buildings = ox.geometries_from_place(\"Pune, India\", tags={\"building\": True})\ncafes = ox.geometries_from_place(\"Pune, India\", tags={\"amenity\": \"cafe\"})\n</code></pre> - Returns GeoDataFrame with geometries and attributes - Can filter by tags like <code>building</code>, <code>amenity</code>, <code>highway</code>, <code>landuse</code>, etc.</p>"},{"location":"vector-analysis/osmnx/#6-using-bounding-boxes","title":"6\ufe0f\u20e3 Using Bounding Boxes","text":"<p><pre><code>bbox = (18.45, 73.80, 18.55, 73.95)\nhighways = ox.geometries_from_bbox(*bbox, tags={\"highway\": True})\n</code></pre> - Useful for sub-city areas - Works with buildings, streets, and other features</p>"},{"location":"vector-analysis/osmnx/#7-using-polygons","title":"7\ufe0f\u20e3 Using Polygons","text":"<p><pre><code>from shapely.geometry import Polygon\n\npoly = Polygon([(73.80,18.45),(73.80,18.55),(73.95,18.55),(73.95,18.45)])\nroads_poly = ox.geometries_from_polygon(poly, tags={\"highway\": True})\n</code></pre> - Polygon-based queries allow precise custom regions</p>"},{"location":"vector-analysis/osmnx/#8-graph-utilities","title":"8\ufe0f\u20e3 Graph Utilities","text":"<p><pre><code>stats = ox.basic_stats(G)\nprint(stats)\n\nG = ox.add_edge_speeds(G)\nG = ox.add_edge_travel_times(G)\n</code></pre> - Adds realistic attributes for routing</p>"},{"location":"vector-analysis/osmnx/#9-routing-examples","title":"9\ufe0f\u20e3 Routing Examples","text":"<p><pre><code>import networkx as nx\n\norig_node = list(G.nodes)[0]\ndest_node = list(G.nodes)[50]\n\nroute = nx.shortest_path(G, orig_node, dest_node, weight='length')\n\nfig, ax = ox.plot_graph_route(G, route, node_size=0, bgcolor='white')\n</code></pre> - Can use <code>length</code>, <code>travel_time</code>, or custom weights</p>"},{"location":"vector-analysis/osmnx/#10-saving-and-loading","title":"10\ufe0f\u20e3 Saving and Loading","text":"<p><pre><code>ox.save_graphml(G, \"pune_drive.graphml\")\nG2 = ox.load_graphml(\"pune_drive.graphml\")\nedges.to_file(\"pune_edges.shp\")\n</code></pre> - OSMnx integrates with GeoPandas for saving and analysis</p>"},{"location":"vector-analysis/osmnx/#11-additional-utilities","title":"11\ufe0f\u20e3 Additional Utilities","text":"<ul> <li>Simplify graphs: <code>ox.simplify_graph(G)</code> </li> <li>Project graphs: <code>G_proj = ox.project_graph(G)</code> (to metric CRS)  </li> <li>Calculate network stats: <code>ox.extended_stats(G_proj)</code> </li> <li>Nearest nodes: <code>ox.distance.nearest_nodes(G, X, Y)</code> </li> <li>Shortest path with travel times, lengths, or custom attributes</li> </ul>"},{"location":"vector-analysis/osmnx/#12-full-hands-on-workflow-roads-buildings-and-pois","title":"12\ufe0f\u20e3 Full Hands-On Workflow: Roads, Buildings, and POIs","text":"<p><pre><code># Define a polygon for a small Pune area\nfrom shapely.geometry import Polygon\n\npoly = Polygon([(73.80,18.50),(73.80,18.52),(73.83,18.52),(73.83,18.50)])\n\n# Get road network within polygon\nG_sub = ox.graph_from_polygon(poly, network_type=\"drive\")\n\n# Convert to GeoDataFrames\nedges_sub = ox.graph_to_gdfs(G_sub, nodes=False)\nnodes_sub = ox.graph_to_gdfs(G_sub, edges=False)\n\n# Get buildings and cafes inside polygon\nbuildings_sub = ox.geometries_from_polygon(poly, tags={\"building\": True})\ncafes_sub = ox.geometries_from_polygon(poly, tags={\"amenity\": \"cafe\"})\n\n# Plot combined layers\nfig, ax = plt.subplots(figsize=(10,10))\n\n# Plot roads\nedges_sub.plot(ax=ax, linewidth=1, edgecolor='blue')\n\n# Plot buildings\nbuildings_sub.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.5)\n\n# Plot cafes\ncafes_sub.plot(ax=ax, color='red', markersize=20, label='Cafe')\n\nplt.title(\"Pune Subset: Roads, Buildings, Cafes\")\nplt.legend()\nplt.show()\n</code></pre> - Combines network, building footprints, and points of interest - CRS handled automatically for plotting - Can extend workflow to routing or spatial analysis</p>"},{"location":"vector-analysis/osmnx/#summary","title":"\u2705 Summary","text":"<ul> <li>OSMnx allows querying networks, buildings, and POIs by place, bounding box, or polygon</li> <li>Provides GeoDataFrames for easy manipulation in GeoPandas</li> <li>Full workflows can combine multiple layers for visualization and analysis</li> <li>Supports routing, metrics, and saving/loading for reuse</li> </ul>"},{"location":"vector-analysis/spatial_operations/","title":"Spatial Operations in GeoPandas","text":""},{"location":"vector-analysis/spatial_operations/#introduction","title":"Introduction","text":"<p>Spatial operations are the heart of vector-based GIS analysis. GeoPandas provides high-level access to these operations through its integration with Shapely and PyGEOS under the hood. With these tools, you can measure spatial relationships, combine geometries, and derive new spatial datasets.</p>"},{"location":"vector-analysis/spatial_operations/#core-spatial-relationships","title":"Core Spatial Relationships","text":"<ul> <li> <p>Intersects \u2014 Check if geometries overlap or touch. <pre><code>gdf['intersects'] = gdf.geometry.intersects(other_gdf.unary_union)\n</code></pre></p> </li> <li> <p>Within / Contains \u2014 Identify features inside or containing others. <pre><code>gdf['within_boundary'] = gdf.geometry.within(boundary.geometry.iloc[0])\ngdf['contains_point'] = gdf.geometry.contains(point)\n</code></pre></p> </li> <li> <p>Touches / Crosses / Overlaps \u2014 Detect specific spatial relationships between lines and polygons. <pre><code>roads['touches_boundary'] = roads.touches(city_boundary.geometry.iloc[0])\nrivers['crosses_road'] = rivers.crosses(roads.unary_union)\n</code></pre></p> </li> <li> <p>Distance-based relations \u2014 Compute minimum distance between features. <pre><code>gdf['dist_to_road'] = gdf.distance(roads.unary_union)\n</code></pre></p> </li> </ul>"},{"location":"vector-analysis/spatial_operations/#geometric-set-operations","title":"Geometric Set Operations","text":"<ul> <li> <p>Union \u2014 Merge multiple geometries into one. <pre><code>merged = gdf.unary_union\n</code></pre></p> </li> <li> <p>Intersection \u2014 Extract the common area between two geometries. <pre><code>common_area = gpd.overlay(gdf1, gdf2, how='intersection')\n</code></pre></p> </li> <li> <p>Difference \u2014 Subtract one geometry from another. <pre><code>remaining = gpd.overlay(gdf1, gdf2, how='difference')\n</code></pre></p> </li> <li> <p>Symmetric Difference \u2014 Areas belonging to one or the other, but not both. <pre><code>unique_areas = gpd.overlay(gdf1, gdf2, how='symmetric_difference')\n</code></pre></p> </li> </ul>"},{"location":"vector-analysis/spatial_operations/#buffering-and-proximity-analysis","title":"Buffering and Proximity Analysis","text":"<p>Buffers are used to create zones around features \u2014 essential in proximity and impact analysis.</p> <pre><code># Create 500-meter buffer around roads\nroads['buffer_500m'] = roads.geometry.buffer(500)\n\n# Find all schools within 500m of a road\nschools_near_roads = schools[schools.geometry.intersects(roads.unary_union.buffer(500))]\n</code></pre> <p>Tips: - Always confirm the CRS is in meters before buffering (e.g., <code>EPSG:32643</code>). - Use <code>buffer(distance, cap_style=2)</code> for square edges.</p>"},{"location":"vector-analysis/spatial_operations/#spatial-joins","title":"Spatial Joins","text":"<p>Spatial joins link features based on spatial relationships \u2014 like finding which district a school belongs to.</p> <pre><code>schools_with_districts = gpd.sjoin(schools, districts, how='left', predicate='within')\n</code></pre> <p>Options for <code>predicate</code>: - <code>'intersects'</code> - <code>'within'</code> - <code>'contains'</code></p> <p>After a spatial join, your attributes are merged, enabling both geometric and tabular analysis.</p>"},{"location":"vector-analysis/spatial_operations/#clipping-and-masking","title":"Clipping and Masking","text":"<p>Clip a layer to a defined boundary (common for administrative region analysis).</p> <pre><code>subset = gpd.clip(landcover, region)\n</code></pre> <p>This reduces data size and isolates the area of interest for further analysis.</p>"},{"location":"vector-analysis/spatial_operations/#dissolving-and-aggregation","title":"Dissolving and Aggregation","text":"<p>Combine geometries sharing the same attribute, such as merging polygons of the same state.</p> <pre><code>states = districts.dissolve(by='state_name', aggfunc='sum')\n</code></pre> <ul> <li><code>aggfunc</code> can summarize numeric columns (<code>sum</code>, <code>mean</code>, <code>max</code>, etc.).</li> <li>Dissolving simplifies layers for cleaner visualization or reporting.</li> </ul>"},{"location":"vector-analysis/spatial_operations/#centroids-and-bounding-boxes","title":"Centroids and Bounding Boxes","text":"<p>Useful for representing complex geometries with simpler spatial representations.</p> <pre><code># Compute centroid of each polygon\ngdf['centroid'] = gdf.geometry.centroid\n\n# Extract bounding boxes\ngdf['bbox'] = gdf.geometry.envelope\n</code></pre>"},{"location":"vector-analysis/spatial_operations/#real-world-use-cases","title":"Real-World Use Cases","text":"<ul> <li>Environmental Analysis \u2014 Overlay land cover with administrative boundaries to estimate forest cover by region.  </li> <li>Urban Planning \u2014 Buffer roads or rivers to identify restricted zones.  </li> <li>Accessibility Studies \u2014 Use distance and intersection functions to find service areas around facilities.  </li> <li>Infrastructure Risk Assessment \u2014 Clip hazard zones (floods, earthquakes) with asset locations.</li> </ul>"},{"location":"vector-analysis/spatial_operations/#best-practices","title":"Best Practices","text":"<ul> <li>Always verify CRS alignment before performing spatial operations. Use <code>gdf.to_crs()</code> if needed.  </li> <li>When working with large datasets, prefer vectorized operations instead of row-by-row loops.  </li> <li>Validate geometries before processing using <code>gdf.is_valid</code>. Repair with <code>gdf.buffer(0)</code> if needed.  </li> <li>Use simplified geometries for faster performance in large-scale spatial joins.</li> </ul>"},{"location":"vector-analysis/spatial_operations/#further-reading","title":"Further Reading","text":"<ul> <li>GeoPandas documentation \u2014 https://geopandas.org/ </li> <li>Shapely documentation for geometry operations \u2014 https://shapely.readthedocs.io/ </li> <li>GDAL/OGR command-line utilities for preprocessing large spatial files.</li> </ul>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/","title":"Spatial Operations in GeoPandas","text":"<p>Spatial operations allow us to combine, compare, and analyze geographic features based on their geometry.\\ In this tutorial, we'll use Natural Earth datasets and explore how to perform key spatial operations in GeoPandas.</p>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#1-setup-and-import","title":"1\ufe0f\u20e3 Setup and Import","text":"<pre><code>import geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#2-download-and-load-natural-earth-data","title":"2\ufe0f\u20e3 Download and Load Natural Earth Data","text":"<p>GeoPandas has a convenient function to load sample datasets from the Natural Earth collection.</p> <pre><code># Load world boundaries\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Load cities (requires geopandas datasets plugin)\ncities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n\nworld.head()\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#3-inspecting-and-visualizing","title":"3\ufe0f\u20e3 Inspecting and Visualizing","text":"<pre><code># Quick visualization\nfig, ax = plt.subplots(figsize=(10, 6))\nworld.plot(ax=ax, color='lightgray', edgecolor='black')\ncities.plot(ax=ax, color='red', markersize=10)\nplt.show()\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#4-reprojecting-to-a-metric-crs","title":"4\ufe0f\u20e3 Reprojecting to a Metric CRS","text":"<p>Always use a projected CRS for distance or area calculations.</p> <pre><code>world = world.to_crs(epsg=3857)\ncities = cities.to_crs(epsg=3857)\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#5-buffer-operation-example-200-km-around-cities","title":"5\ufe0f\u20e3 Buffer Operation (Example: 200 km around cities)","text":"<pre><code>cities['buffer_200km'] = cities.buffer(200000)  # meters since EPSG:3857\nbuffer_gdf = gpd.GeoDataFrame(cities[['name']], geometry=cities['buffer_200km'])\n</code></pre> <pre><code># Plot buffers\nfig, ax = plt.subplots(figsize=(10, 6))\nworld.plot(ax=ax, color='lightgray')\nbuffer_gdf.plot(ax=ax, facecolor='none', edgecolor='blue')\ncities.plot(ax=ax, color='red', markersize=20)\nplt.show()\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#6-spatial-join-find-which-country-each-city-belongs-to","title":"6\ufe0f\u20e3 Spatial Join --- Find Which Country Each City Belongs To","text":"<pre><code>city_country = gpd.sjoin(cities, world, how='left', predicate='within')\ncity_country[['name', 'name_right']].head()\n</code></pre> <p>This gives the country name for each city.</p>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#7-overlay-operations","title":"7\ufe0f\u20e3 Overlay Operations","text":"<p>Overlay operations combine two spatial datasets based on geometry --- like intersection, union, difference, and symmetric difference.</p> <p>Example: Find part of countries within a 200 km radius of any major city.</p> <pre><code>country_near_city = gpd.overlay(world, buffer_gdf, how='intersection')\ncountry_near_city.plot(color='orange', edgecolor='black')\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#8-measuring-area-and-distance","title":"8\ufe0f\u20e3 Measuring Area and Distance","text":"<pre><code># Area in square kilometers\nworld['area_km2'] = world.geometry.area / 10**6\n\n# Example: Distance between first two cities\ndistance = cities.distance(cities.geometry.iloc[0])\ndistance.head()\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#9-centroid-extraction","title":"9\ufe0f\u20e3 Centroid Extraction","text":"<pre><code>world['centroid'] = world.centroid\ncentroids = gpd.GeoDataFrame(geometry=world['centroid'])\n</code></pre> <pre><code># Plot centroids\nfig, ax = plt.subplots(figsize=(10, 6))\nworld.plot(ax=ax, color='lightgreen', edgecolor='black')\ncentroids.plot(ax=ax, color='red', markersize=15)\nplt.show()\n</code></pre>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#summary-of-spatial-operations-covered","title":"\ud83d\udd1f Summary of Spatial Operations Covered","text":"<p>Operation               Function              Description</p> <p>Buffer                  <code>buffer()</code>            Creates zones around geometries</p> <p>Spatial Join            <code>gpd.sjoin()</code>         Combine layers based on spatial                                                 relation</p> <p>Overlay                 <code>gpd.overlay()</code>       Perform                                                 intersection/union/difference</p> <p>Reprojection            <code>to_crs()</code>            Convert CRS for metric accuracy</p> <p>Area/Distance           <code>.area</code>,              Compute measurements                           <code>.distance()</code> </p> <p>Centroid                <code>.centroid</code>           Get geometric center</p>"},{"location":"vector-analysis/spatial_operations_in_geopandas%20%281%29/#conclusion","title":"\u2705 Conclusion","text":"<p>You've learned how to: - Load real-world datasets (Natural Earth) - Perform spatial joins, overlays, and measurements - Visualize and manipulate geometry data in GeoPandas</p> <p>Next, try combining these tools for your own spatial analysis workflows --- such as proximity analysis, regional summaries, or environmental impact assessments.</p>"},{"location":"vector-analysis/spatial_relations/","title":"Spatial Relations","text":""},{"location":"vector-analysis/spatial_relations/#introduction","title":"Introduction","text":"<ul> <li>Spatial relationships define how spatial features relate to one another in space.</li> <li>Geometry operations allow us to transform, analyze, and manipulate spatial shapes.</li> <li>Together, these are foundational in spatial data analysis.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#types-of-spatial-relationships","title":"Types of Spatial Relationships","text":""},{"location":"vector-analysis/spatial_relations/#disjoint","title":"\ud83d\udccc Disjoint","text":"<ul> <li>Explanation: No common point between geometries.</li> <li>Use Case: Find urban areas not impacted by flooding zones.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#touch","title":"\ud83d\udccc Touch","text":"<ul> <li>Explanation: Geometries touch at boundaries but do not overlap.</li> <li>Use Case: Identify villages that touch forest boundaries.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#intersect","title":"\ud83d\udccc Intersect","text":"<ul> <li>Explanation: Any spatial overlap between features.</li> <li>Use Case: Roads that intersect flood zones.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#_1","title":"Spatial Relations","text":""},{"location":"vector-analysis/spatial_relations/#within-contains","title":"\ud83d\udccc Within / Contains","text":"<ul> <li>Explanation:</li> <li>A within B: A lies completely inside B.</li> <li>B contains A: Same as above, reversed.</li> <li>Use Case: Lakes within administrative boundaries.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#overlaps","title":"\ud83d\udccc Overlaps","text":"<ul> <li>Explanation: Features partially overlap but neither completely contains the other.</li> <li>Use Case: Identify conflict zones between mining and wildlife areas.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#crosses","title":"\ud83d\udccc Crosses","text":"<ul> <li>Explanation: Features cross each other like an 'X'.</li> <li>Use Case: Rivers crossing roads or railways.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#equals","title":"\ud83d\udccc Equals","text":"<ul> <li>Explanation: Geometries are identical in shape and position.</li> <li>Use Case: Validate duplicate parcel entries.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#geometry-operations","title":"Geometry Operations","text":""},{"location":"vector-analysis/spatial_relations/#buffer","title":"\ud83d\udccd Buffer","text":"<ul> <li>Explanation: Creates zones at a specified distance from features.</li> <li>Use Case: Identify schools within 500m of highways.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#intersection","title":"\ud83d\udccd Intersection","text":"<ul> <li>Explanation: Extracts shared area between layers.</li> <li>Use Case: Areas where agriculture and flood zones overlap.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#union","title":"\ud83d\udccd Union","text":"<ul> <li>Explanation: Merges geometries into one combined shape.</li> <li>Use Case: Combine two adjacent conservation zones.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#difference","title":"\ud83d\udccd Difference","text":"<ul> <li>Explanation: Removes the area of B from A.</li> <li>Use Case: Exclude roads from construction zones.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#symmetric-difference","title":"\ud83d\udccd Symmetric Difference","text":"<ul> <li>Explanation: Returns areas unique to each geometry.</li> <li>Use Case: Change detection between two land-use years.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#centroid","title":"\ud83d\udccd Centroid","text":"<ul> <li>Explanation: Finds the geometric center of a shape.</li> <li>Use Case: Label location of administrative zones.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#convex-hull","title":"\ud83d\udccd Convex Hull","text":"<ul> <li>Explanation: Smallest convex polygon enclosing a geometry.</li> <li>Use Case: Estimate range of animal movement from GPS points.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#envelope-bounding-box","title":"\ud83d\udccd Envelope (Bounding Box)","text":"<ul> <li>Explanation: Minimum bounding rectangle that encloses a feature.</li> <li>Use Case: Indexing features for faster processing.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#simplify","title":"\ud83d\udccd Simplify","text":"<ul> <li>Explanation: Reduces the number of vertices in complex geometries.</li> <li>Use Case: Create simplified boundaries for web maps.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#densify","title":"\ud83d\udccd Densify","text":"<ul> <li>Explanation: Adds vertices at regular intervals along geometry.</li> <li>Use Case: Improve accuracy for projection transformations.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#split","title":"\ud83d\udccd Split","text":"<ul> <li>Explanation: Divides geometry using a line or another polygon.</li> <li>Use Case: Split a district into zones using a river.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#clip","title":"\ud83d\udccd Clip","text":"<ul> <li>Explanation: Cuts a geometry using another as a mask.</li> <li>Use Case: Clip land-use data to a city boundary.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#distance","title":"\ud83d\udccd Distance","text":"<ul> <li>Explanation: Shortest path between features.</li> <li>Use Case: Distance from a village to nearest river.</li> </ul>"},{"location":"vector-analysis/spatial_relations/#spatial-join","title":"\ud83d\udccd Spatial Join","text":"<ul> <li>Explanation: Attribute data is transferred based on spatial relation.</li> <li>Use Case: Attach population data to districts.</li> </ul>"}]}